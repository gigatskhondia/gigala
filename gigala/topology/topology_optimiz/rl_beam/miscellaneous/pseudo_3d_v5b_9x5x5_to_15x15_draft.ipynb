{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df9c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795aff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fb0afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import results_plotter\n",
    "import autograd, autograd.core, autograd.extend, autograd.tracer  \n",
    "import autograd.numpy as anp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea66b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0, z0 = 9, 5, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501892d4",
   "metadata": {},
   "source": [
    "### Finite Element Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5ac3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectView(object):\n",
    "    def __init__(self, d): self.__dict__ = d\n",
    "    \n",
    "def get_args(normals, forces, density=1e-4):  # Manage the problem setup parameters\n",
    "    width = normals.shape[0] - 1\n",
    "    height = normals.shape[1] - 1\n",
    "    fixdofs = np.flatnonzero(normals.ravel())\n",
    "    alldofs = np.arange(2 * (width + 1) * (height + 1))\n",
    "    freedofs = np.sort(list(set(alldofs) - set(fixdofs)))\n",
    "    params = {\n",
    "      # material properties\n",
    "      'young': 1, 'young_min': 1e-9, 'poisson': 0.3, 'g': 0,\n",
    "      # constraints\n",
    "      'density': density, 'xmin': 0.001, 'xmax': 1.0,\n",
    "      # input parameters\n",
    "      'nelx': width, 'nely': height, 'mask': 1, 'penal': 3.0, 'filter_width': 1,\n",
    "      'freedofs': freedofs, 'fixdofs': fixdofs, 'forces': forces.ravel(),\n",
    "      # optimization parameters\n",
    "      'opt_steps': 80, 'print_every': 10}\n",
    "#     print(params)\n",
    "    return ObjectView(params)\n",
    "\n",
    "def mbb_beam(width=z0*3, height=z0*3, density=1e-4, y=1, x=0, rd=-1):  # textbook beam example\n",
    "    normals = np.zeros((width + 1, height + 1, 2))\n",
    "    normals[0, 0, x] = 1\n",
    "    normals[0, 0, y] = 1\n",
    "    normals[0, -1, x] = 1\n",
    "    normals[0, -1, y] = 1\n",
    "    forces = np.zeros((width + 1, height + 1, 2))\n",
    "    forces[-1, rd, y] = -1\n",
    "    return normals, forces, density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdaf4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def young_modulus(x, e_0, e_min, p=3):\n",
    "    return e_min + x ** p * (e_0 - e_min)\n",
    "\n",
    "def physical_density(x, args, volume_contraint=False, use_filter=True):\n",
    "    x = args.mask * x.reshape(args.nely, args.nelx)  # reshape from 1D to 2D\n",
    "    return gaussian_filter(x, args.filter_width) if use_filter else x  # maybe filter\n",
    "\n",
    "def mean_density(x, args, volume_contraint=False, use_filter=True):\n",
    "    return anp.mean(physical_density(x, args, volume_contraint, use_filter)) / anp.mean(args.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d0125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, args, volume_contraint=False, use_filter=True):\n",
    "    kwargs = dict(penal=args.penal, e_min=args.young_min, e_0=args.young)\n",
    "    x_phys = physical_density(x, args, volume_contraint=volume_contraint, use_filter=use_filter)\n",
    "    ke     = get_stiffness_matrix(args.young, args.poisson)  # stiffness matrix\n",
    "    u      = displace(x_phys, ke, args.forces, args.freedofs, args.fixdofs, **kwargs)\n",
    "    c      = compliance(x_phys, u, ke, **kwargs)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55484aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@autograd.extend.primitive\n",
    "def gaussian_filter(x, width): # 2D gaussian blur/filter\n",
    "    return scipy.ndimage.gaussian_filter(x, width, mode='reflect')\n",
    "\n",
    "def _gaussian_filter_vjp(ans, x, width): # gives the gradient of orig. function w.r.t. x\n",
    "    del ans, x  # unused\n",
    "    return lambda g: gaussian_filter(g, width)\n",
    "autograd.extend.defvjp(gaussian_filter, _gaussian_filter_vjp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799b9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compliance(x_phys, u, ke, *, penal=3, e_min=1e-9, e_0=1):\n",
    "    nely, nelx = x_phys.shape\n",
    "    ely, elx = anp.meshgrid(range(nely), range(nelx))  # x, y coords for the index map\n",
    "\n",
    "    n1 = (nely+1)*(elx+0) + (ely+0)  # nodes\n",
    "    n2 = (nely+1)*(elx+1) + (ely+0)\n",
    "    n3 = (nely+1)*(elx+1) + (ely+1)\n",
    "    n4 = (nely+1)*(elx+0) + (ely+1)\n",
    "    all_ixs = anp.array([2*n1, 2*n1+1, 2*n2, 2*n2+1, 2*n3, 2*n3+1, 2*n4, 2*n4+1])\n",
    "    u_selected = u[all_ixs]  # select from u matrix\n",
    "\n",
    "    ke_u = anp.einsum('ij,jkl->ikl', ke, u_selected)  # compute x^penal * U.T @ ke @ U\n",
    "    ce = anp.einsum('ijk,ijk->jk', u_selected, ke_u)\n",
    "    C = young_modulus(x_phys, e_0, e_min, p=penal) * ce.T\n",
    "    return anp.sum(C)\n",
    "\n",
    "def get_stiffness_matrix(e, nu):  # e=young's modulus, nu=poisson coefficient\n",
    "    k = anp.array([1/2-nu/6, 1/8+nu/8, -1/4-nu/12, -1/8+3*nu/8,\n",
    "                -1/4+nu/12, -1/8-nu/8, nu/6, 1/8-3*nu/8])\n",
    "    return e/(1-nu**2)*anp.array([[k[0], k[1], k[2], k[3], k[4], k[5], k[6], k[7]],\n",
    "                               [k[1], k[0], k[7], k[6], k[5], k[4], k[3], k[2]],\n",
    "                               [k[2], k[7], k[0], k[5], k[6], k[3], k[4], k[1]],\n",
    "                               [k[3], k[6], k[5], k[0], k[7], k[2], k[1], k[4]],\n",
    "                               [k[4], k[5], k[6], k[7], k[0], k[1], k[2], k[3]],\n",
    "                               [k[5], k[4], k[3], k[2], k[1], k[0], k[7], k[6]],\n",
    "                               [k[6], k[3], k[4], k[1], k[2], k[7], k[0], k[5]],\n",
    "                               [k[7], k[2], k[1], k[4], k[3], k[6], k[5], k[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b6372f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k(stiffness, ke):\n",
    "    # Constructs sparse stiffness matrix k (used in the displace fn)\n",
    "    # First, get position of the nodes of each element in the stiffness matrix\n",
    "    nely, nelx = stiffness.shape\n",
    "    ely, elx = anp.meshgrid(range(nely), range(nelx))  # x, y coords\n",
    "    ely, elx = ely.reshape(-1, 1), elx.reshape(-1, 1)\n",
    "\n",
    "    n1 = (nely+1)*(elx+0) + (ely+0)\n",
    "    n2 = (nely+1)*(elx+1) + (ely+0)\n",
    "    n3 = (nely+1)*(elx+1) + (ely+1)\n",
    "    n4 = (nely+1)*(elx+0) + (ely+1)\n",
    "    edof = anp.array([2*n1, 2*n1+1, 2*n2, 2*n2+1, 2*n3, 2*n3+1, 2*n4, 2*n4+1])\n",
    "    edof = edof.T[0]\n",
    "    x_list = anp.repeat(edof, 8)  # flat list pointer of each node in an element\n",
    "    y_list = anp.tile(edof, 8).flatten()  # flat list pointer of each node in elem\n",
    "\n",
    "    # make the global stiffness matrix K\n",
    "    kd = stiffness.T.reshape(nelx*nely, 1, 1)\n",
    "    value_list = (kd * anp.tile(ke, kd.shape)).flatten()\n",
    "    return value_list, y_list, x_list\n",
    "\n",
    "def displace(x_phys, ke, forces, freedofs, fixdofs, *, penal=3, e_min=1e-9, e_0=1):\n",
    "    # Displaces the load x using finite element techniques (solve_coo=most of runtime)\n",
    "    stiffness = young_modulus(x_phys, e_0, e_min, p=penal)\n",
    "    k_entries, k_ylist, k_xlist = get_k(stiffness, ke)\n",
    "\n",
    "    index_map, keep, indices = _get_dof_indices(freedofs, fixdofs, k_ylist, k_xlist)\n",
    "\n",
    "    u_nonzero = solve_coo(k_entries[keep], indices, forces[freedofs], sym_pos=True)\n",
    "    u_values = anp.concatenate([u_nonzero, anp.zeros(len(fixdofs))])\n",
    "    return u_values[index_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50801294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dof_indices(freedofs, fixdofs, k_xlist, k_ylist):\n",
    "    index_map = inverse_permutation(anp.concatenate([freedofs, fixdofs]))\n",
    "    keep = anp.isin(k_xlist, freedofs) & anp.isin(k_ylist, freedofs)\n",
    "    # Now we index an indexing array that is being indexed by the indices of k\n",
    "    i = index_map[k_ylist][keep]\n",
    "    j = index_map[k_xlist][keep]\n",
    "    return index_map, keep, anp.stack([i, j])\n",
    "\n",
    "def inverse_permutation(indices):  # reverses an index operation\n",
    "    inverse_perm = np.zeros(len(indices), dtype=anp.int64)\n",
    "    inverse_perm[indices] = np.arange(len(indices), dtype=anp.int64)\n",
    "    return inverse_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50ffd2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_solver(a_entries, a_indices, size, sym_pos):\n",
    "    # a is (usu.) symmetric positive; could solve 2x faster w/sksparse.cholmod.cholesky(a).solve_A\n",
    "    a = scipy.sparse.coo_matrix((a_entries, a_indices), shape=(size,)*2).tocsc()\n",
    "    return scipy.sparse.linalg.splu(a).solve\n",
    "\n",
    "@autograd.primitive\n",
    "def solve_coo(a_entries, a_indices, b, sym_pos=False):\n",
    "    solver = _get_solver(a_entries, a_indices, b.size, sym_pos)\n",
    "    return solver(b)\n",
    "\n",
    "def grad_solve_coo_entries(ans, a_entries, a_indices, b, sym_pos=False):\n",
    "    def jvp(grad_ans):\n",
    "        lambda_ = solve_coo(a_entries, a_indices if sym_pos else a_indices[::-1],\n",
    "                            grad_ans, sym_pos)\n",
    "        i, j = a_indices\n",
    "        return -lambda_[i] * ans[j]\n",
    "    return jvp\n",
    "\n",
    "autograd.extend.defvjp(solve_coo, grad_solve_coo_entries,\n",
    "                       lambda: print('err: gradient undefined'),\n",
    "                       lambda: print('err: gradient not implemented'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092a6ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_stopt(args, x):\n",
    "\n",
    "    reshape = lambda x: x.reshape(args.nely, args.nelx)\n",
    "    objective_fn = lambda x: objective(reshape(x), args)\n",
    "#     constraint = lambda params: mean_density(reshape(params), args) - args.density\n",
    "    constraint = lambda params: mean_density(reshape(params), args) \n",
    "    value = objective_fn(x)\n",
    "    const = constraint(x)\n",
    "    return value, const"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf64004",
   "metadata": {},
   "source": [
    "### RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b745b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, x):\n",
    "        self.flag_ = True\n",
    "        self.n, self.m = x.shape\n",
    "        self.actions_dic={} \n",
    "    \n",
    "        k=0\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.m):\n",
    "                self.actions_dic[k]=(i,j)\n",
    "                k+=1\n",
    "        \n",
    "    def action_space_(self, action, X):\n",
    "        x,y=self.actions_dic[action]\n",
    "        X[x][y]=1\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab97e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(X):  \n",
    "    plt.figure(dpi=50) \n",
    "    print('\\nFinal Cantilever beam design:')\n",
    "    plt.imshow(X) \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cdfaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CantileverEnv(gymnasium.Env):\n",
    "    \n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self,x1,y1):\n",
    "        super().__init__()\n",
    "        self.x0=x1\n",
    "        self.y0=y1\n",
    "        \n",
    "        DIM =  self.x0 * self.y0\n",
    "        N_DISCRETE_ACTIONS = self.x0 * self.y0\n",
    "        \n",
    "        self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS)\n",
    "        self.observation_space = spaces.Box(low=np.array([-1e10 for x in range(DIM)]),\n",
    "                                            high=np.array([1e10 for y in range(DIM)]),\n",
    "                                            shape=(DIM,),\n",
    "                                           dtype=np.float64)\n",
    "        \n",
    " \n",
    "        self.x = np.zeros(( self.x0, self.y0))\n",
    "    \n",
    "        self.M=Model(self.x)\n",
    "        \n",
    "        self.reward=0\n",
    "        self.step_=0\n",
    "        self.needs_reset = True\n",
    "        self.ext_reward=0\n",
    "\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        \n",
    "        self.M.action_space_(action, self.x)        \n",
    "        self.step_+=1\n",
    "               \n",
    "        done=False\n",
    "                  \n",
    "        if self.step_ > 4 * self.x0 * self.y0:\n",
    "            done=True            \n",
    "            \n",
    "        if self.needs_reset:\n",
    "            raise RuntimeError(\"Tried to step environment that needs reset\")\n",
    "            \n",
    "        if done:\n",
    "            self.needs_reset = True\n",
    "                         \n",
    "        \n",
    "        return self.x.reshape(self.x.shape[0]*self.x.shape[1]), self.ext_reward, done, False, dict()\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "                   \n",
    "        self.x = np.zeros((self.x0, self.y0))\n",
    "\n",
    "        self.reward=0\n",
    "        self.needs_reset = False\n",
    "        self.step_=0\n",
    "        self.ext_reward=0\n",
    "\n",
    "        return self.x.reshape(self.x.shape[0]*self.x.shape[1]),{}\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        pass   \n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "638c4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "#             print(y)\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                \n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                \n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
    "                    )\n",
    "\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
    "                    self.model.save(self.save_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c1286a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_3d_structure(xy_plane, yz_plane, xz_plane):\n",
    "    \"\"\"\n",
    "    Reconstructs a 3D structure from three 2D projections using extrusion and intersection.\n",
    "\n",
    "    Parameters:\n",
    "        xy_plane (ndarray): 2D binary array (X by Y) projection in XY plane.\n",
    "        yz_plane (ndarray): 2D binary array (Y by Z) projection in YZ plane.\n",
    "        xz_plane (ndarray): 2D binary array (X by Z) projection in XZ plane.\n",
    "\n",
    "    Returns:\n",
    "        volume (ndarray): 3D binary array (X by Y by Z) representing the reconstructed structure.\n",
    "    \"\"\"\n",
    "    x_dim, y_dim = xy_plane.shape\n",
    "    y_dim2, z_dim = yz_plane.shape\n",
    "    x_dim2, z_dim2 = xz_plane.shape\n",
    "\n",
    "    assert x_dim == x_dim2, \"X dimensions mismatch between XY and XZ planes.\"\n",
    "    assert y_dim == y_dim2, \"Y dimensions mismatch between XY and YZ planes.\"\n",
    "    assert z_dim == z_dim2, \"Z dimensions mismatch between YZ and XZ planes.\"\n",
    "\n",
    "    # Extrude XY along Z\n",
    "    xy_extruded = np.repeat(xy_plane[:, :, np.newaxis], z_dim, axis=2)\n",
    "\n",
    "    # Extrude YZ along X\n",
    "    yz_extruded = np.repeat(yz_plane[np.newaxis, :, :], x_dim, axis=0)\n",
    "\n",
    "    # Extrude XZ along Y\n",
    "    xz_extruded = np.repeat(xz_plane[:, np.newaxis, :], y_dim, axis=1)\n",
    "\n",
    "    # Intersect all three extrusions\n",
    "    volume = xy_extruded & yz_extruded & xz_extruded\n",
    "\n",
    "    return volume.astype(np.uint8)  # or bool, depending on your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1270a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconstruct(topology):\n",
    "    grid = np.zeros((z0*3, z0*3), dtype=int)\n",
    "    for i in range(9):\n",
    "        row_offset = (i // 3) * z0\n",
    "        col_offset = (i % 3) * z0\n",
    "        grid[row_offset:row_offset+z0, col_offset:col_offset+z0] = topology[i]\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b872d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_islands_dfs(grid):\n",
    "    \"\"\"\n",
    "    Calculates the number of islands in a 2D binary grid using Depth First Search (DFS).\n",
    "\n",
    "    An island is formed by connected 1's (horizontally/vertically adjacent).\n",
    "    \n",
    "    Args:\n",
    "        grid (list of lists): A 2D matrix with values 0 or 1.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of islands found.\n",
    "    \"\"\"\n",
    "#     if not grid or not grid[0]:\n",
    "#         return 0\n",
    "    \n",
    "    rows = len(grid)\n",
    "    cols = len(grid[0])\n",
    "    visited = set()\n",
    "    island_count = 0\n",
    "\n",
    "    def dfs(r, c):\n",
    "        \"\"\"Helper function to traverse and mark a single island as visited.\"\"\"\n",
    "        # Check boundary conditions and if the cell has already been visited or is water (0)\n",
    "        if r < 0 or r >= rows or c < 0 or c >= cols or grid[r][c] == 0 or (r, c) in visited:\n",
    "            return\n",
    "        \n",
    "        visited.add((r, c))\n",
    "        \n",
    "        # Recursively visit all adjacent cells (up, down, left, right)\n",
    "        dfs(r + 1, c) # Down\n",
    "        dfs(r - 1, c) # Up\n",
    "        dfs(r, c + 1) # Right\n",
    "        dfs(r, c - 1) # Left\n",
    "\n",
    "    # Iterate through every cell in the grid\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            # If we find land (1) that hasn't been visited yet, \n",
    "            # it means we've found the start of a new island.\n",
    "            if grid[r][c] == 1 and (r, c) not in visited:\n",
    "                island_count += 1\n",
    "                # Start DFS from this point to mark all parts of this island\n",
    "                dfs(r, c)\n",
    "                \n",
    "    return island_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cfae001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smoothness_metric(binary_matrix):\n",
    "    \"\"\"\n",
    "    Calculates a smoothness metric for a 2D binary matrix.\n",
    "    Lower values indicate greater smoothness. A value of 0 means \n",
    "    the image is perfectly uniform or has only linear transitions.\n",
    "\n",
    "    The metric is the sum of differences between a pixel and its\n",
    "    right and bottom neighbors, effectively counting vertical and\n",
    "    horizontal edges.\n",
    "\n",
    "    Args:\n",
    "        binary_matrix (list of lists or numpy array): A 2D matrix \n",
    "                                                     with values 0 or 1.\n",
    "\n",
    "    Returns:\n",
    "        int: The total count of horizontal and vertical transitions.\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array for efficient processing\n",
    "    matrix = np.array(binary_matrix, dtype=int)\n",
    "    h, w = matrix.shape\n",
    "    \n",
    "    # Calculate absolute differences for horizontal transitions\n",
    "    # We slice the matrix to compare each element with its right neighbor\n",
    "    horizontal_diffs = np.abs(matrix[:, :w-1] - matrix[:, 1:])\n",
    "    \n",
    "    # Calculate absolute differences for vertical transitions\n",
    "    # We slice the matrix to compare each element with its bottom neighbor\n",
    "    vertical_diffs = np.abs(matrix[:h-1, :] - matrix[1:, :])\n",
    "    \n",
    "    # The sum of these differences gives the total number of transitions (edges)\n",
    "    total_transitions = np.sum(horizontal_diffs) + np.sum(vertical_diffs)\n",
    "    \n",
    "    return int(total_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1caa50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossRewardEnv(gymnasium.Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.env1 = CantileverEnv(x0,y0)\n",
    "        self.env2 = CantileverEnv(y0,z0)\n",
    "        self.env3 = CantileverEnv(x0,z0)\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'X_projection': self.env1.observation_space,\n",
    "            'Y_projection': self.env2.observation_space,\n",
    "            'Z_projection': self.env3.observation_space,\n",
    "        })\n",
    "\n",
    "        self.action_space = spaces.MultiDiscrete([x0*y0, y0*z0, x0*z0])\n",
    "        self.step1_=0\n",
    "        \n",
    "    def reset(self,seed=0):\n",
    "        obs1, info1 = self.env1.reset()\n",
    "        obs2, info2 = self.env2.reset()\n",
    "        obs3, info3 = self.env3.reset()\n",
    "        self.step1_=0\n",
    "        return {\n",
    "            'X_projection': obs1,\n",
    "            'Y_projection': obs2,\n",
    "            'Z_projection': obs3\n",
    "        }, {\n",
    "            'X_projection': info1,\n",
    "            'Y_projection': info2,\n",
    "            'Z_projection': info3\n",
    "        }\n",
    "\n",
    "    def step(self, action):\n",
    "        a1 = action[0]\n",
    "        a2 = action[1]\n",
    "        a3 = action[2]\n",
    "\n",
    "        obs1_, r1, done1,_, info1 = self.env1.step(a1)\n",
    "        obs2_, r2, done2,_, info2 = self.env2.step(a2)\n",
    "        obs3_, r3, done3,_, info3 = self.env3.step(a3)\n",
    "        obs1 = obs1_.reshape(x0,y0).astype(np.uint8)\n",
    "        obs2 = obs2_.reshape(y0,z0).astype(np.uint8)\n",
    "        obs3 = obs3_.reshape(x0,z0).astype(np.uint8)\n",
    "        topology = reconstruct_3d_structure(obs1, obs2, obs3)\n",
    "        obs1 = obs1_\n",
    "        obs2 = obs2_\n",
    "        obs3 = obs3_\n",
    "        \n",
    "        done11 = False\n",
    "        s_u = np.sum(topology)\n",
    "\n",
    "        if bool(s_u > 0.55*x0*y0*z0):\n",
    "            done11 = True\n",
    "            \n",
    "        if done11:\n",
    "            self.grid = deconstruct(topology)\n",
    "            self.args = get_args(*mbb_beam(rd=-1))\n",
    "            self.tmp, self.const = fast_stopt(self.args, self.grid.astype(float))\n",
    "            self.step1_+=1\n",
    "\n",
    "            reward = 1/self.tmp+1/calculate_smoothness_metric(self.grid.reshape(3*z0, 3*z0))\n",
    "            \n",
    "            if count_islands_dfs(self.grid)==1:\n",
    "                reward*=10\n",
    "                \n",
    "            self.env1.ext_reward=reward\n",
    "            self.env2.ext_reward=reward\n",
    "            self.env3.ext_reward=reward\n",
    "        else:\n",
    "            reward=0\n",
    "            self.env1.ext_reward=0\n",
    "            self.env2.ext_reward=0\n",
    "            self.env3.ext_reward=0\n",
    "        \n",
    "        done = done1 or done2 or done3 or bool(s_u > 0.9*x0*y0*z0)\n",
    "\n",
    "       \n",
    "        return {\n",
    "            'X_projection': obs1,\n",
    "            'Y_projection': obs2,\n",
    "            'Z_projection': obs3\n",
    "        }, reward, done, False, {\n",
    "            'X_projection': info1,\n",
    "            'Y_projection': info2,\n",
    "            'Z_projection': info3,\n",
    "        }\n",
    "\n",
    "    def render(self, mode='human'):    \n",
    "        draw(self.coord, self.elcon,'red')   \n",
    "\n",
    "    def close(self):\n",
    "        self.env1.close()\n",
    "        self.env2.close()\n",
    "        self.env3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc99e1",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aee358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 3e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cfdc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log dir\n",
    "log_dir = \"/tmp/gym7_v3alkkjdjsdkndf/\"\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "897fbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = SaveOnBestTrainingRewardCallback(check_freq=10_000, log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6728425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=CrossRewardEnv()\n",
    "check_env(env)\n",
    "env  = Monitor(env, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25bade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbf827b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 10000\n",
      "Best mean reward: -inf - Last mean reward per episode: 1.09\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 20000\n",
      "Best mean reward: 1.09 - Last mean reward per episode: 1.12\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 30000\n",
      "Best mean reward: 1.12 - Last mean reward per episode: 1.16\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 40000\n",
      "Best mean reward: 1.16 - Last mean reward per episode: 1.17\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 50000\n",
      "Best mean reward: 1.17 - Last mean reward per episode: 1.39\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 60000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.76\n",
      "Num timesteps: 70000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.82\n",
      "Num timesteps: 80000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.91\n",
      "Num timesteps: 90000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.77\n",
      "Num timesteps: 100000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.95\n",
      "Num timesteps: 110000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.82\n",
      "Num timesteps: 120000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.64\n",
      "Num timesteps: 130000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.71\n",
      "Num timesteps: 140000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.71\n",
      "Num timesteps: 150000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.69\n",
      "Num timesteps: 160000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.61\n",
      "Num timesteps: 170000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.48\n",
      "Num timesteps: 180000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.62\n",
      "Num timesteps: 190000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.46\n",
      "Num timesteps: 200000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.53\n",
      "Num timesteps: 210000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.38\n",
      "Num timesteps: 220000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.37\n",
      "Num timesteps: 230000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.47\n",
      "Num timesteps: 240000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.38\n",
      "Num timesteps: 250000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.48\n",
      "Num timesteps: 260000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.44\n",
      "Num timesteps: 270000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.55\n",
      "Num timesteps: 280000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.57\n",
      "Num timesteps: 290000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.58\n",
      "Num timesteps: 300000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.71\n",
      "Num timesteps: 310000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.54\n",
      "Num timesteps: 320000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.48\n",
      "Num timesteps: 330000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.44\n",
      "Num timesteps: 340000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.64\n",
      "Num timesteps: 350000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.47\n",
      "Num timesteps: 360000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.48\n",
      "Num timesteps: 370000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.39\n",
      "Num timesteps: 380000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.33\n",
      "Num timesteps: 390000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.45\n",
      "Num timesteps: 400000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.36\n",
      "Num timesteps: 410000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.46\n",
      "Num timesteps: 420000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.43\n",
      "Num timesteps: 430000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.42\n",
      "Num timesteps: 440000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.39\n",
      "Num timesteps: 450000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.41\n",
      "Num timesteps: 460000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.38\n",
      "Num timesteps: 470000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.34\n",
      "Num timesteps: 480000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.35\n",
      "Num timesteps: 490000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.43\n",
      "Num timesteps: 500000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.40\n",
      "Num timesteps: 510000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.51\n",
      "Num timesteps: 520000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.45\n",
      "Num timesteps: 530000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.38\n",
      "Num timesteps: 540000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.48\n",
      "Num timesteps: 550000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.50\n",
      "Num timesteps: 560000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.53\n",
      "Num timesteps: 570000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.45\n",
      "Num timesteps: 580000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.49\n",
      "Num timesteps: 590000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.37\n",
      "Num timesteps: 600000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.37\n",
      "Num timesteps: 610000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.60\n",
      "Num timesteps: 620000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.53\n",
      "Num timesteps: 630000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.39\n",
      "Num timesteps: 640000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.53\n",
      "Num timesteps: 650000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.50\n",
      "Num timesteps: 660000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.52\n",
      "Num timesteps: 670000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.39\n",
      "Num timesteps: 680000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.50\n",
      "Num timesteps: 690000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.68\n",
      "Num timesteps: 700000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.73\n",
      "Num timesteps: 710000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.75\n",
      "Num timesteps: 720000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.49\n",
      "Num timesteps: 730000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.72\n",
      "Num timesteps: 740000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.61\n",
      "Num timesteps: 750000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.58\n",
      "Num timesteps: 760000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.43\n",
      "Num timesteps: 770000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.53\n",
      "Num timesteps: 780000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.73\n",
      "Num timesteps: 790000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.61\n",
      "Num timesteps: 800000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.72\n",
      "Num timesteps: 810000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.63\n",
      "Num timesteps: 820000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.68\n",
      "Num timesteps: 830000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.72\n",
      "Num timesteps: 840000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.70\n",
      "Num timesteps: 850000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.76\n",
      "Num timesteps: 860000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.46\n",
      "Num timesteps: 870000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.51\n",
      "Num timesteps: 880000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.47\n",
      "Num timesteps: 890000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.62\n",
      "Num timesteps: 900000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.63\n",
      "Num timesteps: 910000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.87\n",
      "Num timesteps: 920000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.61\n",
      "Num timesteps: 930000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.52\n",
      "Num timesteps: 940000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.77\n",
      "Num timesteps: 950000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.03\n",
      "Num timesteps: 960000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 970000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.89\n",
      "Num timesteps: 980000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.02\n",
      "Num timesteps: 990000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.18\n",
      "Num timesteps: 1000000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.81\n",
      "Num timesteps: 1010000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.10\n",
      "Num timesteps: 1020000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.76\n",
      "Num timesteps: 1030000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.83\n",
      "Num timesteps: 1040000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.88\n",
      "Num timesteps: 1050000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.68\n",
      "Num timesteps: 1060000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.59\n",
      "Num timesteps: 1070000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.62\n",
      "Num timesteps: 1080000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.58\n",
      "Num timesteps: 1090000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.61\n",
      "Num timesteps: 1100000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.85\n",
      "Num timesteps: 1110000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.81\n",
      "Num timesteps: 1120000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.70\n",
      "Num timesteps: 1130000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.74\n",
      "Num timesteps: 1140000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.82\n",
      "Num timesteps: 1150000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.80\n",
      "Num timesteps: 1160000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.63\n",
      "Num timesteps: 1170000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.81\n",
      "Num timesteps: 1180000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.90\n",
      "Num timesteps: 1190000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.65\n",
      "Num timesteps: 1200000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.54\n",
      "Num timesteps: 1210000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.04\n",
      "Num timesteps: 1220000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.71\n",
      "Num timesteps: 1230000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.68\n",
      "Num timesteps: 1240000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.85\n",
      "Num timesteps: 1250000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.85\n",
      "Num timesteps: 1260000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.92\n",
      "Num timesteps: 1270000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.89\n",
      "Num timesteps: 1280000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.82\n",
      "Num timesteps: 1290000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.68\n",
      "Num timesteps: 1300000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.71\n",
      "Num timesteps: 1310000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.89\n",
      "Num timesteps: 1320000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.81\n",
      "Num timesteps: 1330000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.82\n",
      "Num timesteps: 1340000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.88\n",
      "Num timesteps: 1350000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.12\n",
      "Num timesteps: 1360000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.19\n",
      "Num timesteps: 1370000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.74\n",
      "Num timesteps: 1380000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.94\n",
      "Num timesteps: 1390000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.91\n",
      "Num timesteps: 1400000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.69\n",
      "Num timesteps: 1410000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.80\n",
      "Num timesteps: 1420000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.59\n",
      "Num timesteps: 1430000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.57\n",
      "Num timesteps: 1440000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.55\n",
      "Num timesteps: 1450000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.37\n",
      "Num timesteps: 1460000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.42\n",
      "Num timesteps: 1470000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.45\n",
      "Num timesteps: 1480000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.58\n",
      "Num timesteps: 1490000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.83\n",
      "Num timesteps: 1500000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.74\n",
      "Num timesteps: 1510000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.03\n",
      "Num timesteps: 1520000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.92\n",
      "Num timesteps: 1530000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.70\n",
      "Num timesteps: 1540000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.82\n",
      "Num timesteps: 1550000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.71\n",
      "Num timesteps: 1560000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.61\n",
      "Num timesteps: 1570000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.79\n",
      "Num timesteps: 1580000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.98\n",
      "Num timesteps: 1590000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.64\n",
      "Num timesteps: 1600000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.56\n",
      "Num timesteps: 1610000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.59\n",
      "Num timesteps: 1620000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.82\n",
      "Num timesteps: 1630000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.57\n",
      "Num timesteps: 1640000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.76\n",
      "Num timesteps: 1650000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.66\n",
      "Num timesteps: 1660000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.07\n",
      "Num timesteps: 1670000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.89\n",
      "Num timesteps: 1680000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.85\n",
      "Num timesteps: 1690000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.97\n",
      "Num timesteps: 1700000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.81\n",
      "Num timesteps: 1710000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.00\n",
      "Num timesteps: 1720000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.79\n",
      "Num timesteps: 1730000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.65\n",
      "Num timesteps: 1740000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.77\n",
      "Num timesteps: 1750000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.58\n",
      "Num timesteps: 1760000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.60\n",
      "Num timesteps: 1770000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.49\n",
      "Num timesteps: 1780000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.93\n",
      "Num timesteps: 1790000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.54\n",
      "Num timesteps: 1800000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.88\n",
      "Num timesteps: 1810000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.77\n",
      "Num timesteps: 1820000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.69\n",
      "Num timesteps: 1830000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.68\n",
      "Num timesteps: 1840000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.55\n",
      "Num timesteps: 1850000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.41\n",
      "Num timesteps: 1860000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.46\n",
      "Num timesteps: 1870000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.50\n",
      "Num timesteps: 1880000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.60\n",
      "Num timesteps: 1890000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.97\n",
      "Num timesteps: 1900000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.90\n",
      "Num timesteps: 1910000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.86\n",
      "Num timesteps: 1920000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.59\n",
      "Num timesteps: 1930000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.75\n",
      "Num timesteps: 1940000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.90\n",
      "Num timesteps: 1950000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 1960000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.80\n",
      "Num timesteps: 1970000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.60\n",
      "Num timesteps: 1980000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.64\n",
      "Num timesteps: 1990000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.79\n",
      "Num timesteps: 2000000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.86\n",
      "Num timesteps: 2010000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.86\n",
      "Num timesteps: 2020000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.81\n",
      "Num timesteps: 2030000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.94\n",
      "Num timesteps: 2040000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.16\n",
      "Num timesteps: 2050000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.20\n",
      "Num timesteps: 2060000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.72\n",
      "Num timesteps: 2070000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.70\n",
      "Num timesteps: 2080000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.96\n",
      "Num timesteps: 2090000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.23\n",
      "Num timesteps: 2100000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.27\n",
      "Num timesteps: 2110000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.21\n",
      "Num timesteps: 2120000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.35\n",
      "Num timesteps: 2130000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.75\n",
      "Num timesteps: 2140000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.70\n",
      "Num timesteps: 2150000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.87\n",
      "Num timesteps: 2160000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.81\n",
      "Num timesteps: 2170000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.80\n",
      "Num timesteps: 2180000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.30\n",
      "Num timesteps: 2190000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.31\n",
      "Num timesteps: 2200000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.89\n",
      "Num timesteps: 2210000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.22\n",
      "Num timesteps: 2220000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.80\n",
      "Num timesteps: 2230000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.76\n",
      "Num timesteps: 2240000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.82\n",
      "Num timesteps: 2250000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.95\n",
      "Num timesteps: 2260000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.82\n",
      "Num timesteps: 2270000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.74\n",
      "Num timesteps: 2280000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.65\n",
      "Num timesteps: 2290000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 0.80\n",
      "Num timesteps: 2300000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.30\n",
      "Num timesteps: 2310000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.30\n",
      "Num timesteps: 2320000\n",
      "Best mean reward: 1.39 - Last mean reward per episode: 1.58\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2330000\n",
      "Best mean reward: 1.58 - Last mean reward per episode: 1.74\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2340000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 0.94\n",
      "Num timesteps: 2350000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.24\n",
      "Num timesteps: 2360000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 0.88\n",
      "Num timesteps: 2370000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.59\n",
      "Num timesteps: 2380000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.07\n",
      "Num timesteps: 2390000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.03\n",
      "Num timesteps: 2400000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.01\n",
      "Num timesteps: 2410000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.48\n",
      "Num timesteps: 2420000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.05\n",
      "Num timesteps: 2430000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.16\n",
      "Num timesteps: 2440000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.30\n",
      "Num timesteps: 2450000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.59\n",
      "Num timesteps: 2460000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.65\n",
      "Num timesteps: 2470000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.36\n",
      "Num timesteps: 2480000\n",
      "Best mean reward: 1.74 - Last mean reward per episode: 1.83\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2490000\n",
      "Best mean reward: 1.83 - Last mean reward per episode: 2.14\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2500000\n",
      "Best mean reward: 2.14 - Last mean reward per episode: 1.24\n",
      "Num timesteps: 2510000\n",
      "Best mean reward: 2.14 - Last mean reward per episode: 2.28\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2520000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 2.02\n",
      "Num timesteps: 2530000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 2.02\n",
      "Num timesteps: 2540000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 1.97\n",
      "Num timesteps: 2550000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 1.70\n",
      "Num timesteps: 2560000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 1.06\n",
      "Num timesteps: 2570000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 2.18\n",
      "Num timesteps: 2580000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 1.29\n",
      "Num timesteps: 2590000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 1.29\n",
      "Num timesteps: 2600000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 1.32\n",
      "Num timesteps: 2610000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 1.38\n",
      "Num timesteps: 2620000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 0.98\n",
      "Num timesteps: 2630000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 1.15\n",
      "Num timesteps: 2640000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 1.69\n",
      "Num timesteps: 2650000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 2.08\n",
      "Num timesteps: 2660000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 2.19\n",
      "Num timesteps: 2670000\n",
      "Best mean reward: 2.28 - Last mean reward per episode: 2.39\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2680000\n",
      "Best mean reward: 2.39 - Last mean reward per episode: 1.82\n",
      "Num timesteps: 2690000\n",
      "Best mean reward: 2.39 - Last mean reward per episode: 1.28\n",
      "Num timesteps: 2700000\n",
      "Best mean reward: 2.39 - Last mean reward per episode: 2.42\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2710000\n",
      "Best mean reward: 2.42 - Last mean reward per episode: 1.67\n",
      "Num timesteps: 2720000\n",
      "Best mean reward: 2.42 - Last mean reward per episode: 1.39\n",
      "Num timesteps: 2730000\n",
      "Best mean reward: 2.42 - Last mean reward per episode: 1.49\n",
      "Num timesteps: 2740000\n",
      "Best mean reward: 2.42 - Last mean reward per episode: 1.48\n",
      "Num timesteps: 2750000\n",
      "Best mean reward: 2.42 - Last mean reward per episode: 1.64\n",
      "Num timesteps: 2760000\n",
      "Best mean reward: 2.42 - Last mean reward per episode: 2.43\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2770000\n",
      "Best mean reward: 2.43 - Last mean reward per episode: 1.85\n",
      "Num timesteps: 2780000\n",
      "Best mean reward: 2.43 - Last mean reward per episode: 1.95\n",
      "Num timesteps: 2790000\n",
      "Best mean reward: 2.43 - Last mean reward per episode: 1.66\n",
      "Num timesteps: 2800000\n",
      "Best mean reward: 2.43 - Last mean reward per episode: 2.36\n",
      "Num timesteps: 2810000\n",
      "Best mean reward: 2.43 - Last mean reward per episode: 2.35\n",
      "Num timesteps: 2820000\n",
      "Best mean reward: 2.43 - Last mean reward per episode: 2.51\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2830000\n",
      "Best mean reward: 2.51 - Last mean reward per episode: 1.79\n",
      "Num timesteps: 2840000\n",
      "Best mean reward: 2.51 - Last mean reward per episode: 2.12\n",
      "Num timesteps: 2850000\n",
      "Best mean reward: 2.51 - Last mean reward per episode: 2.37\n",
      "Num timesteps: 2860000\n",
      "Best mean reward: 2.51 - Last mean reward per episode: 1.85\n",
      "Num timesteps: 2870000\n",
      "Best mean reward: 2.51 - Last mean reward per episode: 2.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 2880000\n",
      "Best mean reward: 2.51 - Last mean reward per episode: 2.45\n",
      "Num timesteps: 2890000\n",
      "Best mean reward: 2.51 - Last mean reward per episode: 2.88\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2900000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 2.36\n",
      "Num timesteps: 2910000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 1.76\n",
      "Num timesteps: 2920000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 2.17\n",
      "Num timesteps: 2930000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 2.36\n",
      "Num timesteps: 2940000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 2.70\n",
      "Num timesteps: 2950000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 2.45\n",
      "Num timesteps: 2960000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 2.29\n",
      "Num timesteps: 2970000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 2.35\n",
      "Num timesteps: 2980000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 1.80\n",
      "Num timesteps: 2990000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 2.32\n",
      "Num timesteps: 3000000\n",
      "Best mean reward: 2.88 - Last mean reward per episode: 2.75\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = PPO(\"MultiInputPolicy\", env).learn(total_timesteps=ts, callback=callback)\n",
    "end = time.time()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d54db1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 59.81947643359502 min\n"
     ]
    }
   ],
   "source": [
    "print('Total time taken: {} min'.format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70fa65c",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2457ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5271ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ea31b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "ans=[]\n",
    "while i < 1000:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, _, info = env.step(action)\n",
    "    ans.append(obs)\n",
    "    if dones:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "294ae712",
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = reconstruct_3d_structure(ans[-1]['X_projection'].astype(np.uint8).reshape(x0,y0), \n",
    "                                    ans[-1]['Y_projection'].astype(np.uint8).reshape(y0,z0),\n",
    "                                    ans[-1]['Z_projection'].astype(np.uint8).reshape(x0,z0))\n",
    "grid = deconstruct(topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfa71f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Cantilever beam design:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7971fc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_plotter.plot_results([log_dir], ts, results_plotter.X_TIMESTEPS, \"CantileverEnv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13338629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5027e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09e787dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0eeb49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = PPO.load(log_dir + \"best_model.zip\", env = env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1f8872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "ans=[]\n",
    "while i<1000:\n",
    "    action, _states = model_best.predict(obs)\n",
    "    obs, rewards, dones, _ , info = env.step(action)\n",
    "    ans.append(obs)\n",
    "    if dones:\n",
    "        break\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6dcae567",
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = reconstruct_3d_structure(ans[-1]['X_projection'].astype(np.uint8).reshape(x0,y0), \n",
    "                                    ans[-1]['Y_projection'].astype(np.uint8).reshape(y0,z0),\n",
    "                                    ans[-1]['Z_projection'].astype(np.uint8).reshape(x0,z0))\n",
    "grid = deconstruct(topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f797343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Cantilever beam design:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f00a6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args(*mbb_beam(rd=-1))\n",
    "tmp, const = fast_stopt(args, grid.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2325c815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.223509741151474"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cdcd2592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7200000000000001"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b77364a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60491e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038bcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
