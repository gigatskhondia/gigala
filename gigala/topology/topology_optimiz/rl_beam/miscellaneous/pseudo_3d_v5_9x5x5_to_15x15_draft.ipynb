{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df9c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795aff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fb0afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import results_plotter\n",
    "import autograd, autograd.core, autograd.extend, autograd.tracer  \n",
    "import autograd.numpy as anp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea66b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0, z0 = 9, 5, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501892d4",
   "metadata": {},
   "source": [
    "### Finite Element Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5ac3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectView(object):\n",
    "    def __init__(self, d): self.__dict__ = d\n",
    "    \n",
    "def get_args(normals, forces, density=1e-4):  # Manage the problem setup parameters\n",
    "    width = normals.shape[0] - 1\n",
    "    height = normals.shape[1] - 1\n",
    "    fixdofs = np.flatnonzero(normals.ravel())\n",
    "    alldofs = np.arange(2 * (width + 1) * (height + 1))\n",
    "    freedofs = np.sort(list(set(alldofs) - set(fixdofs)))\n",
    "    params = {\n",
    "      # material properties\n",
    "      'young': 1, 'young_min': 1e-9, 'poisson': 0.3, 'g': 0,\n",
    "      # constraints\n",
    "      'density': density, 'xmin': 0.001, 'xmax': 1.0,\n",
    "      # input parameters\n",
    "      'nelx': width, 'nely': height, 'mask': 1, 'penal': 3.0, 'filter_width': 1,\n",
    "      'freedofs': freedofs, 'fixdofs': fixdofs, 'forces': forces.ravel(),\n",
    "      # optimization parameters\n",
    "      'opt_steps': 80, 'print_every': 10}\n",
    "#     print(params)\n",
    "    return ObjectView(params)\n",
    "\n",
    "def mbb_beam(width=z0*3, height=z0*3, density=1e-4, y=1, x=0, rd=-1):  # textbook beam example\n",
    "    normals = np.zeros((width + 1, height + 1, 2))\n",
    "    normals[0, 0, x] = 1\n",
    "    normals[0, 0, y] = 1\n",
    "    normals[0, -1, x] = 1\n",
    "    normals[0, -1, y] = 1\n",
    "    forces = np.zeros((width + 1, height + 1, 2))\n",
    "    forces[-1, rd, y] = -1\n",
    "    return normals, forces, density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdaf4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def young_modulus(x, e_0, e_min, p=3):\n",
    "    return e_min + x ** p * (e_0 - e_min)\n",
    "\n",
    "def physical_density(x, args, volume_contraint=False, use_filter=True):\n",
    "    x = args.mask * x.reshape(args.nely, args.nelx)  # reshape from 1D to 2D\n",
    "    return gaussian_filter(x, args.filter_width) if use_filter else x  # maybe filter\n",
    "\n",
    "def mean_density(x, args, volume_contraint=False, use_filter=True):\n",
    "    return anp.mean(physical_density(x, args, volume_contraint, use_filter)) / anp.mean(args.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d0125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, args, volume_contraint=False, use_filter=True):\n",
    "    kwargs = dict(penal=args.penal, e_min=args.young_min, e_0=args.young)\n",
    "    x_phys = physical_density(x, args, volume_contraint=volume_contraint, use_filter=use_filter)\n",
    "    ke     = get_stiffness_matrix(args.young, args.poisson)  # stiffness matrix\n",
    "    u      = displace(x_phys, ke, args.forces, args.freedofs, args.fixdofs, **kwargs)\n",
    "    c      = compliance(x_phys, u, ke, **kwargs)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55484aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@autograd.extend.primitive\n",
    "def gaussian_filter(x, width): # 2D gaussian blur/filter\n",
    "    return scipy.ndimage.gaussian_filter(x, width, mode='reflect')\n",
    "\n",
    "def _gaussian_filter_vjp(ans, x, width): # gives the gradient of orig. function w.r.t. x\n",
    "    del ans, x  # unused\n",
    "    return lambda g: gaussian_filter(g, width)\n",
    "autograd.extend.defvjp(gaussian_filter, _gaussian_filter_vjp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799b9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compliance(x_phys, u, ke, *, penal=3, e_min=1e-9, e_0=1):\n",
    "    nely, nelx = x_phys.shape\n",
    "    ely, elx = anp.meshgrid(range(nely), range(nelx))  # x, y coords for the index map\n",
    "\n",
    "    n1 = (nely+1)*(elx+0) + (ely+0)  # nodes\n",
    "    n2 = (nely+1)*(elx+1) + (ely+0)\n",
    "    n3 = (nely+1)*(elx+1) + (ely+1)\n",
    "    n4 = (nely+1)*(elx+0) + (ely+1)\n",
    "    all_ixs = anp.array([2*n1, 2*n1+1, 2*n2, 2*n2+1, 2*n3, 2*n3+1, 2*n4, 2*n4+1])\n",
    "    u_selected = u[all_ixs]  # select from u matrix\n",
    "\n",
    "    ke_u = anp.einsum('ij,jkl->ikl', ke, u_selected)  # compute x^penal * U.T @ ke @ U\n",
    "    ce = anp.einsum('ijk,ijk->jk', u_selected, ke_u)\n",
    "    C = young_modulus(x_phys, e_0, e_min, p=penal) * ce.T\n",
    "    return anp.sum(C)\n",
    "\n",
    "def get_stiffness_matrix(e, nu):  # e=young's modulus, nu=poisson coefficient\n",
    "    k = anp.array([1/2-nu/6, 1/8+nu/8, -1/4-nu/12, -1/8+3*nu/8,\n",
    "                -1/4+nu/12, -1/8-nu/8, nu/6, 1/8-3*nu/8])\n",
    "    return e/(1-nu**2)*anp.array([[k[0], k[1], k[2], k[3], k[4], k[5], k[6], k[7]],\n",
    "                               [k[1], k[0], k[7], k[6], k[5], k[4], k[3], k[2]],\n",
    "                               [k[2], k[7], k[0], k[5], k[6], k[3], k[4], k[1]],\n",
    "                               [k[3], k[6], k[5], k[0], k[7], k[2], k[1], k[4]],\n",
    "                               [k[4], k[5], k[6], k[7], k[0], k[1], k[2], k[3]],\n",
    "                               [k[5], k[4], k[3], k[2], k[1], k[0], k[7], k[6]],\n",
    "                               [k[6], k[3], k[4], k[1], k[2], k[7], k[0], k[5]],\n",
    "                               [k[7], k[2], k[1], k[4], k[3], k[6], k[5], k[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b6372f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k(stiffness, ke):\n",
    "    # Constructs sparse stiffness matrix k (used in the displace fn)\n",
    "    # First, get position of the nodes of each element in the stiffness matrix\n",
    "    nely, nelx = stiffness.shape\n",
    "    ely, elx = anp.meshgrid(range(nely), range(nelx))  # x, y coords\n",
    "    ely, elx = ely.reshape(-1, 1), elx.reshape(-1, 1)\n",
    "\n",
    "    n1 = (nely+1)*(elx+0) + (ely+0)\n",
    "    n2 = (nely+1)*(elx+1) + (ely+0)\n",
    "    n3 = (nely+1)*(elx+1) + (ely+1)\n",
    "    n4 = (nely+1)*(elx+0) + (ely+1)\n",
    "    edof = anp.array([2*n1, 2*n1+1, 2*n2, 2*n2+1, 2*n3, 2*n3+1, 2*n4, 2*n4+1])\n",
    "    edof = edof.T[0]\n",
    "    x_list = anp.repeat(edof, 8)  # flat list pointer of each node in an element\n",
    "    y_list = anp.tile(edof, 8).flatten()  # flat list pointer of each node in elem\n",
    "\n",
    "    # make the global stiffness matrix K\n",
    "    kd = stiffness.T.reshape(nelx*nely, 1, 1)\n",
    "    value_list = (kd * anp.tile(ke, kd.shape)).flatten()\n",
    "    return value_list, y_list, x_list\n",
    "\n",
    "def displace(x_phys, ke, forces, freedofs, fixdofs, *, penal=3, e_min=1e-9, e_0=1):\n",
    "    # Displaces the load x using finite element techniques (solve_coo=most of runtime)\n",
    "    stiffness = young_modulus(x_phys, e_0, e_min, p=penal)\n",
    "    k_entries, k_ylist, k_xlist = get_k(stiffness, ke)\n",
    "\n",
    "    index_map, keep, indices = _get_dof_indices(freedofs, fixdofs, k_ylist, k_xlist)\n",
    "\n",
    "    u_nonzero = solve_coo(k_entries[keep], indices, forces[freedofs], sym_pos=True)\n",
    "    u_values = anp.concatenate([u_nonzero, anp.zeros(len(fixdofs))])\n",
    "    return u_values[index_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50801294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dof_indices(freedofs, fixdofs, k_xlist, k_ylist):\n",
    "    index_map = inverse_permutation(anp.concatenate([freedofs, fixdofs]))\n",
    "    keep = anp.isin(k_xlist, freedofs) & anp.isin(k_ylist, freedofs)\n",
    "    # Now we index an indexing array that is being indexed by the indices of k\n",
    "    i = index_map[k_ylist][keep]\n",
    "    j = index_map[k_xlist][keep]\n",
    "    return index_map, keep, anp.stack([i, j])\n",
    "\n",
    "def inverse_permutation(indices):  # reverses an index operation\n",
    "    inverse_perm = np.zeros(len(indices), dtype=anp.int64)\n",
    "    inverse_perm[indices] = np.arange(len(indices), dtype=anp.int64)\n",
    "    return inverse_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50ffd2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_solver(a_entries, a_indices, size, sym_pos):\n",
    "    # a is (usu.) symmetric positive; could solve 2x faster w/sksparse.cholmod.cholesky(a).solve_A\n",
    "    a = scipy.sparse.coo_matrix((a_entries, a_indices), shape=(size,)*2).tocsc()\n",
    "    return scipy.sparse.linalg.splu(a).solve\n",
    "\n",
    "@autograd.primitive\n",
    "def solve_coo(a_entries, a_indices, b, sym_pos=False):\n",
    "    solver = _get_solver(a_entries, a_indices, b.size, sym_pos)\n",
    "    return solver(b)\n",
    "\n",
    "def grad_solve_coo_entries(ans, a_entries, a_indices, b, sym_pos=False):\n",
    "    def jvp(grad_ans):\n",
    "        lambda_ = solve_coo(a_entries, a_indices if sym_pos else a_indices[::-1],\n",
    "                            grad_ans, sym_pos)\n",
    "        i, j = a_indices\n",
    "        return -lambda_[i] * ans[j]\n",
    "    return jvp\n",
    "\n",
    "autograd.extend.defvjp(solve_coo, grad_solve_coo_entries,\n",
    "                       lambda: print('err: gradient undefined'),\n",
    "                       lambda: print('err: gradient not implemented'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092a6ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_stopt(args, x):\n",
    "\n",
    "    reshape = lambda x: x.reshape(args.nely, args.nelx)\n",
    "    objective_fn = lambda x: objective(reshape(x), args)\n",
    "#     constraint = lambda params: mean_density(reshape(params), args) - args.density\n",
    "    constraint = lambda params: mean_density(reshape(params), args) \n",
    "    value = objective_fn(x)\n",
    "    const = constraint(x)\n",
    "    return value, const"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf64004",
   "metadata": {},
   "source": [
    "### RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b745b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, x):\n",
    "        self.flag_ = True\n",
    "        self.n, self.m = x.shape\n",
    "        self.actions_dic={} \n",
    "    \n",
    "        k=0\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.m):\n",
    "                self.actions_dic[k]=(i,j)\n",
    "                k+=1\n",
    "        \n",
    "    def action_space_(self, action, X):\n",
    "        x,y=self.actions_dic[action]\n",
    "        X[x][y]=1\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab97e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(X):  \n",
    "    plt.figure(dpi=50) \n",
    "    print('\\nFinal Cantilever beam design:')\n",
    "    plt.imshow(X) \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cdfaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CantileverEnv(gymnasium.Env):\n",
    "    \n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self,x1,y1):\n",
    "        super().__init__()\n",
    "        self.x0=x1\n",
    "        self.y0=y1\n",
    "        \n",
    "        DIM =  self.x0 * self.y0\n",
    "        N_DISCRETE_ACTIONS = self.x0 * self.y0\n",
    "        \n",
    "        self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS)\n",
    "        self.observation_space = spaces.Box(low=np.array([-1e10 for x in range(DIM)]),\n",
    "                                            high=np.array([1e10 for y in range(DIM)]),\n",
    "                                            shape=(DIM,),\n",
    "                                           dtype=np.float64)\n",
    "        \n",
    " \n",
    "        self.x = np.zeros(( self.x0, self.y0))\n",
    "    \n",
    "        self.M=Model(self.x)\n",
    "        \n",
    "        self.reward=0\n",
    "        self.step_=0\n",
    "        self.needs_reset = True\n",
    "        self.ext_reward=0\n",
    "\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        \n",
    "        self.M.action_space_(action, self.x)        \n",
    "        self.step_+=1\n",
    "               \n",
    "        done=False\n",
    "                  \n",
    "        if self.step_ > 1.7 * self.x0 * self.y0:\n",
    "            done=True            \n",
    "            \n",
    "        if self.needs_reset:\n",
    "            raise RuntimeError(\"Tried to step environment that needs reset\")\n",
    "            \n",
    "        if done:\n",
    "            self.needs_reset = True\n",
    "                         \n",
    "        \n",
    "        return self.x.reshape(self.x.shape[0]*self.x.shape[1]), self.ext_reward, done, False, dict()\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "                   \n",
    "        self.x = np.zeros((self.x0, self.y0))\n",
    "\n",
    "        self.reward=0\n",
    "        self.needs_reset = False\n",
    "        self.step_=0\n",
    "        self.ext_reward=0\n",
    "\n",
    "        return self.x.reshape(self.x.shape[0]*self.x.shape[1]),{}\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        pass   \n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "638c4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "#             print(y)\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                \n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                \n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
    "                    )\n",
    "\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
    "                    self.model.save(self.save_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c1286a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_3d_structure(xy_plane, yz_plane, xz_plane):\n",
    "    \"\"\"\n",
    "    Reconstructs a 3D structure from three 2D projections using extrusion and intersection.\n",
    "\n",
    "    Parameters:\n",
    "        xy_plane (ndarray): 2D binary array (X by Y) projection in XY plane.\n",
    "        yz_plane (ndarray): 2D binary array (Y by Z) projection in YZ plane.\n",
    "        xz_plane (ndarray): 2D binary array (X by Z) projection in XZ plane.\n",
    "\n",
    "    Returns:\n",
    "        volume (ndarray): 3D binary array (X by Y by Z) representing the reconstructed structure.\n",
    "    \"\"\"\n",
    "    x_dim, y_dim = xy_plane.shape\n",
    "    y_dim2, z_dim = yz_plane.shape\n",
    "    x_dim2, z_dim2 = xz_plane.shape\n",
    "\n",
    "    assert x_dim == x_dim2, \"X dimensions mismatch between XY and XZ planes.\"\n",
    "    assert y_dim == y_dim2, \"Y dimensions mismatch between XY and YZ planes.\"\n",
    "    assert z_dim == z_dim2, \"Z dimensions mismatch between YZ and XZ planes.\"\n",
    "\n",
    "    # Extrude XY along Z\n",
    "    xy_extruded = np.repeat(xy_plane[:, :, np.newaxis], z_dim, axis=2)\n",
    "\n",
    "    # Extrude YZ along X\n",
    "    yz_extruded = np.repeat(yz_plane[np.newaxis, :, :], x_dim, axis=0)\n",
    "\n",
    "    # Extrude XZ along Y\n",
    "    xz_extruded = np.repeat(xz_plane[:, np.newaxis, :], y_dim, axis=1)\n",
    "\n",
    "    # Intersect all three extrusions\n",
    "    volume = xy_extruded & yz_extruded & xz_extruded\n",
    "\n",
    "    return volume.astype(np.uint8)  # or bool, depending on your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1270a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconstruct(topology):\n",
    "    grid = np.zeros((z0*3, z0*3), dtype=int)\n",
    "    for i in range(9):\n",
    "        row_offset = (i // 3) * z0\n",
    "        col_offset = (i % 3) * z0\n",
    "        grid[row_offset:row_offset+z0, col_offset:col_offset+z0] = topology[i]\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b872d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_islands_dfs(grid):\n",
    "    \"\"\"\n",
    "    Calculates the number of islands in a 2D binary grid using Depth First Search (DFS).\n",
    "\n",
    "    An island is formed by connected 1's (horizontally/vertically adjacent).\n",
    "    \n",
    "    Args:\n",
    "        grid (list of lists): A 2D matrix with values 0 or 1.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of islands found.\n",
    "    \"\"\"\n",
    "#     if not grid or not grid[0]:\n",
    "#         return 0\n",
    "    \n",
    "    rows = len(grid)\n",
    "    cols = len(grid[0])\n",
    "    visited = set()\n",
    "    island_count = 0\n",
    "\n",
    "    def dfs(r, c):\n",
    "        \"\"\"Helper function to traverse and mark a single island as visited.\"\"\"\n",
    "        # Check boundary conditions and if the cell has already been visited or is water (0)\n",
    "        if r < 0 or r >= rows or c < 0 or c >= cols or grid[r][c] == 0 or (r, c) in visited:\n",
    "            return\n",
    "        \n",
    "        visited.add((r, c))\n",
    "        \n",
    "        # Recursively visit all adjacent cells (up, down, left, right)\n",
    "        dfs(r + 1, c) # Down\n",
    "        dfs(r - 1, c) # Up\n",
    "        dfs(r, c + 1) # Right\n",
    "        dfs(r, c - 1) # Left\n",
    "\n",
    "    # Iterate through every cell in the grid\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            # If we find land (1) that hasn't been visited yet, \n",
    "            # it means we've found the start of a new island.\n",
    "            if grid[r][c] == 1 and (r, c) not in visited:\n",
    "                island_count += 1\n",
    "                # Start DFS from this point to mark all parts of this island\n",
    "                dfs(r, c)\n",
    "                \n",
    "    return island_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cfae001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smoothness_metric(binary_matrix):\n",
    "    \"\"\"\n",
    "    Calculates a smoothness metric for a 2D binary matrix.\n",
    "    Lower values indicate greater smoothness. A value of 0 means \n",
    "    the image is perfectly uniform or has only linear transitions.\n",
    "\n",
    "    The metric is the sum of differences between a pixel and its\n",
    "    right and bottom neighbors, effectively counting vertical and\n",
    "    horizontal edges.\n",
    "\n",
    "    Args:\n",
    "        binary_matrix (list of lists or numpy array): A 2D matrix \n",
    "                                                     with values 0 or 1.\n",
    "\n",
    "    Returns:\n",
    "        int: The total count of horizontal and vertical transitions.\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array for efficient processing\n",
    "    matrix = np.array(binary_matrix, dtype=int)\n",
    "    h, w = matrix.shape\n",
    "    \n",
    "    # Calculate absolute differences for horizontal transitions\n",
    "    # We slice the matrix to compare each element with its right neighbor\n",
    "    horizontal_diffs = np.abs(matrix[:, :w-1] - matrix[:, 1:])\n",
    "    \n",
    "    # Calculate absolute differences for vertical transitions\n",
    "    # We slice the matrix to compare each element with its bottom neighbor\n",
    "    vertical_diffs = np.abs(matrix[:h-1, :] - matrix[1:, :])\n",
    "    \n",
    "    # The sum of these differences gives the total number of transitions (edges)\n",
    "    total_transitions = np.sum(horizontal_diffs) + np.sum(vertical_diffs)\n",
    "    \n",
    "    return int(total_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1caa50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossRewardEnv(gymnasium.Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.env1 = CantileverEnv(x0,y0)\n",
    "        self.env2 = CantileverEnv(y0,z0)\n",
    "        self.env3 = CantileverEnv(x0,z0)\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'X_projection': self.env1.observation_space,\n",
    "            'Y_projection': self.env2.observation_space,\n",
    "            'Z_projection': self.env3.observation_space,\n",
    "        })\n",
    "\n",
    "        self.action_space = spaces.MultiDiscrete([x0*y0, y0*z0, x0*z0])\n",
    "        self.step1_=0\n",
    "        \n",
    "    def reset(self,seed=0):\n",
    "        obs1, info1 = self.env1.reset()\n",
    "        obs2, info2 = self.env2.reset()\n",
    "        obs3, info3 = self.env3.reset()\n",
    "        self.step1_=0\n",
    "        return {\n",
    "            'X_projection': obs1,\n",
    "            'Y_projection': obs2,\n",
    "            'Z_projection': obs3\n",
    "        }, {\n",
    "            'X_projection': info1,\n",
    "            'Y_projection': info2,\n",
    "            'Z_projection': info3\n",
    "        }\n",
    "\n",
    "    def step(self, action):\n",
    "        a1 = action[0]\n",
    "        a2 = action[1]\n",
    "        a3 = action[2]\n",
    "\n",
    "        obs1_, r1, done1,_, info1 = self.env1.step(a1)\n",
    "        obs2_, r2, done2,_, info2 = self.env2.step(a2)\n",
    "        obs3_, r3, done3,_, info3 = self.env3.step(a3)\n",
    "        obs1 = obs1_.reshape(x0,y0).astype(np.uint8)\n",
    "        obs2 = obs2_.reshape(y0,z0).astype(np.uint8)\n",
    "        obs3 = obs3_.reshape(x0,z0).astype(np.uint8)\n",
    "        topology = reconstruct_3d_structure(obs1, obs2, obs3)\n",
    "        obs1 = obs1_\n",
    "        obs2 = obs2_\n",
    "        obs3 = obs3_\n",
    "        \n",
    "        done11 = False\n",
    "        s_u = np.sum(topology)\n",
    "\n",
    "        if bool(s_u > 0.2*x0*y0*z0):\n",
    "            done11 = True\n",
    "            \n",
    "        if done11:\n",
    "            self.grid = deconstruct(topology)\n",
    "            self.args = get_args(*mbb_beam(rd=-1))\n",
    "            self.tmp, self.const = fast_stopt(self.args, self.grid)\n",
    "            self.step1_+=1\n",
    "\n",
    "            reward = 1/self.tmp+1/calculate_smoothness_metric(self.grid.reshape(3*z0, 3*z0))\n",
    "            \n",
    "            if count_islands_dfs(self.grid)==1:\n",
    "                reward*=100\n",
    "                \n",
    "            self.env1.ext_reward=reward\n",
    "            self.env2.ext_reward=reward\n",
    "            self.env3.ext_reward=reward\n",
    "        else:\n",
    "            reward=0\n",
    "            self.env1.ext_reward=0\n",
    "            self.env2.ext_reward=0\n",
    "            self.env3.ext_reward=0\n",
    "        \n",
    "        done = done1 or done2 or done3 or bool(s_u > 0.9*x0*y0*z0)\n",
    "\n",
    "       \n",
    "        return {\n",
    "            'X_projection': obs1,\n",
    "            'Y_projection': obs2,\n",
    "            'Z_projection': obs3\n",
    "        }, reward, done, False, {\n",
    "            'X_projection': info1,\n",
    "            'Y_projection': info2,\n",
    "            'Z_projection': info3,\n",
    "        }\n",
    "\n",
    "    def render(self, mode='human'):    \n",
    "        draw(self.coord, self.elcon,'red')   \n",
    "\n",
    "    def close(self):\n",
    "        self.env1.close()\n",
    "        self.env2.close()\n",
    "        self.env3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc99e1",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aee358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 3e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cfdc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log dir\n",
    "log_dir = \"/tmp/gym7_v3alkkjdjsdkndf/\"\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "897fbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = SaveOnBestTrainingRewardCallback(check_freq=10_000, log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6728425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=CrossRewardEnv()\n",
    "check_env(env)\n",
    "env  = Monitor(env, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25bade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbf827b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 10000\n",
      "Best mean reward: -inf - Last mean reward per episode: 0.08\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 20000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 30000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 40000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 50000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 60000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 70000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.07\n",
      "Num timesteps: 80000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.07\n",
      "Num timesteps: 90000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.07\n",
      "Num timesteps: 100000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 110000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 120000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 130000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 140000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 150000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 160000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 170000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 180000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 190000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 200000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 210000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 220000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 230000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 240000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 250000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 260000\n",
      "Best mean reward: 0.08 - Last mean reward per episode: 0.09\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 270000\n",
      "Best mean reward: 0.09 - Last mean reward per episode: 0.08\n",
      "Num timesteps: 280000\n",
      "Best mean reward: 0.09 - Last mean reward per episode: 0.09\n",
      "Num timesteps: 290000\n",
      "Best mean reward: 0.09 - Last mean reward per episode: 0.10\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 300000\n",
      "Best mean reward: 0.10 - Last mean reward per episode: 0.09\n",
      "Num timesteps: 310000\n",
      "Best mean reward: 0.10 - Last mean reward per episode: 0.09\n",
      "Num timesteps: 320000\n",
      "Best mean reward: 0.10 - Last mean reward per episode: 0.09\n",
      "Num timesteps: 330000\n",
      "Best mean reward: 0.10 - Last mean reward per episode: 0.10\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 340000\n",
      "Best mean reward: 0.10 - Last mean reward per episode: 0.11\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 350000\n",
      "Best mean reward: 0.11 - Last mean reward per episode: 0.11\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 360000\n",
      "Best mean reward: 0.11 - Last mean reward per episode: 0.11\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 370000\n",
      "Best mean reward: 0.11 - Last mean reward per episode: 0.12\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 380000\n",
      "Best mean reward: 0.12 - Last mean reward per episode: 0.13\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 390000\n",
      "Best mean reward: 0.13 - Last mean reward per episode: 0.14\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 400000\n",
      "Best mean reward: 0.14 - Last mean reward per episode: 0.16\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 410000\n",
      "Best mean reward: 0.16 - Last mean reward per episode: 0.18\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 420000\n",
      "Best mean reward: 0.18 - Last mean reward per episode: 0.16\n",
      "Num timesteps: 430000\n",
      "Best mean reward: 0.18 - Last mean reward per episode: 0.42\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 440000\n",
      "Best mean reward: 0.42 - Last mean reward per episode: 0.43\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 450000\n",
      "Best mean reward: 0.43 - Last mean reward per episode: 0.62\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 460000\n",
      "Best mean reward: 0.62 - Last mean reward per episode: 0.91\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 470000\n",
      "Best mean reward: 0.91 - Last mean reward per episode: 2.92\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 480000\n",
      "Best mean reward: 2.92 - Last mean reward per episode: 2.40\n",
      "Num timesteps: 490000\n",
      "Best mean reward: 2.92 - Last mean reward per episode: 5.78\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 500000\n",
      "Best mean reward: 5.78 - Last mean reward per episode: 8.95\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 510000\n",
      "Best mean reward: 8.95 - Last mean reward per episode: 11.66\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 520000\n",
      "Best mean reward: 11.66 - Last mean reward per episode: 14.20\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 530000\n",
      "Best mean reward: 14.20 - Last mean reward per episode: 19.77\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 540000\n",
      "Best mean reward: 19.77 - Last mean reward per episode: 24.05\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 550000\n",
      "Best mean reward: 24.05 - Last mean reward per episode: 25.89\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 560000\n",
      "Best mean reward: 25.89 - Last mean reward per episode: 26.82\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 570000\n",
      "Best mean reward: 26.82 - Last mean reward per episode: 40.63\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 580000\n",
      "Best mean reward: 40.63 - Last mean reward per episode: 44.82\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 590000\n",
      "Best mean reward: 44.82 - Last mean reward per episode: 59.87\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 600000\n",
      "Best mean reward: 59.87 - Last mean reward per episode: 67.40\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 610000\n",
      "Best mean reward: 67.40 - Last mean reward per episode: 76.71\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 620000\n",
      "Best mean reward: 76.71 - Last mean reward per episode: 84.15\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 630000\n",
      "Best mean reward: 84.15 - Last mean reward per episode: 92.60\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 640000\n",
      "Best mean reward: 92.60 - Last mean reward per episode: 87.31\n",
      "Num timesteps: 650000\n",
      "Best mean reward: 92.60 - Last mean reward per episode: 90.96\n",
      "Num timesteps: 660000\n",
      "Best mean reward: 92.60 - Last mean reward per episode: 91.01\n",
      "Num timesteps: 670000\n",
      "Best mean reward: 92.60 - Last mean reward per episode: 99.10\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 680000\n",
      "Best mean reward: 99.10 - Last mean reward per episode: 105.66\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 690000\n",
      "Best mean reward: 105.66 - Last mean reward per episode: 103.09\n",
      "Num timesteps: 700000\n",
      "Best mean reward: 105.66 - Last mean reward per episode: 111.67\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 710000\n",
      "Best mean reward: 111.67 - Last mean reward per episode: 111.68\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 720000\n",
      "Best mean reward: 111.68 - Last mean reward per episode: 112.62\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 730000\n",
      "Best mean reward: 112.62 - Last mean reward per episode: 116.44\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 740000\n",
      "Best mean reward: 116.44 - Last mean reward per episode: 111.76\n",
      "Num timesteps: 750000\n",
      "Best mean reward: 116.44 - Last mean reward per episode: 110.00\n",
      "Num timesteps: 760000\n",
      "Best mean reward: 116.44 - Last mean reward per episode: 106.73\n",
      "Num timesteps: 770000\n",
      "Best mean reward: 116.44 - Last mean reward per episode: 113.19\n",
      "Num timesteps: 780000\n",
      "Best mean reward: 116.44 - Last mean reward per episode: 119.20\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 790000\n",
      "Best mean reward: 119.20 - Last mean reward per episode: 113.02\n",
      "Num timesteps: 800000\n",
      "Best mean reward: 119.20 - Last mean reward per episode: 122.59\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 810000\n",
      "Best mean reward: 122.59 - Last mean reward per episode: 109.10\n",
      "Num timesteps: 820000\n",
      "Best mean reward: 122.59 - Last mean reward per episode: 117.86\n",
      "Num timesteps: 830000\n",
      "Best mean reward: 122.59 - Last mean reward per episode: 120.51\n",
      "Num timesteps: 840000\n",
      "Best mean reward: 122.59 - Last mean reward per episode: 118.85\n",
      "Num timesteps: 850000\n",
      "Best mean reward: 122.59 - Last mean reward per episode: 115.91\n",
      "Num timesteps: 860000\n",
      "Best mean reward: 122.59 - Last mean reward per episode: 117.11\n",
      "Num timesteps: 870000\n",
      "Best mean reward: 122.59 - Last mean reward per episode: 123.82\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 880000\n",
      "Best mean reward: 123.82 - Last mean reward per episode: 119.37\n",
      "Num timesteps: 890000\n",
      "Best mean reward: 123.82 - Last mean reward per episode: 120.55\n",
      "Num timesteps: 900000\n",
      "Best mean reward: 123.82 - Last mean reward per episode: 120.90\n",
      "Num timesteps: 910000\n",
      "Best mean reward: 123.82 - Last mean reward per episode: 124.48\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 920000\n",
      "Best mean reward: 124.48 - Last mean reward per episode: 123.81\n",
      "Num timesteps: 930000\n",
      "Best mean reward: 124.48 - Last mean reward per episode: 122.54\n",
      "Num timesteps: 940000\n",
      "Best mean reward: 124.48 - Last mean reward per episode: 123.66\n",
      "Num timesteps: 950000\n",
      "Best mean reward: 124.48 - Last mean reward per episode: 122.54\n",
      "Num timesteps: 960000\n",
      "Best mean reward: 124.48 - Last mean reward per episode: 119.99\n",
      "Num timesteps: 970000\n",
      "Best mean reward: 124.48 - Last mean reward per episode: 124.72\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 980000\n",
      "Best mean reward: 124.72 - Last mean reward per episode: 125.48\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 990000\n",
      "Best mean reward: 125.48 - Last mean reward per episode: 122.05\n",
      "Num timesteps: 1000000\n",
      "Best mean reward: 125.48 - Last mean reward per episode: 115.78\n",
      "Num timesteps: 1010000\n",
      "Best mean reward: 125.48 - Last mean reward per episode: 124.85\n",
      "Num timesteps: 1020000\n",
      "Best mean reward: 125.48 - Last mean reward per episode: 122.80\n",
      "Num timesteps: 1030000\n",
      "Best mean reward: 125.48 - Last mean reward per episode: 122.40\n",
      "Num timesteps: 1040000\n",
      "Best mean reward: 125.48 - Last mean reward per episode: 119.32\n",
      "Num timesteps: 1050000\n",
      "Best mean reward: 125.48 - Last mean reward per episode: 124.03\n",
      "Num timesteps: 1060000\n",
      "Best mean reward: 125.48 - Last mean reward per episode: 124.77\n",
      "Num timesteps: 1070000\n",
      "Best mean reward: 125.48 - Last mean reward per episode: 131.85\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1080000\n",
      "Best mean reward: 131.85 - Last mean reward per episode: 129.21\n",
      "Num timesteps: 1090000\n",
      "Best mean reward: 131.85 - Last mean reward per episode: 133.48\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1100000\n",
      "Best mean reward: 133.48 - Last mean reward per episode: 133.17\n",
      "Num timesteps: 1110000\n",
      "Best mean reward: 133.48 - Last mean reward per episode: 134.25\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1120000\n",
      "Best mean reward: 134.25 - Last mean reward per episode: 128.28\n",
      "Num timesteps: 1130000\n",
      "Best mean reward: 134.25 - Last mean reward per episode: 129.85\n",
      "Num timesteps: 1140000\n",
      "Best mean reward: 134.25 - Last mean reward per episode: 135.50\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1150000\n",
      "Best mean reward: 135.50 - Last mean reward per episode: 126.19\n",
      "Num timesteps: 1160000\n",
      "Best mean reward: 135.50 - Last mean reward per episode: 133.93\n",
      "Num timesteps: 1170000\n",
      "Best mean reward: 135.50 - Last mean reward per episode: 137.24\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1180000\n",
      "Best mean reward: 137.24 - Last mean reward per episode: 133.85\n",
      "Num timesteps: 1190000\n",
      "Best mean reward: 137.24 - Last mean reward per episode: 136.46\n",
      "Num timesteps: 1200000\n",
      "Best mean reward: 137.24 - Last mean reward per episode: 133.43\n",
      "Num timesteps: 1210000\n",
      "Best mean reward: 137.24 - Last mean reward per episode: 133.98\n",
      "Num timesteps: 1220000\n",
      "Best mean reward: 137.24 - Last mean reward per episode: 137.69\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1230000\n",
      "Best mean reward: 137.69 - Last mean reward per episode: 145.78\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1240000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 142.03\n",
      "Num timesteps: 1250000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 138.39\n",
      "Num timesteps: 1260000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 133.73\n",
      "Num timesteps: 1270000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 139.09\n",
      "Num timesteps: 1280000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 138.89\n",
      "Num timesteps: 1290000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 142.70\n",
      "Num timesteps: 1300000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 145.41\n",
      "Num timesteps: 1310000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 140.04\n",
      "Num timesteps: 1320000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 138.15\n",
      "Num timesteps: 1330000\n",
      "Best mean reward: 145.78 - Last mean reward per episode: 146.35\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1340000\n",
      "Best mean reward: 146.35 - Last mean reward per episode: 144.62\n",
      "Num timesteps: 1350000\n",
      "Best mean reward: 146.35 - Last mean reward per episode: 147.47\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1360000\n",
      "Best mean reward: 147.47 - Last mean reward per episode: 146.86\n",
      "Num timesteps: 1370000\n",
      "Best mean reward: 147.47 - Last mean reward per episode: 148.07\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1380000\n",
      "Best mean reward: 148.07 - Last mean reward per episode: 140.60\n",
      "Num timesteps: 1390000\n",
      "Best mean reward: 148.07 - Last mean reward per episode: 143.36\n",
      "Num timesteps: 1400000\n",
      "Best mean reward: 148.07 - Last mean reward per episode: 144.89\n",
      "Num timesteps: 1410000\n",
      "Best mean reward: 148.07 - Last mean reward per episode: 144.58\n",
      "Num timesteps: 1420000\n",
      "Best mean reward: 148.07 - Last mean reward per episode: 143.18\n",
      "Num timesteps: 1430000\n",
      "Best mean reward: 148.07 - Last mean reward per episode: 146.85\n",
      "Num timesteps: 1440000\n",
      "Best mean reward: 148.07 - Last mean reward per episode: 148.51\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1450000\n",
      "Best mean reward: 148.51 - Last mean reward per episode: 141.85\n",
      "Num timesteps: 1460000\n",
      "Best mean reward: 148.51 - Last mean reward per episode: 149.20\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1470000\n",
      "Best mean reward: 149.20 - Last mean reward per episode: 144.82\n",
      "Num timesteps: 1480000\n",
      "Best mean reward: 149.20 - Last mean reward per episode: 150.13\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 1490000\n",
      "Best mean reward: 150.13 - Last mean reward per episode: 148.57\n",
      "Num timesteps: 1500000\n",
      "Best mean reward: 150.13 - Last mean reward per episode: 143.29\n",
      "Num timesteps: 1510000\n",
      "Best mean reward: 150.13 - Last mean reward per episode: 153.29\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1520000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 152.82\n",
      "Num timesteps: 1530000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 150.21\n",
      "Num timesteps: 1540000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 146.93\n",
      "Num timesteps: 1550000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 152.00\n",
      "Num timesteps: 1560000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 146.13\n",
      "Num timesteps: 1570000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 149.32\n",
      "Num timesteps: 1580000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 148.10\n",
      "Num timesteps: 1590000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 148.13\n",
      "Num timesteps: 1600000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 152.07\n",
      "Num timesteps: 1610000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 151.07\n",
      "Num timesteps: 1620000\n",
      "Best mean reward: 153.29 - Last mean reward per episode: 154.88\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1630000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 154.00\n",
      "Num timesteps: 1640000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 146.55\n",
      "Num timesteps: 1650000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 154.38\n",
      "Num timesteps: 1660000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 153.90\n",
      "Num timesteps: 1670000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 135.72\n",
      "Num timesteps: 1680000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 152.53\n",
      "Num timesteps: 1690000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 154.08\n",
      "Num timesteps: 1700000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 152.44\n",
      "Num timesteps: 1710000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 148.09\n",
      "Num timesteps: 1720000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 149.18\n",
      "Num timesteps: 1730000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 154.19\n",
      "Num timesteps: 1740000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 153.76\n",
      "Num timesteps: 1750000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 149.41\n",
      "Num timesteps: 1760000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 150.74\n",
      "Num timesteps: 1770000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 150.82\n",
      "Num timesteps: 1780000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 145.23\n",
      "Num timesteps: 1790000\n",
      "Best mean reward: 154.88 - Last mean reward per episode: 155.41\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1800000\n",
      "Best mean reward: 155.41 - Last mean reward per episode: 150.66\n",
      "Num timesteps: 1810000\n",
      "Best mean reward: 155.41 - Last mean reward per episode: 148.55\n",
      "Num timesteps: 1820000\n",
      "Best mean reward: 155.41 - Last mean reward per episode: 156.53\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1830000\n",
      "Best mean reward: 156.53 - Last mean reward per episode: 153.32\n",
      "Num timesteps: 1840000\n",
      "Best mean reward: 156.53 - Last mean reward per episode: 155.18\n",
      "Num timesteps: 1850000\n",
      "Best mean reward: 156.53 - Last mean reward per episode: 150.71\n",
      "Num timesteps: 1860000\n",
      "Best mean reward: 156.53 - Last mean reward per episode: 151.77\n",
      "Num timesteps: 1870000\n",
      "Best mean reward: 156.53 - Last mean reward per episode: 154.88\n",
      "Num timesteps: 1880000\n",
      "Best mean reward: 156.53 - Last mean reward per episode: 152.66\n",
      "Num timesteps: 1890000\n",
      "Best mean reward: 156.53 - Last mean reward per episode: 154.00\n",
      "Num timesteps: 1900000\n",
      "Best mean reward: 156.53 - Last mean reward per episode: 156.82\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1910000\n",
      "Best mean reward: 156.82 - Last mean reward per episode: 152.67\n",
      "Num timesteps: 1920000\n",
      "Best mean reward: 156.82 - Last mean reward per episode: 152.59\n",
      "Num timesteps: 1930000\n",
      "Best mean reward: 156.82 - Last mean reward per episode: 151.25\n",
      "Num timesteps: 1940000\n",
      "Best mean reward: 156.82 - Last mean reward per episode: 154.66\n",
      "Num timesteps: 1950000\n",
      "Best mean reward: 156.82 - Last mean reward per episode: 157.41\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 1960000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 154.12\n",
      "Num timesteps: 1970000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 155.25\n",
      "Num timesteps: 1980000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 155.06\n",
      "Num timesteps: 1990000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 154.13\n",
      "Num timesteps: 2000000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 152.95\n",
      "Num timesteps: 2010000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 155.06\n",
      "Num timesteps: 2020000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 150.35\n",
      "Num timesteps: 2030000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 155.44\n",
      "Num timesteps: 2040000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 149.36\n",
      "Num timesteps: 2050000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 155.69\n",
      "Num timesteps: 2060000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 149.29\n",
      "Num timesteps: 2070000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 154.02\n",
      "Num timesteps: 2080000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 155.24\n",
      "Num timesteps: 2090000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 151.72\n",
      "Num timesteps: 2100000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 154.29\n",
      "Num timesteps: 2110000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 154.88\n",
      "Num timesteps: 2120000\n",
      "Best mean reward: 157.41 - Last mean reward per episode: 157.88\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2130000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 156.18\n",
      "Num timesteps: 2140000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 157.24\n",
      "Num timesteps: 2150000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 156.31\n",
      "Num timesteps: 2160000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 156.54\n",
      "Num timesteps: 2170000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 155.72\n",
      "Num timesteps: 2180000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 154.07\n",
      "Num timesteps: 2190000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 152.89\n",
      "Num timesteps: 2200000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 152.29\n",
      "Num timesteps: 2210000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 157.53\n",
      "Num timesteps: 2220000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 154.59\n",
      "Num timesteps: 2230000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 154.53\n",
      "Num timesteps: 2240000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 156.47\n",
      "Num timesteps: 2250000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 154.44\n",
      "Num timesteps: 2260000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 152.76\n",
      "Num timesteps: 2270000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 157.65\n",
      "Num timesteps: 2280000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 156.71\n",
      "Num timesteps: 2290000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 156.48\n",
      "Num timesteps: 2300000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 154.94\n",
      "Num timesteps: 2310000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 148.76\n",
      "Num timesteps: 2320000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 156.77\n",
      "Num timesteps: 2330000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 154.35\n",
      "Num timesteps: 2340000\n",
      "Best mean reward: 157.88 - Last mean reward per episode: 158.13\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2350000\n",
      "Best mean reward: 158.13 - Last mean reward per episode: 153.29\n",
      "Num timesteps: 2360000\n",
      "Best mean reward: 158.13 - Last mean reward per episode: 157.47\n",
      "Num timesteps: 2370000\n",
      "Best mean reward: 158.13 - Last mean reward per episode: 155.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 2380000\n",
      "Best mean reward: 158.13 - Last mean reward per episode: 153.29\n",
      "Num timesteps: 2390000\n",
      "Best mean reward: 158.13 - Last mean reward per episode: 156.25\n",
      "Num timesteps: 2400000\n",
      "Best mean reward: 158.13 - Last mean reward per episode: 158.29\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2410000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 153.71\n",
      "Num timesteps: 2420000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 154.71\n",
      "Num timesteps: 2430000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 150.30\n",
      "Num timesteps: 2440000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 154.76\n",
      "Num timesteps: 2450000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 156.82\n",
      "Num timesteps: 2460000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 153.13\n",
      "Num timesteps: 2470000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 156.41\n",
      "Num timesteps: 2480000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 155.00\n",
      "Num timesteps: 2490000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 152.71\n",
      "Num timesteps: 2500000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 156.47\n",
      "Num timesteps: 2510000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 155.77\n",
      "Num timesteps: 2520000\n",
      "Best mean reward: 158.29 - Last mean reward per episode: 158.65\n",
      "Saving new best model to /tmp/gym7_v3alkkjdjsdkndf/best_model.zip\n",
      "Num timesteps: 2530000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 153.41\n",
      "Num timesteps: 2540000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.06\n",
      "Num timesteps: 2550000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 156.78\n",
      "Num timesteps: 2560000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.35\n",
      "Num timesteps: 2570000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.95\n",
      "Num timesteps: 2580000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.18\n",
      "Num timesteps: 2590000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 156.59\n",
      "Num timesteps: 2600000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.06\n",
      "Num timesteps: 2610000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.29\n",
      "Num timesteps: 2620000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.94\n",
      "Num timesteps: 2630000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.59\n",
      "Num timesteps: 2640000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 156.95\n",
      "Num timesteps: 2650000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.24\n",
      "Num timesteps: 2660000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 156.82\n",
      "Num timesteps: 2670000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.47\n",
      "Num timesteps: 2680000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.48\n",
      "Num timesteps: 2690000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 156.88\n",
      "Num timesteps: 2700000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.53\n",
      "Num timesteps: 2710000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.41\n",
      "Num timesteps: 2720000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.00\n",
      "Num timesteps: 2730000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.29\n",
      "Num timesteps: 2740000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.37\n",
      "Num timesteps: 2750000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.65\n",
      "Num timesteps: 2760000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.00\n",
      "Num timesteps: 2770000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.59\n",
      "Num timesteps: 2780000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.41\n",
      "Num timesteps: 2790000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.18\n",
      "Num timesteps: 2800000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 156.06\n",
      "Num timesteps: 2810000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.42\n",
      "Num timesteps: 2820000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.41\n",
      "Num timesteps: 2830000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.59\n",
      "Num timesteps: 2840000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.18\n",
      "Num timesteps: 2850000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.54\n",
      "Num timesteps: 2860000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.53\n",
      "Num timesteps: 2870000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.54\n",
      "Num timesteps: 2880000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.47\n",
      "Num timesteps: 2890000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.47\n",
      "Num timesteps: 2900000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.06\n",
      "Num timesteps: 2910000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.35\n",
      "Num timesteps: 2920000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 153.24\n",
      "Num timesteps: 2930000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 152.24\n",
      "Num timesteps: 2940000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 157.12\n",
      "Num timesteps: 2950000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 153.88\n",
      "Num timesteps: 2960000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 156.53\n",
      "Num timesteps: 2970000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.35\n",
      "Num timesteps: 2980000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 153.77\n",
      "Num timesteps: 2990000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 158.47\n",
      "Num timesteps: 3000000\n",
      "Best mean reward: 158.65 - Last mean reward per episode: 155.59\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = PPO(\"MultiInputPolicy\", env).learn(total_timesteps=ts, callback=callback)\n",
    "end = time.time()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d54db1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 93.8705025156339 min\n"
     ]
    }
   ],
   "source": [
    "print('Total time taken: {} min'.format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70fa65c",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2457ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5271ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ea31b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "ans=[]\n",
    "while i < 1000:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, _, info = env.step(action)\n",
    "    ans.append(obs)\n",
    "    if dones:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "294ae712",
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = reconstruct_3d_structure(ans[-1]['X_projection'].astype(np.uint8).reshape(x0,y0), \n",
    "                                    ans[-1]['Y_projection'].astype(np.uint8).reshape(y0,z0),\n",
    "                                    ans[-1]['Z_projection'].astype(np.uint8).reshape(x0,z0))\n",
    "grid = deconstruct(topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfa71f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Cantilever beam design:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7971fc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAC+CAYAAACoGZm5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/HklEQVR4nO2dB3wU1fbHT3ovQBISeu8IiFLt6MP6LIi9P32INEWxPp//p8+uWFEsT+wiCNi7AiogKl16RyAQWoD0hOz/87vJHe7ezOzObEl2k/P9fJLdnZ2Ze+fO7Mw99/7OOREul8tFDMMwDMMwDMMwfhDpz8YMwzAMwzAMwzCADQuGYRiGYRiGYfyGDQuGYRiGYRiGYfyGDQuGYRiGYRiGYfyGDQuGYRiGYRiGYfyGDQuGYRiGYRiGYfyGDQuGYRiGYRiGYfyGDQuGYRiGYRiGYfyGDQuGYRiGYRiGYfyGDQuGYRgmYJxyyiniT7JlyxaKiIigN998s07rxTAMwwQfNiwYhmHCmI0bN9KIESOoXbt2FB8fT6mpqTR48GB67rnnqLi4OChlrlq1iv7v//5PGA31hTlz5ggDyOpv6tSpdV1FhmGYkCe6rivAMAzD+MYXX3xBw4cPp7i4OLrmmmuoR48eVFZWRr/88gtNmDCBVq5cSa+++mpQDIv//Oc/YmaiTZs2bt99++23FM6MHTuWjj/++BrLBw4cWCf1YRiGCSfYsGAYhglDNm/eTJdddhm1bt2afvzxR8rJyTG+GzVqFG3YsEEYHrVNbGwshRMlJSVudT7xxBPp4osvrtM6MQzDhCsshWIYhglDnnjiCSooKKD//e9/bkaFpEOHDjRu3DjxfsqUKXTaaadRVlaWmN3o1q0bvfzyyzW2wezDueeeK2Y8+vXrJ6RVkFi9/fbbxjrwlcAsCTj11FMNqRCkRGY+FlasWbNGdOAbN24syjnuuOPo008/Nb7/448/xH7feuutGtt+88034rvPP//cWLZjxw664YYbqGnTpuIYu3fvTm+88Yap3Amypn/961/UvHlzSkxMpEOHDpETsI/Ro0fTxx9/LGaJZHlff/21sc5HH30k1ps7d26N7V955RXx3Z9//umoXIZhmFCHZywYhmHCkM8++0x0+gcNGuR1XRgR6Pj+/e9/p+joaLHtLbfcQpWVlWJ2QwUzHejw/+Mf/6Brr71WdM6vu+466tu3r9jHSSedJORCzz//PN17773UtWtXsZ18tQMkWvADQcf+7rvvpqSkJJo2bRpdcMEFNGPGDLrwwguFoYHjw3LUQ+XDDz+kRo0a0dChQ8Xn3bt304ABA4wOf2ZmJn311VfiGGA03HrrrW7bP/TQQ2KW4o477qDS0lK3GYvDhw/T3r17a9S5SZMmYv8SGF8zZ84U7ZiSkiLaY9iwYbRt2zax7jnnnEPJycmi/ieffHKN+qMtYZQwDMPUK1wMwzBMWHHw4EEXbt/nn3++rfWLiopqLBs6dKirXbt2bstat24t9vvTTz8Zy/Ly8lxxcXGu22+/3Vg2ffp0sd7s2bNr7Pfkk08Wf5LNmzeLdadMmWIsGzJkiKtnz56ukpISY1llZaVr0KBBro4dOxrL7rnnHldMTIxr//79xrLS0lJXenq664YbbjCW/eMf/3Dl5OS49u7d61aXyy67zJWWlmYcP+qLuuC49TaR31n95ebmGuvic2xsrGvDhg3GsmXLlonlL7zwgrHs8ssvd2VlZbkqKiqMZdhPZGSk68EHH6zRdgzDMOEOS6EYhmHCDCndwUi5HRISEoz3Bw8eFCPyGEXftGmT+KwCmRT8DCQY/e/cubNYNxDs379f+IRccsklxuwA/vbt2ydmINavXy9kTeDSSy+l8vJyMTOgOofn5+eL7wD6+ZjlOO+888R7uT/8YX84vsWLF7vVATMgapuo/Pvf/6bvvvuuxh8kWyqnn346tW/f3vh8zDHHiIhcajuhjnl5eYZMTEqkMFMk688wDFOfYCkUwzBMmIEOLEDH3A7z5s2jBx54gBYsWEBFRUVu36HjnZaWZnxu1apVje0hOzpw4AAFAkitYADcf//94s8MdMYhk+rVqxd16dJFSIcgawJ4n5GRIXxGwJ49e4ShgehXVhGwsD+Vtm3bWtavZ8+ewmjwhp12OvPMM0Xbos5Dhgwx6t+7d2/q1KmT1zIYhmHCDTYsGIZhwtCwaNasmS3nX+S5QKcWHfSJEydSy5YthU/Bl19+Sc8884wYPVeJiooy3U+VAsh/ZHnwb5A+EmaO5xKM7D/88MNiBgIzNHDwvvzyy4WviLq/q666qoYvhjqboGI1W+EEO+0Ep274jcyaNYteeukl4QsCI++RRx7xu3yGYZhQhA0LhmGYMATRmzBCj1kITzkW4KgNB2V0yNVR9tmzZ/tcturE7BQ4ZIOYmBhbMwMwLJAzA3InRHyCDAxhdlWpFgyOI0eO2NpfbYP6I7LVDz/8QKtXrxaGB8ugGIapr7CPBcMwTBhy5513imhKN954oxgJN5upQPZtObKujqRD/oQQtL6CcgEkSE5ByFuEo0XI1dzc3BrfQ9qkgmhTkCdBQoQ/hNZFZCoJjg/RmGB4mM3g6PurbWDswD9D1h9hfD1JsRiGYcIZnrFgGIYJQ+A4/P7774vRb3S+1czb8+fPp+nTp4swsePHjxfSJzg3jxgxQuS+eO2110QH36xjbwf4CKBD//jjjwsjBZIfmSfDDpMmTaITTjhBGAw33XSTmMWAcYTZl+3bt9OyZcvc1scxwqka+S7gaxEZ6T4m9thjj4kZmP79+4v9wQEdTuJw2v7+++/Fe7v8/PPPImmemZxKl1TZATMzF110kcidUVhYSE899ZTjfTAMw4QLbFgwDMOEKchLsXz5cnryySfpk08+Efkq0MlHB/jpp58WnWx8RiQiJISDX0N2djaNHDlSSIiQUM4XsI/JkyfTo48+Kjr6kCGhY2/XsEDHHwnwIHFCwj1EhMK2ffr0EQaEDgwL1B+O52YyIkikfvvtN3rwwQdFBCn4MyCXBHJFwPhxAvJRmAHnd18MC1n/119/XUjIEA2LYRimvhKBmLN1XQmGYRiGYRiGYcIb9rFgGIZhGIZhGKbuDQtMgS9dujRgMc4ZhmEYhmEYhmkAhsWtt95K//vf/wyjAtlbjz32WBEbXc0uyjAMwzAMwzBMw8GxYQEnQGRDlfHRN2/eTGvWrKHbbruN7rvvvmDUkWEYhmEYhmGY+mZYIPspIoIAZG4dPnw4derUSUQXWbFiRTDqyDAMwzAMwzBMfTMsENZv1apVQgb19ddf0xlnnCGWIwygTMTEMAzDMAzDMEzDwnEei+uvv17E4Ub2U8TkRlZRsHDhQurSpQuFI5WVlbRz505KSUkRx8QwDMMwDMMwDBEyUxw+fJiaNWtWI0Gp34bF//3f/4nsrn/99ZeQQSH5EsBsxd13303hCIwKOJ8zDMMwDMMwDFMT9P1btGhBnuAEeUR08OBBSk9PFw2Wmppa19VhGIZhGIZhmJDg0KFDYgA+Pz+f0tLS/J+xeP75520XPnbsWAo3pPwJRgUbFgzDMAzDMAzjjh13AVszFm3btnX7vGfPHuGsjVF+AAsmMTGRsrKyaNOmTRSOlhgsMMxcsGHBMOFJxZFK2ra/iFo1TqToKL9zfzIMwzAMQ876ybaevshVIf8efvhh6t27N61evZr2798v/vAeSfIeeuihQB0DwzBh3MHftKdAvNZmmRe9NJ9Oe3queK3NskOpHRpCXUP5uGR5JWUVluXW17ZmqsC5n7s2T7wy5vBvoH7j2Meiffv2Iklenz593JYvWrSILr74YmF8hBs8Y8E0ZAI50i87+Mt3HKRjmqfRzFsGieVy/1bv1XJ9qQ8eUjAqJN/ddhJFRUbU2eyFWTuE6ixKONU1lI9LLS8hJoqKy4/UKLe+tjVTBYyJPg99L849roEl959O8bGOY+TUa/g3EJ446Sc7vuJzc3OpoqKmJY68Frt373a6O4ZhagGrzrqvN3mr/WEZ9gXwunlvId0+bZl43yMnhUqPuGh9XgF1zEyiuJgo+nPnIbdysd8LJ82jFTsPifWfuawPtc1IEg/sL1bsoqHds2h/UUWNcvEZ+0E5PZun0m0fLhX77tkslWaNGlzrDy69HfC5XWYyhSLhVNdQPi61PHQszcqtr23NVLFw837j3OMVn0/unFXX1Qop+DdQ/3FsWAwZMoRGjBhBr7/+upA/ydmKkSNHGjktGIYJHnqn3tsIv2o8oKM98dLeorOOdfWb/LwNe2lwhwyPHXFPxojewd9+4Oj+/8w9bOxj/Z5C4736cIEhAqNCrn/GMz9Rt6ZJtHp3IWFq9a6ZVdugjGkjBtCWfUWUe7CYBrZrIuqB/ZRVVNKZz/0s1sO+sM+OTVM8tmGgUdvhmBZpxgxNKBJOdQ3l41LLM2YstHLra1szVfRv29g493jFZ8Yd/g3UfxxLoeC4fe2114qs2zExMWIZZjCGDh1Kb775pnDgDjdYCsWEAmpnF1i9l536TplJ9OTwXjRhxnJat7vAVHqETrMuEwLSwGjZKIGGv/IrrfAg31Dr1iwtnhZs2kfXv/mH8d3jF/Wkc3pmU+6hUvEZ+0SHf+zUJaJesVERVHbE+jYDA2TWLVWzCut3VxkTdmjdKJ62HigR7+OiI2nRfUMoOSGWVu88SGc9/4ubLConNU7MeKCeKOf8SfNo7e4C0Q4Pnt9DaKIHd2hC+4vKqbS8kv7aW0h/7jpAnTNSKLewhNqkJ1FsTBRlpcZTRSXRpr0FdGrnTIqOiqLl2/OpVaMEev/3rZQQG0WdmiQTrKClu/fRn1sPU8/WaZSeEEPLtuZTy8wkKiopp30F5TSofRNa/lc+tclOos078mlDXiklxkVQQjRR7kEXJcQRJcYQFZUTpSXGUE6jBCotLaMd+0uo+AhR0ySitQeqjjGi+g935CgiKrJos3bpUXTo0BHaq0ibI6pHmMpttTrDMAzT0KgsLaK/nr3EVj/ZkWGBVZHrITMzk7Zv3y6ctgEybnfq1InCFTYsmLoEnXaMqo+ftkx08GEwoBMrpTwUEWEsn3BmF7rpnUWW+0InWkqP1FF92cnXwf4rXS5aqcwmgEcv7EEX9mkuOuEb8gpozAeLaX1eIcVGEpV58bfr0SxVzBqsy6tZnoo0OLrnpNAdQzuLWQeUd/ZzP3vdNiYqgso1Y6VN4wT6fMwJdNHL82ldXqFRl3f/cTz1eegHMeMBOmQl0Ybq7xmGYRiGqSPDorKykuLj42nlypXUsWNHqi+wYcHUFaqsyC6xUURlVTJeNzo1TaZJVxzrNuLfKSvJ6GS3TIujiMgI2lY9yu+N+OhIapeRSKt2ee7kBwoc18yRg6hFowTq98iPwujA6Lt6qBOH96Knv1tLO/LNj6F5erzbd69f05f2HC6le2b9WQtHwDAMwzAN27Bw5GMRGRkpDIp9+/bVK8OCYeoK1cfBjI6ZibQVfgNK79rMqABjT+0oZE8dMpNow55C6qgYFeCvg1VSJZXoCKIKi6GFkopKn40KyGscaSyrj+vcF+dT60YJhnQKhxoTSVReWXWzGj99mcd96AbHjW8voraN4tzqk54QRfnQEjEMwzAME1Acey0+9thjNGHCBPrzTx4BZBh/gR+EkDtVExdVldWyW3YydcxKpvV73I0KT4yeuoRGvLtYGBVg675C6prtOdqGlVHhL/7sduuBYrfPMCqAr1HhNx8odasPGxUMwzAMEyLO240aNRJZt+GwHRsbSwkJCW7fI2FeuMFSKKYunbPhsKw6G5MySs8wDMMwDFMvpVDg2Wef9aduDNMgQR4GNRKRdMiGg/WjF/WssT4bFQzDMAzDhBuODQuEmmUYxlnEp1HvLTYiHck8DQD+FYu3VccMZRiGYcKSdMgsbawXS0S9W8XTn9tLRIQ9OxJPM1+4LpmxFBtZSct3OxeJQnDbv3USLdleSKUBVoa2To2kyiOVdLicqEN2MnVrniaeg9N/z6VyD/qY45rF044DJVRGETSkRza1TUuifcWldLCkgrITYumn9bm0bHeZsX7XjFjaerCcispdQtN//eCWtL+olPYVlFFFRSW1yUqiv/YV0o69BVReGUmdmqdQYWG5SOb8+46jctuUaKKzjmlG3Zul0rM/bqQDiO+tIH3ykmMiaPzfOtGGvYXUt2U6uVyR9PAXf9KBkkpKjSGKi4ulPQWovbsUuFlKNMXFRNPm/SWiw312r6a0dOsB2pZfRglRRPed15WSYmKNEOZYF7mZEqKj6L3ftlCTlBgqK3fRCR0y6Pi2jej85+fR7sIKahxHNKRHDq3OLaA/d1ZFdURY86HdMynCFUF/696U5q7bS92bpdCdM1eK7+/6Wyfq0DSFBrZrTFv3F9MfW/ZT48QY4T8dFRlBOWnxtOtQCVUccdHE79bSxr1F1CiW6Iwezah3dixdaXNewa9c8yUlJVRWdvREA5YSMQ0dzE4g42qvFql06asLxSyFFXHREXT/J1U/etAsNYZ2HuKMAgzDMOHAj7efLJJ7IhfOtVN+97o+ekyPDe8v3uv5hZz4wt1zbi9q2TjR9j5UsLuRp3WzVV+nTLnpxBqZtBFU5P3fcj1uN2ZoT49ZyuN+iKNl360zPg/s1IxWz98i3mOC/8oB7Wxl8NbP0+EKoptPrQpG9MDna2qsL33yCspddEqXbLqhugwcE4wKIB7Z5VV9YZe2/U4UUG0+4v+wY1vRp8t2i8/Y9aD2WTXq3b15mngd3CnTbTnKhFEB9pcSjTylk9i2zd1fiGWPDetJZ/bIMdY/rVsOFZcdoUe+XkdHjrjoykFtKDW+Kv9c9+axRjkqvarLgVEBDpRVtU9GXGXwnLcLCwtp9OjRIhFeUlKS8LlQ/ximIYARGPz48KouW5N7iPo89L24cfV+6AePRgUo1Z4YbFQwDMMElqqQGIEHeXKkzxyybMvgG+pMg0736m1E4I7qjh0i4XVBxksLEOkPRCihwLNS4kTC0u4eAnTERRG1SqvqSKqgXNRXDRxiuY/oSCNCYQKc/9Tj09btlpMijkt/PupBSvRmUbOUq9vK9xisO0nrZN9yalshJQZmGbzNntEA5aD9JMijhHY8UukyzofazjjHVW2WKtZRj0mWj+/ktgkxUW6v6neoZ99W6dS5adU585R5XK8/XtU6Yr/IFwUfzeUPnEFf33qim1FhtG1sFM2dcCotuHeIYVRYlYV2xv5gjHRS6oj22by3IHjO26NGjaLZs2fTQw89RFdffTVNmjSJduzYQa+88oqIGHXllVdSuMHO24yvuSdklmoskz4UZnTISKRtB4o9ZqBmGMacjAQi1xGife4T5I7p2yyONu4upUNHiOK1DOU3DmxB36zYTn8pP+Hk2AgqKHOJjgaSQ5baHLSLjSBq1yiCNu53EfoNjZPiqFFKPJ3eNZsmzdlE+wqPDiCg+3FV/+Y0c8lOOlxmfX9IjSW6bkAbWrxjL63cWkAFFUTJMUTJCdHUpUUqlVe46IirkirKK6lpeiK1T0+iTQcLaO/hUjpwuIQ27iul4oqqzmC7pkm0bndV9LjMpGjaU1hB2ckxIgHnrgMl9Mf2PfT7lkNUUFppSDuap0TTS1cfT5WuCLrl/cWUe7DECDKRnRxNV/drTZvyC0Q9Ko4QXdG/JR0qqaTHvloj7n3yWKXypnlKDJ3SNYsGtcugd37dSuf2zqGYiGj67xcr6HAZ2j6S3rjueIqPiaYl2w4IyUZMdJSQa9w+fZmIfofuIU5Jy/Q4mnhJb1q0+QCt3JUvknv+ubOArujfQtQhKzmWFm3LF7PIi7cdpCZJsbS/qIx6Nk+hYS8toK3VuX1SYohiY6JpX1GFIT+Sr82So2lI92wacUo7WrerSNSjbUYS7TxYIjqHSO6JjtnP6/eKjtnT36+jrfuKqFvTJDpQckS0F5Jzfj76BIqPja56ZrzwM62sDumNTuyb1x1P36zcRdee0IrmrN5HLlclTV+8g1ZVJzBtn5FAE4Z2pRdnbxAJVPH8ef/GfkLysmbXITqpY4aQDk38bp3YBoZAcXkltU6NppwmyXTzKe2oeXqyqLda38e+Wm2MUMdHEl05qBXddGJbuvaNReKZBuOitKKSeuSk0O1DO1Oflmm0bPsh0UkvKC2j53/YSMe3SaczuuWI/erPRyyTsmCQkxrndj7Qlh2bpojv5LaqLyI66cXlR6hLZgJ1a96I7jyrI2WnJbsFREEZnp7R6vf5hSV0zgvzaUd+sTAcIqrLQZkTL+1Nmckx9M3KPDqnZ7Y4V2oCW/2Y9IAszdLixTUhX+V32AcMgzumLxPnDjmmPq2+FnT0+iPR7SWv/Gq0y2PDjqFxUxEBsuqcwdiYpR2jXdSycA0izLykY2YSPXNpb5EHatmm3OAkyAOtWrWit99+m0455RSx88WLF1OHDh3onXfeoQ8++IC+/PJLCjfYsGCcAMtenX5GtuvR7y2mtR6yRY84qS298tPmWqohwzChBkZG0TmT4aBV3rj2OLrhrT/82r8cWUWnRZa3cU+hW0fBW/4aaUSoiTVVMGqNBJs4DjNkB1DtFDoBg7zliub/63En0p0fLRedHlk32cm1qrseHEPvVHq6l9uVPXnrvHrar9yH2TqxURFi8AntuOT+00XHVF+nbZNE2rzvqEmsnit0MCde0sstSaqK3im2Ss6KEfUXtWSrZm1g1g5Pa+Xr66t429YK2T5mnXKgt61+3s557mfL5zWe57dPW+Z2XmEwWO3PDhUWbY2ypEHlqf5vXX+8m3yrTeME2rLfPSy70zpZlRWIqFCOzRuEk23Xrp14j53L8LInnHAC/fST9wuCYcIddQoU04S4aXgyKgAbFQzTsFmZe9jUqMA9JCsFLr3+AYNCGhWyPDOjwlP+GrnYzKgAyKtjZVQAGBUyQIVTowKoRgX4Y+t+ozMm64byW6RXhblXFC3G92rZ2BadQlXqoUt0pEHmDV22ghHo5Vo5EoxWo8MPejRLMcrAMnwny1ZlTDHVRoVsR/jp6RIiUe6+IkOmAgNAPVfyuOXzScpxJGo9PSVnlTPv+n7MpDvqfuSrJ4mS3W3N5EUS2T5WoI2t5EYoU31ed8pKdpMqqXWR7aU/8z0dky+JcHX08jAzJD/juHSjAteD0zqZlaVKxPzBsfM2jIrNmzeLmYsuXbrQtGnTqF+/fvTZZ59RejriIjBM/QajPXIUAzewi1+eX9dVYhgmCAQyn0zXpkliBgGRgCSfjx5EHbJSAnYPgaZeRvnBe0g8ShQrQo9YY2xXPQtgjPo3T6XKSpcwTrplJ1GFK4LWQRITFUGlmpxTjrK7zVg0TyVoIWDooGP9+LBedNu0pWIfrRvFU0x0pCHjcK9HhOF3hvf/+vhoYAtZN7xuzy+2nLmAfCMuJkqULXXoF740X3S65TZyJFru1+xcx8dEUkl5pTAKIAeR8iEAw2T8h0uNddExlR07fDd88gKjw1+lCak6Jiwb/sqvQrYCIqOqOsxtGifSRyP704lPzBXSJRw7ZEJ4xky/eSBt2VdEo95bZMiVYqMixWh3y0YJoiwZaRD1QD3V59NfB4rptg+XGu0h6yk7lEJe0zyVHrvoqLyme05VpxwSHF3Wo8/+SF8RISXSyjdbX99W1gEdaH1bII8DbYDziOtL9cnQQftDNgTjqHNWMk375wC3OqhlopP+yajB4nu1TLVO8hjsHpMZaplSnibbygzsH20P40n4hMRGu51T9Zx3zEqimTcP9Lluen8G1wskW2DCR8urz2sqPXhWbzo2WFGhrr/+elq2bBmdfPLJdPfdd9N5551HL774IpWXl9PEiROd7o5hwhL8GOV09p/V+leGYcKH9Bii/HL3hyHirWQmRVFqQpzoxCEEY3mlKyAGBkJtqkYFSIyLER22QN1D1NCheP/FmMG0+1CJcPRFZxva9i9W7KK7Zq5w227myEE0+v3FYjQcnbEPbuxPl7/+m/guKiqaZlZ3clQ5RsesZFqfV0CdmqbQU8N7ibZCR1d2RNGBBhERkdQ5O4U+HTXY1A+tbeN4EYpT4CKafOWxYl83vbPIbb3Px5xAf+44aNTdauZk/Z5CMcoPGRU6Rmc+9/PRNqneRh25lx00nF9ITCABQlvJYzHrrGFbNWw45EdyHf07GGcqK9Syq0ext+wvogNFR6hdRpJYH8bVwMfmiE609KOAMSWBkYA2Qodz1qjBhu+CavxIWQyWwcDU3ab1zjI65DvyS8V3q3ILhCRJlU55lNlIRX31q9f1Leqg11193yUnVcif1M62t9kBzEzgHKr7s1Om2fd2j8lO593qutKNI11mJ8tXzzmuU7N1naDuW5VmzVLaoajQvvO243mP2267jcaOHSven3766bRmzRp6//33acmSJTRu3Dinu2OYsMAqwgRuEoGaPmQYpvZQjQogswHsKTxijAzL0f5AzFpsyCsUo4v6KLeZ3CVQxEZH0mldm1KPFumiw5CcEEvD+rZwk/+gHlhP6vbRGYNjrez04hUdocEdMtzkGDAqZCcX22P/6Oyhg4L11e3ROcEy3ajAfgyjQhhDLhHF5tQuWW5tgjrCOEHddXmOKpmRoGMPg8pKjtW5aVX0IvzBkJJAYpIYF+12LGadNF2qoo486+cTba23tyxb3YduhEhZGTqMMAbVCILws5Cj66gf6os/s7oKQ0c7F3qHEq/osMsyZUm6xMsM1ZDCq7f1dVA2jkVK1jyBc4KQtFZGBbAjW1KP26pOnr73hejqfXq6rqwkYnqbquccvytP6waizo4NFV9yV8THV2kEQevWrcUfw9RXrJz0sBw3YysdM8MwoYeU1HTOjKe1e452atE5hmxGlfFI4qPdJUVmeJvVgDO1HDmGE/QTw3qK97iXQO4yf+M+MbNw98wVbmVLnr3kGHpx9kZTPw0ziVO3av0+7lN6x0COW0PzP31ElVRElX9ITbeVHAQDKsYoafX3aoQcXeIiv4chAeNCSm+QCGzit2tpVXVkJClxQVlyVBayDIzOexr5BW6Re7RjgBwLci1IsarkL0dHdT8ZfXQmxa5+3pM0Rq07kEaH2awC9qGOPMMgkZ10KStDnRCd6P8+WyU+Q8712egq+Y4dzM6FGWgvWaa8nuy0h939W+EtgpNT/JUthQKtHLSpv+0vkb9fOzMq3nAcFQpGBXwqIIVCZKhBgwZRQkKVI1W4wlGhGE+YRZjAj84qRBvDMIGhRXocPX7RMXTrtGUiq61KdkoMjT+9Mz36zdoa2XLN6JCRQHed1U1knc09VGp0QlNjIykjNZ427a2SAaGjCZ2xGp0GMw3rLRyaVT1+6/R4umNoZ5HJFkbKhrzD1CUnRfhR4CGtR7wxCyVZ6arybbACOQ+2VodvVWmaEku7Eae1mjZNEoUu3VvEIhlNRg/daRXKU6KH2tQ7h8Dse7TxhyP6G1If3D8//OcAEf51YLsmbqPRTjudno5BrY++D2/HGizMwori2gO6FEsmXvUkA/JUjp3jk2Ug10JeQZnt9vCn/TxFcGrIVDhoU3+vX/U6NAxa7ffmpJ/suAbff/89nXnmmbRw4UI6//zzRVI8RIS677776LvvvnN8QAwT6phNrapTlWxUMExw2J6P3AuVNYwKsOtwOTVNT7BlVIANe4upfVaykANhBFzKQw6VVQqjQtVkY1RZ/uY7eTEqAIwKsDW/hLq3SKdzejWjC/u2oNv+1pm6N6+SIan7lOAego6cvJdgtNqTUSHKOFBsRLyRciB8Vo0KRBiCUWEmj7CSiuiyBydyETPphtX3aGPkCJCyG9w/84vL6cSOmaLtVTmMN0mIpzrpnz0dTzCkL3aktPrx4filxEWXzNiRAVlh9/hkGfiNOGkPf9rP34hL9ZVoB23q7/WrXoeqBM9XWZXjWsCIuPfee+nbb7+l/Px8kSwPeSyeeOIJYXAwTH1DTq1iJAVOjlITCmkDwzCBB1FxJKPfX+ImSfKWPbhHteOu/vtUI/dYZc3VZT+IvBMbHeUW2ckTenQgjAJiNBavQO6zp0UoSdTFW/hTbItINrgfwZkVr/gs9wH9/e/3nmbZWTO7n/mLt86h/j2kPWqGYoyQq20lO+CQZajryVCt4YR+HajGBXeqg3M9Ms5Qr0NPoYWDJoUC69atozlz5hh/paWldNJJJwlpVDg6cLMUinGCyFux6zBd8NI8KudM2oxNYuAEbHPdbk2iafvBCmqSRLSvkKh1k1jafaiM8hQFTJOEKNpXfDQMULv0aNqUL12Qq7IIH1YK7JIZT+1ykik5OpZaN0mkJ7/b4FbmcW1S6I8tNUfLB7ZJEf4FcAIe0DaDlv11kDbkHaKpi3a6rTf8uByKpAjq16YxFZW76P5PjoYKVXn2kl60ZudBOlBSJtZFducHPltlfP/M8F4UHxtFI99bXGPb16/pSzlpCZR3uETIZtAJgUYdsiPo9ZunJxhRTX5ev4euf/No0rkvxpwgHIOl4VBQXEafLsulY1qkCqmSqteXsgI9MRaMgite/5X2VM8O3DqkAz37wwbThFfrdx+2TBSm65nVV0hhcDy/bd5H//l8tduxt2iUKGZbVJ2+xKmUKdDYkU6pfgbSRw2GlZ4IziqJXG3IZPxpN7NtvR1DXcmwgkl9PKb63mYVXnwsnPSTHRsWzZs3p+LiYmFE4A++Fsccc4wSziz8YMOCsfujxnoXTprnFk6QYcKR2CiiMi0hmSfM8iJ4wsyhWPdH0rNFe9qPfDXL7qzqglWfBbU8dR2E7zzu4R+M71CPj0cNFu91zbvqpPz29cdR74d+cKufjEuP7+WIq36fwCwDQjeqHX43B2itLD1fBI59yf1D6Jo3/giYk2tt48lfwu07rR3NltdFHX3dtraPoa4JtDN2Q6AiDNrMST/ZsVgvMzNThJjdtWuX+Nu9e7cwNBITG94UHtPwftQYcWOjgqkPODEqjuZIsD8OZbam7o/kyaDQ9+Myye4sUXXBqs+CWp4evlP9DvWQemJd865GmJmxaHuN+sGoeOv640U4VqtcBjLPgXqvgROzzACs11tPQodP8EvQ/Q3CycnVzF9C1t8qkk9tR/jxVEdft60PUYpqqw0bKtvqWZs5vsKXLl0qDAokx4MECv4WGRkZIjoUHLgZJtzw5CCoOt3h77apR/XeDBPOZCVHU+vGCV5nNYz3ke4+DjER3mc4xGt1nhcz/wF8lmFRzUAZSMQGZL4YuT84Vcv9yWXSZ0H6XSCsa/fq96qj89DuWW75Z7AfdPowi9Cp2jG6U1ay+KzG2cd2Oqi/alR4ynOgOzFLJ2zd10K2ndGW0RE0pGuGUTfVl6M2nI31+6DuiGzlnKx+j7Cxui+LNwdUdXbHTp4Df4/TH58HT9sG2zk8lPCnDX25tuoDreqZr41PPhaSffv2CR+LTz75hD744AOqrKykI0ccDoOFACyFatjYmYZHR2Xc6R3pxrfds8EyTLiD/naHzGRaXZ1LoEtWIl07uB2d1aMpXfnaQlpZvRwd9Leu70uDHpsjcgLoIPzr3Wd1pUlzNhnJ09RwrZ+NPkG8//ukeSKfADru7990PB3/8GzLeRApf+qUmUTR0ZG0qjpiEgwJZFHukZNCZZXV+QmqQ8Xit3vBpHnGbIiUQ3XPThbZr7GulEP9tuUA5aTFG34RuswRHeHpWjjYdXkFblmfEWp26f1n1IjWYyav1O810/45wE3PLP0Qbvtwqah/y7RYioyKoq37i91kXVK6FYyOqlkIVPX4pfxMDSvracZXv49OvLS3qY+ILyEwA3mcqnQpkD4WDRFf2sHsfIBQlwgFiooQv3aCKoWaOXOm4bS9atUqaty4sYgU9fTTTwt/C4YJN6ymqtXRRXQ22Khg6iNQCF09oA3d+/Gf4vOavCLq364J7S+qMIwKsHLnIfph9V5To0KGf22UFFfDqAAI14oONEDHXrzmFdDU33Z4FFfJ79ZpSeFkx/5PJTSrDBUrlivGgeyMq8eC3zXi9MMhXYJRUV3muMIkHKxZqFmsgzCdKnKU2tu9Rl0Hn+GcLev/18GjIWTNpFvBkEvoM7hWx6/O7nqScej3URyfnY6TpxCYgThuT9IlX/fvz7b1CV/awUo5UJ8kQg3l2nFsFt188820c+dO+uc//0lLliyhvLw8YWyMHTuWevXqFZxaMkyQMZuqVqcnGSbcQWZoK7lT46RYQzIkZTaQn0BKpCZma5EeL3IkmCHDv5r9ZtpnJFJWcqyIdiTlPBixv6xfcyMLtBnyO11GJWVN6nKRXbmiUvyZratKp1A2jk+XwZiFrtXDwTZJRHyvo0AehozZulTDSsLhTRaj1gPHJOVDqnRLyrT8BQnR5q7NE69m5eN4EQpWSrbMQvPqoXshefI3pKounQpECMxwkp80BPmPnfMRyueotqkIo2vCLylUfYGlUIwV+BFvyCugC1+aL0bNEK0lPTHGLRkVw4Qq6I49cF5XuujYFqIjO2ftHtqRX0xPfrNWjIDDRoiBxKY6wRtAp3L6zQNp+OQFtgIVtEyPo3+d0034GWAWoHFiNJ3/4jzaeqBq9kASGxVhzHagYzxz5EC64vXfjBFJM5A34vkr+ho+CjJcqcxKjM718Fd+FTMLulToqeG9xOh4TmocDZu8gNbuLjCkONhejcikymDwex/zwWIxy4L1Z1VHi5Ja/wtemk9rdh0WBsZD53enl+ZuEjMIlpGAfIguhPsNjklKseSxIund2KlLDDmXP9IQGBN9Hvpe3NfQcUdODMi51PLRjogEhveq1MxM4oVzI7OZm0V9cpJFWJdO6Vmo67P8JBwiBAULK/lgqJ2jhnhNHAqmFAps3LiRpkyZIl6fe+45ysrKoq+++opatWpF3bt397XeDBNy4McbGx1pTMUjWgsbFUy4gKu2dUZVtmlwZs+cqhHq6g44+vlHFKMCwJiA/MVu9LO/8ktpxHtLDB28akCoqMsgg1q0Ld+jUQFW7y50k85IXwgg8xzIDNq6VAi/W7kOjAp5bNgfOqlWMhhsJzNtY335ndwXjAqwr6ickuJjDNmSuh9/owvJY8Ir6iq3Rd2klMxfaQjOsbyv4VXKudTyVUmZlJrJtlCREq4VHqI++RJdSZ4vmYW6IchP6luEICdYyQcbyvHXl2vCsckzd+5c6tmzJy1cuFBIoAoKqm5yy5YtowceeCAYdWSYOsVMIsEwoYyUEKGzDymPCj5LaQlm4JCHQd3GKqO1N2Qn1coHw5NsykoOJaM1WaFKJVSpkFWWbTsSCyffqcegrhus6EKBlIao14F6nXjLSu5LvZ3Q0OUvDf34mfC/JhxLoQYOHEjDhw+n8ePHU0pKijAo2rVrR7/99htddNFFtH17zTjfoQ5LoRhv6Fl0mfoLulreYtshDCoiDGXGEe0rJdJVr43jiGJiIZkrF6M38nv5vllqDD1wXg/q2yadPlmyi/YcLqK0uBg6XFZBPVqk0zEtU+nVuVuoa3YyPf/jRso9VEot0mLpyuNa0f9+3UJ7CysoKymKLu7bik7tkkU78kvo1y17qW16IrVskkTZaQm0KvcQ9W6ZRl1y0mpMm0MGgxHq7s2S6asVedQkKYYmzdlIK3MPi+hJd5zZhY5v3UiUCyAnQgSllLhomrdhLw3uAOfucnr8q9W0aV9VOnA5YwGfA5lEr23jeLqifxt6d+FWEdmoY2YSPX95HyFtUjNOw/8CMxioD9rjQGGJcKxOSYh1kz0hKzW09zL7NCQC8zfuE5GdsN6CTftFuSd2zDBkPVbZZD1JLGT7oLOtR3vCd7JMOYNith9vmWw9la9+p+4fqNmr7ciKPMlIrI7Tqnyr8rwdq1MauiQmHI81HOscTlTUcfsGNfN2cnIyrVixgtq2betmWGzZsoW6dOlCJSXuulpP/PTTT/Tkk0/SokWLKDc3l2bNmkUXXHCB8T2qhlmQ1157jfLz82nw4MH08ssvU8eOHY119u/fT2PGjKHPPvuMIiMjadiwYUKehXrahQ0LxhNSP3zdG7/RjuqoMwwjQWoHm8moBapUSHbGETZ1496i6o55JLXPTBKdfJVuOSkUGXE0YpBd1KzPKgXFZdTzP99ZRmVSdfdW4T9lOFiEf114z6m0p6Ccbp26xKh795wUodGXdcYMxEc3DzT1b0Ant9d/vjWSw+mZtvWs3dj3Jos208PEOtEle8sQbZVR28m+7GqmdX8DPdSrp+OpLV12bZQTChpzxho+P/WfQw76yY7PfHp6ujACdBAhqnnz5o72VVhYKCJJTZo0yfT7J554gp5//nmaPHmykF4lJSXR0KFD3YyXK6+8klauXEnfffcdff7558JYQcQqhgkE6Oyc8/zPYrYiJdZLRjCmQeLEqNClQlI+hLCp8j06z7pRAZDDwalRAVZoSR8lyD6tVr1FunuyPKm79xT+06WEf122vUoPr9Z9pVZnvFfDl6phJbFczTitZ9rWs3av9NBmephYPfGlrwkz9YzaVm3rbV+eyrDaHuXqPgy+HkcgqY1yautYGN/g88P4ZVhcdtlldNddd4ns2xiJQlK8efPm0R133EHXXHONo32dddZZ9N///pcuvPDCGt9htuLZZ5+lf/3rX3T++efTMcccQ2+//bYIdfvxxx+LdVavXk1ff/01vf7669S/f3+RT+OFF16gqVOnivUYxt9RmL+/+Ivh+LlmT5Xkg2FUnJqbiiuASK4mR9+l3h2j7/isg2WeslRbgeR0kBpBzoc/Ga7wnJ7ZRt3x+vmYQfTpqMFGWFrUA6FGZYhDM38G1ZcD60KmpIZ6xXv9c9PUeFPdPuQ48PnQkT4gmOnR28OqzfQwsQiXijawE67Rm4+D6nsifUCsQkFCGiRDteJVhojVQ7rqmmm5P9TZU6hXTyEo/dVle9q3+p04lupy1DC4gQyPGW4a84ZGXZ2fcAnBWuGwnoE4Lrv7CEYbOpZClZWV0ahRo+jNN98UWbajo6PF6xVXXCEiReGzTxWJiHCTQm3atInat28vZkJ69+5trIckfPgMudMbb7xBt99+Ox04cMD4vqKiguLj42n69OmmBgsoLS0Vf+oUT8uWLVkKxbjBfhX1n/S4CMov9XwLRH+2eVosbcu3Fw0MXd2nLzmGXpy9kTYoid2wH92vWfojoJP5wU39hZ8BOsSQESDs6ej3F4t9wDiAtGfgY3OMUXozmqfFUXxMlJBVuZdzVEakyncgh8LMBYwMfO794HfGejBioqKiamRZVjNDozN/x9DOwh9Dho7FsTxZHepVDRMLo2PCR8urwqhaZGBGfTBDiFC1RsbsnBQqr86ujQzc2C4uJsrwsZA+AmpWb3mM+P78SfPE4ICT7M3e/C8w4LCuOhwtQvNaha6V8hCZKVxtRzWkrCqnMpOcmYV6Bd7kJ77qsr3JwfTM3Be/PN9IVuiPDM1bnVjDH7rU9vkJF/lVhcN6BuK4fJFaeisrqFKo2NhY4fOAjj+kR++++y6tWbOG3nnnHZ+NCjMwIwKaNj2aGVV+lt/hFaFuVVAHZAOX65jx6KOPigaSfzAqGEYn1EdBGP/xZlQAGAN2jQqxvpAGudyMCrkfHenkDJkLckAg3Cd8GmTYU7kPhD/9ZmWeR6MC7DhYWsOoqCqn0lS+gzC0l/ZrJV7RQVfXW7XraChXKW/QM0NDftS6SZKouyrZQd3h2Iz18Yf3WLbCSwZm7EfmvzAyZucePpqte08hJcZFG/tGW8k2g9OwXE8eI5bJGUc9e7MnPCWxE+Uo4WitJFeqPERmCpff6yFldbmVLjmToV7VetmRn3hLxuerHEzPzP1ngGRonvD1WJjaobbPT7jIr7Y5rGcgjssXqWUg29DnKwCd8bPPPpsuueQS4UyN0LOQK4UD99xzj7C65N9ff/1V11ViQhB+gDGgc2YCNU12z7bsCWSyxkhzq8buPgtmMh+MZFvJB9TM191zkqlH8zRD+uMpoRxmN2rW6WjZHTITqbT8iBh5V6fARWQgeKIrzuJHJS5JVFRaIWbxUC9d9qBKfrAu9q8b5rpcQma+lvXAq1m2ZbsSIKuwsnrmajPpkRNZgHqsdkPO6ufZU7Zq9TtPGacDIT+xOl679ZPHr8rD9FDC/khjAi3TsNpfuEhqwr3OgSRc5HGtHNbT0/p2z7ndMoPVho6kUK+88opwksasxbhx44Rfw48//ijkSOvWrRM+FojaFOpSKB2OCsWYoUaAgcxbyyPG1EOcRniyY2RMHzGQEuNiRDhUZE7efqCIMpPjaMKM5WKEXcpc9HCfF7z4izESLCMkdWuaROv3FNa4FtFvxaA4/BGKyysNyRDuq7dNWyrK0a9hXRoEzn/xF8MJGv4DU2/qTxe9PN8YoQdqNmhdkqNGvDKLmKSGJZVSGVkP+WqWbRnYkQDpcgz1NyzbxiqSkx1ZgLqOet6sZCAwlqQUSz/PnrJV2w3f6o/8xNvx2qmf2s56GFx/pTGBlrr4G6ErlAjHOgeDcJHHVTisp1W4ZaeSKjtl2l0vKFKoxx57TIR1RVjZTz/9lE477TR65JFHRFSmSy+9VOSv8NWoMAPhbLOzs+mHH35wOzBEh0IuDYBXhKFFuFoJDB04lMPoYRinyBEBdAjwY4N++q3rj2ejooEQSKMClB0hyi+uENIddCi75KTS6d2yKSUhxpDtSJmLCq49VV4iq7Vqd02jQtS7ehk6zqpkKCE2yihH306XBuFPjawEuRN8PlSjQs8GrUty1IhXZhGTpFxCzXytZn82y7Ys5VR2JEC6HEON4iTbxiqSkx1ZgLqOet6sZCCqFEs/z1bZqtX9qW0QaPmJt+O1Uz9ZrpS7SYmav3WzU79A7S9cJDUq4VjnYBAu8rhoh/U0W9/pObdbZjDa0Pae4JgN34o//viDvvrqKyouLqb58+fThg0b6O6776ZGjRo5LhxZu5cuXSr+wObNm8X7bdu2iZG2W2+9VUSNgiGD3BmYEWnWrJkxq9G1a1c688wz6aabbhIJ+hCdavTo0SJyFdZjGCfIEYHTnp5LfR76XrwOn7yAGiXGiuRkTP2kbRN3yVIgwSi5nvnazhQ0PiO3hUQKlHo0S3HLMH20nKMZlNV9WmWmtlrXTNKiZ+BWs1rbzX7t6fit6m6Fk+l7u7Iiu/sNpKzBl/0FUg4TjOMNJIEu22p/4SKpUQnHOjMN55zblkIlJCQIuZN0dI6LixOGRd++fX0ufM6cOXTqqafWWH7ttdeKqFMyQd6rr74qZiYQTvall16iTp06uSXIgzGhJshD7gtOkMc4BQ9oGBNMaBJoOVp8FFHrzGRau6uAmqXE0s7D7g7aMCb/eVJ7+luPLPpu5V5KiYuiZ37cQFv3FVFOcgzlFpQb62Ymx9KegjLKTo2jqSP60cd/5FKnnGQa1L6JyO+AUKxwTPYkHdHBOogMJaVT+4vKqE/LNPp10wHadahEvI+LiRb699yDxZSdGm+MMqv7lGVhPQnWUaVGap3UzNaelut1ldIdyL1Qn4HtmrhFMfK0jZqF245cwIm0wElWaDv7DYSswZ/9BUoOY+caDEZW7bqQung7htqS1ASqLe2eO6Z+URGk69TOfoOSeRud9t27d1NmZqb4jKzby5cvF5KlcIcNC0bXQ0u9N9MwfSNU1JCfkLN4w8hGHRVBkZERQoIjl8nwnHZDceqZnlWkD8Txj/zolgXbW3hQb74D/mi2/ckUzfg3EPLj7ScLSUOohsCsK0Kl7mZhhH01CEPheJj6QYXN68lJP9lRfNj777+fEhMTjXwWkCmhIJWJEyc62SXDhMyPC5096WQ5Y+RA2rq/mM554Ze6rlq9A4KUQJpssdER9MGN/WjY5IUUDNSQn22bJNLmfZ61rUY2avgbVPscyGUyPKeulbXqEOqZnlXgA4EcFHoWbH2fZtpcvTw769hBzxQt8WefjGdphOgQOJRGOD3fgbo+6oJQqbtZGGFf6hMqx8PUD7YF4XqybeaedNJJtHbtWhGlCX+DBg0SkZvkZ/xJXwmGCTd0p0zIVvIOuzvUMoEh0PNAs0YOpl4tGythRa1zYctvpC+Avm7HzCQjg7O+F4RRnX5zf2rdqCqzsLcyYEDJLNZyGTqAkEWp2ZTVUJ46IuSsSfhY0L1ZKg3tnmWEMpWYZov2kBkZM3VlFZXUSQmh6ovWH6FosR9ZFkLldszyHIK2rrPOBnsfVvvUQ/36UhZGFTG6iJmKmSOdjVrrIXN98RXBMcxdmyde6zIsqrf9O9Wme9ufr8fjKfxwfdPaN/RQuOHUpsG4nhxn3q6PsBSKcZsObJEmHtTQt5/53M91XTXGC1OuO45O7Fgl0VR9CfA67OV5RhI6b7Rpkij8AyDhGf+3TnT9m3/UWEfNYN0+I4EiIo4msfMGOvUzRw40MlQjJGxsTJSYebAK96nKoJB/IiYqklbvqpJjwQCCRBVSI0N+FR1Ji+4bIhLeWYWu1TMjq8eEOn6qhb71hl5P1KsMhkZ1NClvIWjrKutssPdhVwrjRBoXCKxC5jrRYeM9AlzIMMFL7j/ddB/Blu04yTBsN/SmtxC8/hyPp/DD9SXMKku1Ak9t/I4C6WPBZ5thtNG/af8cIH5k6Gh2yAi90aBwQ03OZsZD53f3ed/YMwwAdJznrM2j2z5cKozBse8vpp35xbaNirbVRgVAB7lFo6OjOCpqZuqNe4ttGxVgXV6BCN8qZ8YQElZmsDYLH6jLoDbsKTKMCoDQsDIUqCG/qqgUZej78ZQZWT2mdSahb72h1xP1kkaFnRC0dZV1Ntj7sCuFCUaWarv1MAt1bCcsJeqshgnGZ29lBePY7O7fbkhNb/vz93g8hR+uL2FWORRu+LVpoK+n0LsqGaaOwI8qKzmWznruZyPUbJyXTMcMUeesRMpItB51UzuWOhjB7tMy3fL7Nlr2ah25Z3Scb3x7kdFRR6f9pncWGVIkFUh0VAkURvnhN6GGI0WkFRia3912knCSNgPLpewHmbF1SZLZsaoZic0ySqvo4V9RnloXtXx5NDgGPbytVRhZpyFirfBWTyf7D8S0fKjsw9M+1WstUFmqfamHr+WhzmqYYLOQyoEqKxRC0gaqvHCQMflLQzjG2qZVmLUpS6FYCtWg8DTlh2nqXg9+J0Z9GXu8dEUfevzrNcLR3QmQ9bxw+bGiAw8DTo54y5CyyNfw1PDeYtmEj5aLkW5VUiOREiC7/Pf87iJ064j3Fpt+//hFPen83s1qZEfevKeQ/vnu0UScr1x1LMVGR4qQrwgni44V1oUz9cmdG9OPq/dRl+xk2l9ULsLAwkA1y0gMPE1B45qcv3Ef5cDXommV74cMM4lwsX8dKBaSL/zBJ0gN8QodPb5X1wV6PdT1vIWutAqXqYe/1OuphqD1Jv0wy+psloXWWwhXs3Ccvoae9Xae7OKp/Zweo5PyghFeFdcmZipw7Xs6p97OZyAydAfyPPl6bQVq//UBX44x0NdFfaOijtsjKOFm6zNsWDQMvOkU4Yh47ZTfjc+t0uNo56FSI6txuIPxxXZZSUKmYhWetVXjBNpm00jAqDScdSGfcQqceT8dfYLomKht3rpxIm3dX0RdmyZRcYVLdEhRzjOX9jY6x1v3FYrZCStio6oyXkukD0FcFCI1mSexQ0hYPQQkkNeL6ocAH4JNe4vcQryqoVXlMk/acx2rjqXV9WpHr6/W2ZtvQzDDZfqjDzbbFvgSPlfdrrbq7yuh6ifiL3qdAulfUlvHG4rtGu4E87pgAgP7WDCMQ50ibmxNU+ON6X2MjkdHR4WlUWHl0oA+9bOX9qHXru5L957d1XSdf5/brcayLk1rRiX67wXdRWffk1EhfSvw2k3JIg3W5RXS3yfNE0aF2uYwKsDq3YWGz4OUN8nkbwMUGYYZqlEB0Ll+5IIepkYFeOHyPsIBXA8BqV4vqh/CVQNa1wjxihkX3d/Bk/bcKuM7XmXUD0/Xqx29vlpnb74N/obLDJY+2GxbO/vztl1t1d9XQtVPxF/0OgXSv6S2jjcU2zXcCeZ1wdQ+PhkWP//8M1111VU0cOBA2rFjh1j2zjvv0C+/cMx/Jjx0imqYT9mxg9Nv+4xE0cmcPmKgGJUORzy4NNDId/8QvgcPfrG6xnetGyeITnuMZpncenpnIV1SR/gv6NVMvLcKhYrlUraE18LSCpp580A3R+511U6M6OTdcUYnj74YmBmRne9hLy+okbxQ1fHrQJPap5W5HweOBbMfE79dV8PfQQ3TKvePmZazejQ1DJsIE78CNaRtk6RYWpN7SIRitQoTaNVRUa9XhAZVw8Ti2tXrBt8RlKcvl7MsZrpcJyEMzXwE1HoFSh+shjE129ZsmX4c3rZTfRzU+pi1h37fwLVodT4DFRLSaThYp+1eV+FA9ToF0r/ElzZz2g76by8c9O7hQDCvC6b2cSyFmjFjBl199dV05ZVXCmNi1apV1K5dO3rxxRfpyy+/FH/hBkuhGg5SHzt+2jIjI/Djw3rSWc8fNYrfuv540akZ8d4SCnXaNI6nLfv9z7cBadSkK/pQqyZJbm0hjQQ1ys+nowbThI+WiegmZvKiMae2p1GndqC/v/iLmJkw6qpEXnLqJ6HXoXlaHO04WOr1uGT4VMx2XPjSfHHOEekrIjKS1muzLXDUxoyIqvGVYVTh7C0jTMGAwG0T0Y/k8h6YkYmIELMryLiN5HjqNp7kSGahjuU6anhKXSIA+dWTw3vR7dOWirpIpHQsMzmG+j86W/gMmcmyfJF0SMkWghwMm7zAqJcdOZEdfTCOVw9jKn1GrPwPgNlxmPkzACsfC2/SM9w3EHVMzqDp5zNQEhlfw8EGQmJXGwRDS+9LmzltB3V9/PYmXtrbJx8Lxhz2sWjAUihk2548eTK99tprFBMTYywfPHgwLV5s7hDJMHWNHJkC6DxK2QoeEmM/OHrdojMDec6T36yhcMBFEcKB2h9Gn9SOoqIihSEFY0CdnQDo0MuZBnSWx09baoRM1I0KrDXipHbiQXDnmV3cvoNR0SGz5gyHmVEB/5b/nHdUlqUaFSjDyqjADIQKpFoLNu0T53/iJb3o63En0n3ndqthVMhIUGrIPTWMqmogoGMpO/JyOaJSyQ6nyLitbeNJjuQp0ZkanlKXCKBuuw+VuBkVsn64xuFULgMRmMmyfJF0yLCESCCp1svbtnbDGZqFMTXbVl1mdRz4Dp0SGGJSZgawHTqd+j49tYeU4clzbHY+AyWR8TUcrBlmbVfXUh69ToEIdelLmzltB3V9/PZwPXCHN7SvC6ZucHzGkH0bWbh1YMnk57vHT2eYUEDXsGO0Uk6zQtqyfs/RB4rs1GzY6yzKUV2BaEzPfr+O2vgxVfziT5uMDigiMiFfgk6Z0lm2yt0w/vSOtOKBM0SnDe0MiRFG71W2Hyimz0cPFh38nposRQ3Xui2/lN5buNVYR8XT7AZmMl6/pq+RPZuq81xgFPyMZ34Ssxb4LMuEtAUzFWaZi9XpeVVWhMR4MqO03A+iWMnM1XKZLs9Ss17roGx8N2/DXrdMxqq8A6+9WqS6yT2QxRvXsJlTfUZynFtdslLiLCU+TjMSW8kKvWGVedppGFMVT8eBWQa18yij+Xg7JjPpEI5RDaOrh87FuZLXgLewumYSHLlMvT/VZojWcM6W7ORa9rWdazPkp92s5gxTL6RQkD29+uqrdPrpp1NKSgotW7ZMLHv77bfpscceE9KocIOlUPUbPERgVKhSJ3RYEGFIDyOqRxQKF+4d2pke+WZtnZWPzuWsW6okR3p7jxvSgZ77YYNb+5/cOauGVAXymvNenCdySkjQ6QeqBAUGiBoS2Exihc62KsOyE1pWxaxuF740z80IlZm0cw+VGtI6yDBmjBwoRvRlGFd08m/9cImYdYGEYtaoqnayIwGS0gt5zDKakSxHzeINaQa2uWP6MqOtYGDddkYnevb79aYZvv3JSAx0WaEnOYndqFJ2w5jakfyoGcF1+ZLVMXmSDkn5GUar9TC2alkwQD42Oc+e2lKPiuMtHG6gZSfhHunIzrVsFn3ISTvXhjzH7F7gqxSOYcJCCnXTTTfRuHHjaOHChRQREUE7d+6k9957j+644w4aOXKkP/VmmKCgjjShgwap08Uvz6db3lvkZlSAujIq8ENskRbr8/aejAqZC84skFLbxp4db+2ADjac3eWDVh/N/n7VbmNddRRaTnVLWUpyQix9Ne5EtxF5dN6QvwGdNBgZ+Ft03xC3dTADIj9LYFSoI/nqKLh8vWvmCiGT0Udo1RkufI/jgaGgGhVqJm2wQpFhYF15XKg78l1IKRc6nvqouZUESJVeqJImWY6exTsxLlqUpcp1IJOKiTq6zEzi42tGYikPWmFTTmI3KhPaDYank86UleRHNSp0+ZLVMXmSDmF/aGOcV09lob2t2sJOpCt0doMpA9GPs67lUYHAzrXsbzvXhjzHblZzhglVHJvBd999N1VWVtKQIUOoqKhIyKLi4uKEYTFmzJjg1JJh/AAPAYxMIaO2HA2HJj6UQLfx9ev6U3HZEbrw5SoteKCA4/PQ7jn0zapdtHqXu2/B33u3oOd+PDqbIA2R5y/rTc0bJdIt7y+mHflH9coygZ3ewcaMQZeco6MYT1/Sy3gPCZLko5sHioe5mUMt3qMz+cXYE43ZAjURlUwQB+Q6cuQQn91Gz1uk0bR/DnBLECdnHpDEDkaF2olCZ0Fi1smS2aXVzqP0x8FyjITLcv3JZCxHKfEZxwUDTR3hN0b6lcgpy7Vy1XqqWbb19ZwgjUV9H1bLve1DPY5gSUq8lWe37nbW068PT1Ioq/35e478wcl5DGfC4TjN7gUME074nCCvrKyMNmzYQAUFBdStWzdKTnYfMQwnWApV/9HlOaEI/A4Awt5aAZcFT+FkndI6PZa25pcZn5+4qDtNmruZtu4rEg/gt284zogshNmehfecSnsKyoXeXI1GZCbfqRHFqDl+W1Uj3PLBqSaW0yP6qNISOwnevGXENZXiaFGY9PXU7+X+cezbDxS5JenDTAqWq9mlVTnVxZMXiFFsTxIZMwmQmSQLMxVyHSsJkN4O/mYL9tS+nuQhVpFerDJfBzILcyDLs9N+Tto4WJm2/SHY5df18dVWPQKxf1/kgAwTTDjztkPYsKj/4Ebd68Hv3LT5oQaiMeHXuLEO82fA31htIkQqQqcMDzk4CkPmIx+Ys9fsFo7Qqu9Ey8aJbgYctsf6eNCi463OXpiB9TF7YGYIyu/MsNKIqw95vOq+NoM7ZFh2Ej11lnWj54Mb+9Hxj/xojDL+fu9phv8DjCfcZGFY+JMBO9AZrIOdyTnY6wfjGOti3w2BhtJ+DeU4mYbHIQf9ZFum8EUXXWS78JkzZ9pel2ECgZ0RU3RqQ9moAGbRmOCY/NHN/emCSQtouxdJkhn3n92V/vvlaiOS0sybB9Blr/1q6UuiNlHbJolGm6IDLvNAwCH4jqGdqU/LNI/yHWyPEXapS8a50KUp6iyGKk2AMYOEb9KvAevrEZXUEWJgJl/SZ09UGYSVUQFknc3Q9fQIY4tZBFUXDbmVqsvXNf5W+/aEmUTL7n782dbXfQR7/UBvX1f7bgg0lPZrKMfJMH4bFrBSJJjgmDVrllh23HHHiWWLFi0SoWadGCAMEwi8JbVSo7noSdZCHdT3s9EniKnwj0cNpIGPzaHyIy4hSZr2z/50/ksLTLdrnp5AO/KLRYjRh76syrDdPC2evhg7WMiY7DioI/v2Z9WJ5QA68NJJF/InzFRgnZ/vPInW7ipym7J//8Z+1PfhH4Q/C0bxZVQTma9BJliTkh6Zi0CVr0A+pYcBlo6WVlF4dD8HM0dNlG/mPO3ESJVhKkUyrqbJwn8Df6qRdU7PbHpv4bYaEjA9vKcTyYQMPYv8EWqIVzuSG7XOgfazkOXIdpX+LE7LVPdvltHbW3sFQj9vVYbdfYeK3CeQCcjsRlsK9rmpC/REjN7aIZDHGYpyOYYJmGExZcoU4/1dd91Fl1xyiUiSFxVVFWHlyJEjdMstt7CMiAmpESI9mgs66uHCIxf0oIuObS6corfuK6QxU5cIowJg5iUxLkZke9ad0NGp/WbcCaLTDsdiyY6DJbS/qMJRpCdv2l7U56QnfqLF/zrdTb+OstUoRp8s3UnD+rYQ38mkZboxaOU8LdEf0mZReOCjgoRx0lixesjfPm2ZV0PU23cwnmTmaRhBWBcGlKqLlkaUWafEF5kQykF5CC0LyRxkZZ629Te0po5qGHoK66qGknVSpgyyIDONy3a1215W9bOLpzLs7DuUZTBm14L0fXJyDZmtVxvnpi7QB6bMfMF0AnWcdkISh9L1xTAqjq/KN954Q0SAkkYFwPvx48eL7ximNjFLWmSWAAkjoOEyW4HosGf3bCpC4sKRe8S7i6lMyeIMiRGcQ5+5rE+NvAzo3CJsK2Q+4mFYjYxSg+3kcplNW9K6UYLxHrMScgRahmNVk4OpifOQewK+C+c897PwZYEvhrpnRGDCA1EmRdOTlumhLfVwtWYJ7GQUHgnqNuGj5cKYkiFkzTJaewqr6eQ7GE965mk9TKoamtLf8J7q+ggtaxU+1mqbQIUwtRPWVQ0l67RMPdO4p9CwdutnF29leNt3KIds1eumZnB3cg2ZrVcb56Yu0Aem7IZVDsRx2glJHErXF8OoOL7yKyoqaM2aNTWWYxnC0DJMbaJ3HoHMQXD+i/PEyDK+m3HzQGqe7n/OhmAQYZJZ+puVeZYhce85q6t4hZGgGlVyVgCddzBLyf0wfcQA40E0/eaBwtCS2bQlL13V162zjtCtMAbQnhgdRz2xrz/uO9UwSvAqQ/gitwJGm5EwTo8IgQchvsN5Gf/hUiOjtplcQD2nSLqn5wyQ66jH98ylvU0f/PpD3lP2XDXLNb7DZzUrs6yzGsLV6hg8gf0haZ7M0mxne7VuMLY8tZ/dzMJWmZa9ZcfW0Y08mStEb0M76Mcp5V61kfXY3zKcbu+t/e0u96VuMP7Va91baFxP6wXquEMNfYBD/c05va6dHrNZm9bGbyDUCZdrp6HjOCoUZiaQZfvee++lfv36iWVIloes21dffTVNnDiRwg2OClV/0KMJ4eH5yajBRrjPUKV5WhylJ8XRyp2HDClJXFQElWqdf3TnsUTKGZCnAZ0vJCqDtn345AVidA0yKcxowPgA6pT++L91covmJMGD84lhPems539xi5ykSqpkZCZ0Oudv3EdPf7vWCDkrQUdfyo2MTNHVvgHqOqizVRhQp3gKEWtHp6xur2e1lm0t21ZmzwZOJQ+6bAiSs09HD/YoO9Pr9km174tZ2XblT56iaNnJjm1WRzMfCztyG7M6Qe4VGxPlli3cl/Z2SqDD3Xpaz1v721nuS93U8yKvJ2/Xn78+Ft6OO5x8LPy5rp0cM/tYhPe1U98IeFQolaeeeoqys7Pp6aefptzcXLEsJyeHJkyYQLfffrvvtWaYAIAbLh6WGD0H6Mz+tG5vSBsVYMfBUnrzhv60M7/Y6MjDqJh0eR+69cMlRgQoaWbg5vr3SfNo3e4CowOIzhhkMgCzHVKD//iwnm5T+jAq5DZtGifQlv1VSeQw4q9GdfKUhA0dEYSW1Y0K6cwsdcbScMCrYfQ0q0p05/QB7QkzbbPVg0iNUgVDVHf01rNaS+mINAbwKn15fImspMqGkFxQdUq32katm1zfbBsr+ZO39eTxeMqO7amOaFM1gaEMGexrVCh5HevbBjvCjqdoYIHc3k7721nuS93U86JeT/4ck7/HHarox+Xvde3kmM3a1N/rM5wJt2unIeP4KR4ZGUl33nkn7dixQ0SCwh/eY5nqd8EwtY0czcFocyfFUfvmd48mMqtNYm38uhBOVu2QwzdCne7ulJ3iFlZW9YuAUaF2ANXOmAQ34HFTl9RYjm3gqwGjQpWuYIZDlZbBgMCoN2YukMlaHTmDpEmCELSQ9kinW4CbPrY3pEgRVXXfuKdIGD2QqnnTDDuZ+nbixyCNDsxu4VWXDelSJ7vSJ2/11WVDnjI0q9vYlUDYXddqPXW5el34E0XK7j48SU/qm+zDTvvbWR7IsmuD+iDn8ee6DtdjDgW4HcMHnxPk7dmzh9auXSved+nShTIyMihcYSlU+KOPTj9yYXc698X5FOp8OmowTfhomeiQm8lcwAWT5hkzLu2aJNCmfVUzDBI1JwR+zVgXIWkRmUmXIKHzD4NEX26VLM5q1F+XnE257jg3eZWezM4q87msh9cM2P4mTNP2v3rnQTfJl5rIT51lUWVE3jIrqzInKZeyirTjNAu2nkHak4TM3zCielmeoiAFSiJjtj7eByP7cKjISby1v93l/pTtixSxtuRioYw/13WgfiuhTLCOpT61UbgRVClUYWEhjRkzRvhZSGdtzFRcc8019MILL1BiIluRTPCwurHoo9O7DpVSOHDH9GVCDqM6P38x9kRDqoMOaGnF0cQTqlGBWYJnL+tjaNplZ0yG6xS+AjcrvgIt0sSsQw39u4dkcWaj/igHfh1q3oiB7ZoYkimzHAtq6FdDu6/Ux+xBYVW23Vj8VqEf4R+CZH9qRCn5vRoKVzX0JFahao1cH4pcCp9VeZBaL7PlntDr5sn/wa5cwmo9dbnTTOd2y/BWJxleN9B66lDSadtpfzvLfS3bLOyzt7YIRPvVBzmPr9d1OFyX/hLMY6kP105DwLFhAeftuXPn0meffUaDB1c5MP7yyy80duxY4WPx8ssvB6OeDGMZ21uOvKkd22e+W0fhAIwKJJqTOSpgEMjRbERlkpGOzLj9b52NDqqau0PORMBQySsoq9G5luuqfhBWnXM9FwTWVR3B4YQtR91l8jnUW8+xoHby9VFSqweFp7K9xeJXDQ41qR6WIS9IiZJifPwZnUzlU6qhJ2eR6lLj66v/Q7DrEow6BGv/dX0OQwlf2oLbLzjUp3atT8fC1JJhMWPGDProo4/olFNOMZadffbZlJCQIBLnsWHB1NYNC51YdQRZRsDBaDk6tnUJfCH0cK5mSMmSBFGCrAyKjpmJtD2/hIrLK8WI9aD2TWqM2KudcTlzAKxGQL2NWuqj/npsd0R2kuvjFZ/1sK+ybDsj4Xr9rMqWDtVmDzBvyaUQMQtZyWFc4BXt6Mn5X+7XzNCRzt+oKwwszH5AioZXGZHLX8yyZ6uzPrWlNVavNb0tPNXB06ySv5mundZfn2mTs3zBklfUhXTDbpm+tLGa/b022q+hYHUuwlFCFYzfLlPPDYuioiJq2rRpjeVZWVniO4aprRsWbqhqxxKhV9GxzUmNo+gIIiWnXK3SITORYqOjaJVFHgoVGBVwokYuCDywnx5+TA3fEHR+Z90ySMxOqLpzPETMjAJPMwe+jC6pBoFZxyKYDxW1bH3fVhGrrJy25TJEzOqYhYSJBdQ+yz2RFd5D/iTlZOp+9VkXfbYERFjkJvEVq/CxgQrT62s9cLx2Mgx7kkX4m+na1/qrM20gWLKNupC3OCnTaRtLeZqUWULGCOqLhKcucRLVLtQlVIH+7TINwLAYOHAgPfDAA8LHIj6+KuFYcXEx/ec//xHfMUyw0Dt2w16aZ3wXHx1Bt05dIsKfIoRqXRkVYMMe+wY2ZiyEUVHtD3H5awtrrIOR9biYKENShOzOwCrsobeZAxWnI88IGYuOBaJuqVGiauOhohpNnsqyOia5DHWXfi0rFV8IdeQP8iezY5CGjlnbA7OQtP7gKXxsXcmwPIV/1UdPPRmu3ozaQOqprWbanIYODXVJiNMynbSxLhPEtSjLsVseQ7bPhZ1zGaqyI/aFaNg4fuo/99xzNG/ePGrRogUNGTJE/LVs2ZLmz58vvmOY2rhhbdlXRCt3HY1qVFLhMnIqyLwMdUnrxgle12maEmfIoPCg/n3rAbccB94yM5uF3/OUdVkNhSrfAz1zuVW4VNU5eV1eoZgh8nSOgjVSdXv1TMw5z/0s6qmXJQ0OeUyqjweWPX/5sTX2qYefBZ6Owazt9XCp0oHdE7bC0yoZv/XroLYy0XoL9Yjy1+8+LJziZRtimdV2qizJ12zGgai/nRCWvraxp2P3tj+zdexsZzckpy/H5O2aDzfZS239dnzFTtsGuv39aZNQb08mxMPNQvL03nvv0Zo1a8Tnrl270pVXXin8LMIRDjcbXuDGdfZzP4nObSgi/SY6ZiQi8YuQ3HTISKBtB0oMvwu5jlmoWIAO13STrMn6iLCeGdYq67IaLUrkUYiomtHQ5TVS3tO2cSJ9NmYwJSfEGseFjqPquwI5idPoRsHIrC6dq+3iFha2eSrNumWwaEN1v3q4XKv96LMaMpKX9JPxJE+wK3WwCmFb2zIIT2FQZT1UZBuaXbOqLGnipb1FZLNgRIGyW39PPiD+hjwOhLwF2K2HN829P8dkdc2Hm+wlFCVEZtSmj4W/10U4tCcTouFmAULK3nTTTb7Wj2H8AjfRUDUqgJyFWL+3iL4YcwLFRkeKjmbZkWJqnhpH953blW55vyq5HIwK5JBolp7g1mmfeEkvI7mcBGFSDe2/cvOWnbd5G/aaymaEUfHiPMMhWZ0VwXpqeFq5zub9RdT34R9o2b/PMHIIoPMnDSH4fciZj9p8gHhyrvaG+gBGB101yMycen2Z7nciQ7MrdbCSV9W2DMJK3qDWQ6L7plhJPOSxWTni10b9Pck2/G3jQMlb5Hs79fAmQ/HnmKyu+XCTvYSqhEjHTtsGqv39aZNwaU+mdnDcI3jrrbfoiy++MD4j43Z6ejoNGjSItm7dGuj6MYzX7MWhzMWTF4gOrexo7jhUSs9+v95NAoIcEnAkVae09YhChnFQHUpW7XDI0aJrp/zuli1ZSkswgi474jLylCxfTZSHdZqnV/lNSQMJHT4JDBUZ5hR+H0gwJyUvtYV0rka95XHaMQKspE4An4VR53KJWRg9UZ9T7MoT/JU6hIoMRZeAeWtDfX0Y3fq1GyqSmkC3sa/nPJD1CJXrpi7hNghsm3B7Mn5JoTp37ixCyp522mm0YMEC4WPx7LPP0ueff07R0dE0c+ZMCjdYChV+6LKcUOaNa4+jx79a49a5R+cLI9t2JQU1JUAp9MXYEwwHVPU7zIAgYpKUlqjSJ3TIP6mW00gneDhky5HjbtnJtHFvkTAqMCvx0c0DheO4HkFHxY5sSEXKhfTM006m9J1O/+ttJNtfD03s9Fjs1A9Y1RWzUN6yS/sSrtVJHXw5Jl/roZ9rvf3ltRusiFe+yEYCLfXxVd5itx52JF/Am1wqkNdOIKiL89DQ8KdNuD3rN4cc9JMdGxaQQcG3olWrVnTXXXdRbm6uiBC1cuVKkdtiz549FG6wYRHamOmU0TG97cOlhk9CqIJoVdDwQ0Y0rDqiEkZ0PI3oWnUqjIzQ1caB7Ii66Vur94320f0hdEPGykj7etyJ9Nf+Inrsq9XCyACY4UDIW+DmQ+DwWFSfAX2/wdTouun6m+M3XmVoufmbeDkWf8t1Em41kOXqPjW+lONrXb1tp1+7iDQWLF+LhqADtzpGJ8ce6GsnmMfFMEw98LFITk6mffv2CcPi22+/FZm4AULPIuwswwQSszj+suPRKTOJZt48kG585w/aX1hOoUhWaryQDKHuMAasIil5e4B6CuOqfwfGf1jlwyGlTzBsrEbEpQxLdu7aNEmkse8vNowKsELRzcJhe5aPOQxUnwF1vyCYGl21jdRRctTFk9HlL/6EWw1UubpPjS/l+FpXOyFlPSVBDPfwr7WN1TE6OfZAXzuBoCGcO4apLzh+ip5xxhl04403ir9169aJrNsAMxZt2rQJRh2ZBoqZQ7Lq5LluTyFd/vrCkDUqwLbq0LeoM4wKGSrVyjfBynFTd9LTw/qpIV71zjtyNsAYs/KF0MOzQoaCtlVB6FtVN+upLp6ORfePkSFUnWp0fQltKOts5s8SrPC4+nGpIVWDpUvWQ7lihqannyFIPR2HJ+wco3rt+tMmdkL31lVozroOC+zk2NV1ezRL8Rr2OhD4e+707Tn0qTN8DYHMhDcVQTqnjqVQ+fn59K9//Yv++usvGjlyJJ155pliOZLmxcbG0n333UfhBkuhQg91tFtGIsID5e3rj6PjHv6BqgMvhTztM5No455C0bFDpCdven5dsjPxkt41/BCchKtUses/oMuVOmYl0WejT6gx4+FU5iJlRrqPBZD+Hna09YGQRfirB/YU9tfKx8AqW3egdeN6KFe1jf0JQerpOHzR/Adqfbv193Xf/pTndN26Cqtrtg9V8ohIbAiaYDXr6W99/Tl3nma1WTblHV9DIHObhjcVDs9pUKVQiAD14osv1liOzNsMEyjU0W4ZkhVOnYiMFC5GBYBRASorK22FNJWzB/KhDkNE/dHbkQSo+5B+KDBSZHneOhhYhnCseucfIxvqNk5lLnI7vGKfWI66OO0E6OViVguRtZw86PwJ0ei0IyPLssryHEhJh1WGaeBvCFJvxxGotvbl3NiVytRFaM5QCQvs5Nj1sMky03Yw6u3vudO3r43QxfUJX0Mgc5uGN9uCeE5tPYmXL18uOkbyvac/hgkE+tQ3Oo6QEqmRlcIJZAU/87mfjZCmcFKVHWsds1wI6Dw7kc/IzntERET1kgjTsKue5FHwpZAJ8My2cSJzAWrWb7k/GIpW0i8r1HIxm4VQpbUZ9tZOR8ZbvYMlK7EjGYGzPv7U9vJVKqNnGK8ruYRZ/YNZF1/bK1RCcdppm0DW2+q6C0Q5+vYYgAq19g5l/A17zYQnrYJ4Tm1JoSIjI2nXrl2UlZUl3qOzom4mP+P1yJGqOPfhBEuhQhM95KEqzwlnYFjA10LKVZ4c3ksYElaSJ0MKZiGfsYoiBWMEnW5VCgWcZpjWQ7Wq29gNnamO8D+tScJkLg0nUZmsjq82RtE8RjLyIeJXMOpnJRkxi8jla7hfPcN4XUtQ9PtFsKUbTtsrVEJxOpVxBSJMsafrrraliUxN7N7HuU3rFxUOzmnApVCbN2+mzMxM4z3D1Ab6aHe4GhXtMxIpITZaSJLQ8QSqXEXMZAhHyVR6ploTL2VEaufZTD5j1kkAZv4pssOlRoCyM0ohRzbMtjGTJ+g3K32EX68DOuZO8xZgPcxiOT2WQGAm8bKK2GW2bbCNH0+SEbOIXHJdf6QyoSBB0e8Xwa6L0/YKFemIEwlEIOrt7boLRDn69qHU3uGAnfbiNq1/RAfpnNoyLFq3bm36nmFqCxlNKNSNi7joyOrkchFUUlE1qwejAonmZOcZyA6xCgwP3afCW+fZKoqU7p+i+iB46gSbjWA46TibGTq6YQLDSd+fLzc3J/UKNOHYkdF/QzIilz/7U8+rlKDUtqFnp24s3ai7tgn0dccwTGjjOCoUWLt2Lb3wwgu0evVq8blr1640ZswYkZW7rpg0aRI9+eSTQrLVq1cvUb9+/frZ2palUKGJHj1IT/pW17TDTERMlPCf8IYu0/GW5M+u3Mgs8hIwi8bkjUBE/rCSTdXlNHogy7aSnZllEg/FiD9O6+ptv/5KUIJ5XQR7376ec6trqDZ/H3VRXm39RhjfYKkT44mgRoWaMWMGXXbZZXTcccfRwIEDxbJff/2VevToQVOnTqVhw4ZRbfPhhx+KRH2TJ0+m/v3707PPPktDhw4VBhD8Qpjww0yX+8GN/Qw9frfsJFq1yz3XQm2zI7+EFt03hLbnl9DYqUto3W5zx3IYHwjRaeYc/XF19CU4wE74aLlpxChvciOzUXu5DOXafVgEIkqE1WhoXY3oBzJMopXszJt+PNjH4uQY5XXnT3mBmrkJdgjLYF1zdnwGPG3rSbpYW74ptf17dHLdMbUPh5NlAonjK+fOO++ke+65hxYsWEATJ04Uf/Pnz6d7771XfFcXoA433XQTXX/99dStWzdhYCQmJtIbb7xRJ/Vh/MdMl3vui/OEUdG2cSK9f9MAapEaU6d1hORp1pKdtP1AEU0c3ou+HneikYiseVqcsR7kSFv2FdHctXlUUlZRwzjACF6XnFTROflizAl0+fEtqaCkzC2KEt5jW/mqRmkCeoI3vEenHs60ajQns2gwcllWcqww3ABepTGkl19QXFbjWMyS7XmKfGUF9qnuW62vjCyzJveQaXQZMzwlHHSK2b6s9OPe8CVikdWxwDBVl+NzIKIh6eXJEWdfj0n/3ixssKc6m+1fv1681cPOd/I6t6qL3XOul4X9zli03fQaUpf9vH6P43awi76tr23lpAxf9ulL2U638ff4vF0ndsoIVuQytY5W0biCdZ8MxrUY6PPiK8E6X7VBbf0+fJqxyM3NpWuuuabG8quuukpIkWqbsrIyWrRokTB2JIhcdfrppwvjxwk9HviGIuNY+xmqoHMONu8vot4P/UChwP2frjTet24UR5cd11p0fHccLHVb79wXfhb5N2IjiSYM7UKR5KIP/thOG/YUUk5KLN17Tldqnp5IwyYvIGgT75n1p9iue3YyFZQdoa37iw3/DRhWaAP5EJizNo9O6JBRwwHarMN529Ql9GfuYeqYmSQMmdxDpYYcSzp6oxwYcDBK3r+xn6gTPifERFJxeaUIXIs6Yv0l959eI2mWNGqsRsCkLAKzNEBGxMLyPg99L+oQExVBC+4+hW54c7ERPQtrq7Kx7jkp9MnoEzxKglR9t5rLQ11/Q16BMA6zU+MpLiaKclLj6LctB6hJUiztLyqjge2aiH2VVVRSx6xkWp9XIAxIGGJYD/WQcji8x3q4BiQ4Puxzwab94phbNEqgCdOX0urdhdQ5M4GuHtROGHK4Fs7q0ZT2FFRlktcT26mzQW2bJFLjxGhaueMg3fLeIqOsrtnJNOr9xWL2rFNmkkiQh2NqlBhFb/+yjRqlxNDwvi3F8fy8fq/Y5vg26bRs+yHq2ypdXA+ybJTXLSeFVlUf27ipS+jhC3qKjvzgDk1of1E5VRxxUWx0JA1s15guffVX0Q4dMpPo8zFHEyriQT9/4z56+rt1tHLnIRGk4PFhx4iHlkyKGBNJIkhBj5wUevziXuJ8REZE0IkdM8R+sI9zn/+JNuwtplaN4unT0YNp2/4SunjyfCo74hLX4uw7TqD352+nj5fvoG0HSqhlWizdcEI7OrZ1I4qLiRbnZfT7i8R3HTIS6YmLe9Gq3KrrIjoqim6btlS0m7zOG8dH0iXHt6KzeuZQ5+xU4/e1M1/LSp8RT89/v44uPb45xcfEGu1zz6wVtGFPEXVrmkQjT+1It09fJuoqfz8457HRLnpp9iZqmhJLuw+Xif1d/+YflJ0cQ1f3a0Wb8gsoJiKahh/fgnq1bCyuV9kOnTPi6ZzeLemK/i3oQNERKi47Qku2HaDGiTEUEx1FrZskUstGCeK6w7Hj2nvq27W07UAxNU+NoQv7tKDZ6/aKc9Y8NY5euKKPaKfcg8WUmRxHd3y0XFzruFc8f3kfcU0gLw/KkG2Wd7hE/D4AznF6QgyNn75M3KuxHc4zDK/M5Fhq1SSJ7vxoGa3aVUCZSTE0a/RA2phXTO2zEujVuVvEdXhq56a0Pq+QbnrrN9pbVEHZqbH0+ZjBtLegqoO8bvdhOqljhrj2cH30bJFM037bSX1bp9OEGSvEOeqYmUjPX36sqK88ZxioefOXrdS+aRK1zUgWESxv/XCpOL72GQk0bkhn2lNQKn7TaDscxxcrdlLvlmkUHxMj2m/L/kK68NgcuvK1P2hHfrFxnTRLjaOXrzqW2mcm06Jt+dSrRSr9uukAbd1bSG/9ulXUoXV6PN11Vhdqm5ksZm5wHvH7e/zrNeJ33yEzkV6orjPCqqM8/D7k8e4pKKPcgyXiPoJ9yHPxx5b9lBAdSX/uOkQ3nNCafl67n1LiomjiD+tp2/5iio4gqnb1o27ZyTThzC50fOtG4nkizyPOeUFJBWUkRos2b9cknjbmVf02AYIydG+WTJ8v200uVyV1zUmlX9btpUbJMdSnVSPadaiU8g6XUp+WaWJf6j1d3r9wr/ps2S5KT4gW7ZuTFu92fSFoyV0zlotrUT6b8grKjLDRaCtcv1kpcbR292E675gcSk6INY1QJ59jHTMS6dYzquT5uEfhXiKDicjngBwswe8E5wnHjGsXvwF538c6OB9b9xXS49+spa37isS99bnL+1BOWhx9uWI3dclOpoMlFcY2G/IKxPpwNMDvUM7Wrd11mJZvzxf1x31NlQfiHvfpslzq3iyFEuNiRJ1kXXDOoIzAe7Qz7tfwacM+8gtL6NU5m+hASRld2Kc5JcXFit9l15wk+uiPXDq3d1P6aOEOmrFsB+UeLBXPqLFDOoq64TzgupfPvszkGHGecA0988MG2rq/SKx/x9DO1D5Nhq4Pgo/F2WefTcOHDxezAypTpkwRUqhvvvmGapOdO3dS8+bNxayJlGYBzJ7MnTuXFi5cWGOb0tJS8adqx1q2bEktb53GhgUTFqAjVq4MJMiHnCqvOP+Fn2nlrip5Fm4JM24eQBdN/tXYRhoqnkAHdnO1QWfGlOuOo1O7NHXka2EWNhgd9fFndBSdKqtjNAOzRJjt8ShVemm+eOCYhVe94MVfhKHlifjoSJFBXfWlwUN6877iKkMsKoJaNk4UHQTVad9f0AFHB2iFcjx4+PR9+Aev580bsVFEZR4ig6Ot3rnhONsGvNqBATDAvhp3opux6Au4rn+/d4g4Txv2FVNdER8TSSXlldQqiWhbABSYMJzLjzi7TmA0lpUfoY111A4YFCkzuexw/SNdTqCu+0AhO5gw7FbtDr5sVhqM3sC9Y9PeIiox+Q3jXmO23O65CCQ4r5GREeK54u/9y3HZ1c8mDDTA+CjVfito6xUPnCE61vKe7w3cmztkpVQljNUGqoxBtagIoyyz+773MiKF7yWMZxV0ztHVVpergza4JvRt1LqYIQdTBjx69DkbTCpLi+ivZy8Jjo/F3//+d7rrrrvELMGAAQMMH4vp06eL7Nuffvqp27qhyKOPPsqZwpmwRr/Xy5u/Oo0tjQqA29MvG/a5bWPVOZU3WenP4omctARHvha6jESChw/2pXa4cEjSsMHIWkn5ETGaqYIRHGlYWE3nywebHuYS770ZFQAPev3hoj4EcPOHUVG1buA6V+rsjDyev/YX+W1UAE9GhWyrd3/9y/b+9MNGZ0DW11ejQl7XX6zY5dWogKkYzH4WjAoQCKMCODUqwGqt41HbWHVkPXV+6hJ53dWGUQHstoLegVSxY1SAYBsVxnn149yaBSWxXXZ1O1jdn1Er3BeOb9u4hlFhNWCGe7Osk/4MkteKei2b3fe9gW1WmZxfs/1Io0K8N9nG2+8KdX7y6w1UL3wsbrnlFtq7dy+99NJLQhKFP7zfs2eP+O6CCy4QfxdeeCHVBhkZGRQVFUW7d+92W47P2dnZpttANgWrS/799Zf9ByjDBBPd0seovX7TBD2apYjREXVkF8hOPP4w2nP0+yi6ZmAr023ilX0ieR/kTZhh+GTUYCMzZ6esJDGqoo/CdMiyjn8vfS3UqFRSmmQ2Qo59/X7vaRQbFWHU+bPRg8U+Zt0ymD4bfYKQDKj1lzIMq0yinrKL6m1kBdoHx6ofO+onv8fonNqWgQD77KnVHdPfslwz5GS1bENPMxaeQLlXDWhpu64YQVXp3izVsr5xUfbrhXN8Ts9sIQm0AsbojxNOpEAAGQbkaWYzFqBVgPydPZ1DTzMW+m+wNtHPsTqyitHgUEO2MQJ9BAP9kO22AM6h1X3C7v3D6lx4wukZwnmVzwh/719OkeXimYR66GAJ7gvq/R2DT3h+IaAK5HA6uEblfRrryvfqtaKWZXbf9wa26WbyG8V+9OWYsTDem2xjdtwqqPOEMztQsImorXCzoQYiQSG0LELMgsrKSmrVqhWNHj2a7r77btthtFgKxeg/qLhIouPapVJBYQUlJkTS3kNl1DQ9kZIToml/fjGVHiHq2jKVqBIdoBzauKdI6Imz0xIMbXFmSjz9vG4PdWmWQv3aNjK0qtB+R0RECq0r1lO1s1KHiQ75nLV7aNehEjqudbqYypW6YchMoGuGTlLVE6tSH2g9pV5UatX1baTO3VteCyB9I/RM4U6w8rGQ+0IdoeuVGlJ9W/2Y/Anl6cTHQj92bCvrKbW7aEtopOWxmflYQHObmRJDU3/bQRccm00/rd1PHbOSvPpY6O0Dnwhdd4tl0Car9UD5vvhYYB046iNAQVZKrMiFAgnHj6t31/CxgH4Z7QGN8DEtUqlLTpppfWXdoB2GXA7a7GOap4p9NU9PEOXiO+iTVR8L7Bv6ZGjKs1PjRF3kscvrAFpjqaNv1ThJ6OBV7TfaAucZTzz4ueAU4XcmdeaqLnzVzkP09fKd4iYwtEe2m4/F71v20vWv/07Ht2tEY4Z0oGaNEujpbzbQJcc1M3wsTuqUIfYJrTPK/31LvuFfg2tMaroTY4le/HETtUyLp2aNEsVx9GmVKu4RxcVltOHAYTcfC1WnfWKnxvTx4l10Wb/mtnwsVKTPwPWDWlN0ZKSh7YbfBNoUvwX1t4K2wb68+VjgNyM129IvSb2/QZM+Y9FOOlhcSlcMaElrdxXV8LHANYa2r3BVUk56gtCN7zpU5tHHAvdV/H7Ucynb2MzHAnXD+ZD+JLhW4MPgzcdi+HHNxO8V1zjuxbI9sF6bJkluPhaYrYuLjqCzj8mmJdsOGb996WOht5e8Lvz1sZB+DPBHkD5E0OxjW9QPv0PdxwLXzg8rdxl+E9JfIFg+Fvgd6NeXvO/qzzM7PhZm93zp56Deo/zxsZB+X/Ank/dJ+CSEg4/FzN92UlpSNPVv10Rcp/JZZOVjIc+TvIfgummbStS6WVNbUqh6YVgg3Oy1115Lr7zyijAwEG522rRptGbNGmratKb+W4fzWDAMwzAMwzBMLeWxgNP2Bx98IHYMHnvsMbr55pspPT1dfN63bx+deOKJtGrVKqptLr30UiHF+ve//y0S5PXu3Zu+/vprW0YFkLYVGo5hGIZhGIZhGHLrH9uZi7A9YwE/BoSalQnnYLEsXbqU2rVrZ/g0NGvWjI4c8d1Rr67YtGkTtW/fvq6rwTAMwzAMwzAhCXySW7RoEZgZC93+qAcKKoPGjau0q9u2bTNmZJj6gQwljB8Dy9zqF3xu6y98busvfG7rL3xu6y/o8x8+fFhMIHjDcbjZ+ggS6gEYFfxjqJ/gvPK5rZ/wua2/8Lmtv/C5rb/wua2f2B14tx3SBYlO8KcvYxiGYRiGYRiGcSSFuu666yguLk58LikpEc7bSUlVIcXUTNYMwzAMwzAMwzQsbBsWCOeqctVVV9VYB8nywhEYSw888IBhNDH1Bz639Rc+t/UXPrf1Fz639Rc+t0y9yWPBMAzDMAzDMEzd4nu+doZhGIZhGIZhmGrYsGAYhmEYhmEYxm/YsGAYhmEYhmEYxm8ajGExadIkatOmDcXHx1P//v3pt99+87j+9OnTqUuXLmL9nj170pdffllrdWWCd27ffPNNI3Sy/MN2TGjx008/0XnnnSeS8eAcffzxx163mTNnDh177LHCcbBDhw7iXDPhf25xXvXfLP527dpVa3Vm7PHoo4/S8ccfTykpKZSVlUUXXHABrV271ut2/Lytn+eWn7cNkwZhWHz44Yc0fvx4Ea1g8eLF1KtXLxo6dCjl5eWZrj9//ny6/PLL6R//+ActWbJE/IDw9+eff9Z63ZnAnluAxD25ubnG39atW2u1zox3CgsLxbmE0WiHzZs30znnnEOnnnoqLV26lG699Va68cYb6Ztvvgl6XZngnlsJOjHq7xadGya0mDt3Lo0aNYp+/fVX+u6776i8vJz+9re/iXNuBT9v6++5Bfy8bYC4GgD9+vVzjRo1yvh85MgRV7NmzVyPPvqo6fqXXHKJ65xzznFb1r9/f9eIESOCXlcmuOd2ypQprrS0tFqsIeMvuE3NmjXL4zp33nmnq3v37m7LLr30UtfQoUODXDsm2Od29uzZYr0DBw7UWr2YwJCXlyfO3dy5cy3X4edt/T23/LxtmNT7GYuysjJatGgRnX766cayyMhI8XnBggWm22C5uj7AKLjV+kz4nFtQUFBArVu3ppYtW9L5559PK1eurKUaM8GCf7P1n969e1NOTg6dccYZNG/evLquDmODgwcPitfGjRtbrsO/3fp7bgE/bxse9d6w2Lt3Lx05coSaNm3qthyfrTS6WO5kfSZ8zm3nzp3pjTfeoE8++YTeffddqqyspEGDBtH27dtrqdZMMLD6zR46dIiKi4vrrF6M/8CYmDx5Ms2YMUP8oYNyyimnCOkjE7rg3gpJ4uDBg6lHjx6W6/Hztv6eW37eNkxsZ95mmPrAwIEDxZ8EN7muXbvSK6+8Qg899FCd1o1hGPPOCf7U3+zGjRvpmWeeoXfeeadO68ZYAz0+/CR++eWXuq4KU0fnlp+3DZN6P2ORkZFBUVFRtHv3brfl+JydnW26DZY7WZ8Jn3OrExMTQ3369KENGzYEqZZMbWD1m4XjYEJCQp3ViwkO/fr1499sCDN69Gj6/PPPafbs2dSiRQuP6/Lztv6eWx1+3jYM6r1hERsbS3379qUffvjBWIbpOHxWLWkVLFfXB4iCYLU+Ez7nVgdSqhUrVgi5BRO+8G+2YYHIX/ybDT3gj4+O56xZs+jHH3+ktm3bet2Gf7v199zq8PO2geBqAEydOtUVFxfnevPNN12rVq1y/fOf/3Slp6e7du3aJb6/+uqrXXfffbex/rx581zR0dGup556yrV69WrXAw884IqJiXGtWLGiDo+CCcS5/c9//uP65ptvXBs3bnQtWrTIddlll7ni4+NdK1eurMOjYHQOHz7sWrJkifjDbWrixIni/datW8X3OKc4t5JNmza5EhMTXRMmTBC/2UmTJrmioqJcX3/9dR0eBROIc/vMM8+4Pv74Y9f69evFPXjcuHGuyMhI1/fff1+HR8GYMXLkSBEFaM6cOa7c3Fzjr6ioyFiHn7cN59zy87Zh0iAMC/DCCy+4WrVq5YqNjRUhSn/99Vfju5NPPtl17bXXuq0/bdo0V6dOncT6CGP5xRdf1EGtmUCf21tvvdVYt2nTpq6zzz7btXjx4jqqOeMtxKj+J88lXnFu9W169+4tzm27du1EqEMm/M/t448/7mrfvr3okDRu3Nh1yimnuH788cc6PALGCrPzij/1t8jP24Zzbvl52zCJwL+6njVhGIZhGIZhGCa8qfc+FgzDMAzDMAzDBB82LBiGYRiGYRiG8Rs2LBiGYRiGYRiG8Rs2LBiGYRiGYRiG8Rs2LBiGYRiGYRiG8Rs2LBiGYRiGYRiG8Rs2LBiGYRiGYRiG8Rs2LBiGYRiGYRiG8Rs2LBiGYRiPzJkzhyIiIig/P7+uq8IwDMNo/PTTT3TeeedRs2bNxL36448/JqcgX/ZTTz1FnTp1ori4OGrevDk9/PDDjvfDhgXDMAzjximnnEK33nqr8XnQoEGUm5tLaWlpdVYnNm4YhmHMKSwspF69etGkSZPIV8aNG0evv/66MC7WrFlDn376KfXr18/xfqJ9rgHDMAzTIIiNjaXs7Oy6rgbDMAxjwllnnSX+rCgtLaX77ruPPvjgAzE406NHD3r88cfFIBJYvXo1vfzyy/Tnn39S586dxbK2bduSL/CMBcMwDGNw3XXX0dy5c+m5554TMwT4e/PNN91mC/A5PT2dPv/8c/EQSkxMpIsvvpiKiororbfeojZt2lCjRo1o7NixdOTIEbeH2x133CGm2JOSkqh///5iJkKydetWMZ2PbfF99+7d6csvv6QtW7bQqaeeKtbBd6gL6gkqKyvp0UcfFQ/BhIQEMWr30Ucf1Zjp+OKLL+iYY46h+Ph4GjBggHiAeiuXYRimPjB69GhasGABTZ06lZYvX07Dhw+nM888k9avXy++/+yzz6hdu3bino57Ke7hN954I+3fv99xWTxjwTAMwxjAoFi3bp0Y0XrwwQfFspUrV9ZYD0bE888/Lx5Uhw8fposuuoguvPBCYXCgU75p0yYaNmwYDR48mC699FLj4bZq1SqxDbTAs2bNEg+3FStWUMeOHWnUqFFUVlYm9MLo4GPd5ORkatmyJc2YMUPsb+3atZSamiqMCACj4t1336XJkyeLfWDbq666ijIzM+nkk0826jthwgRxbJh5uffee4UhgeOMiYmxLJdhGCbc2bZtG02ZMkW84r4LMMDz9ddfi+WPPPKIuF9jgGX69On09ttviwGh2267TQwY/fjjj47KY8OCYRiGMYAfBaRPmIWQ8ifobXXKy8vF1Hn79u3FZzyA3nnnHdq9e7folHfr1k3MMsyePVsYFnYebvgOxkPPnj3F9xhBkzRu3Fi8ZmVlCeNFzoBgu++//54GDhxobPPLL7/QK6+84mZYPPDAA3TGGWeI95hVadGihTBsLrnkEo/lMgzDhDMrVqwQhgKcslVw/2zSpIkx84vPMCrkev/73/+ob9++YjBHyqPswIYFwzAM4xgYHtKoAE2bNhXT5+pIP5bl5eXZfrhBOjVy5Ej69ttv6fTTTxedfciXrNiwYYOYOZEGgwSzD3369HFbJg0PaaTgQQldsS/lMgzDhAsFBQUUFRVFixYtEq8q8n6dk5ND0dHRbvfnrl27ilcMvLBhwTAMwwQVSIhU4MdgtgwjYXYfbtD0Dh06VPhDoJMPmdPTTz9NY8aMMa0D9gmwPvw2VBAu0S5Oy2UYhgkX+vTpIwZ1MMhz4oknmq4DyWpFRQVt3LjRGDCCVBS0bt3aUXnsvM0wDMO4ASmU6nQd6Idbhw4d3P7UiFPwp7j55ptp5syZdPvtt9Nrr71m1Amo9YLcCgYERtT0fWI/Kr/++qvx/sCBA+KhKUfkPJXLMAwT6hQUFNDSpUvFH9i8ebN4j3sjZiGuvPJKuuaaa8T9Dd/99ttvYgAFgykAM7XHHnss3XDDDbRkyRIxADRixAgxG6zPMnuDZywYhmEYNyBpWrhwoYjGhNkEOevgD+rDDbMBMDT27NlDP/zwg5AdnXPOOSJ3BkImYl10/uGfITv/GDXDDAiilpx99tnCeTslJUX4acDJEHU84YQT6ODBgzRv3jzh4H3ttdca5cMRHZIryLMQdjEjI4MuuOAC8Z2nchmGYUKdP/74w4icB8aPHy9ecQ9EFD/4sf33v/8VgyY7duwQ9z9Exzv33HPFepGRkSIyFGZpTzrpJBHEAvdE3Ksd42IYhmEYhbVr17oGDBjgSkhIcOExMWXKFPF64MAB8T0+p6WluW3zwAMPuHr16uW27Nprr3Wdf/75xueysjLXv//9b1ebNm1cMTExrpycHNeFF17oWr58ufh+9OjRrvbt27vi4uJcmZmZrquvvtq1d+9eY/sHH3zQlZ2d7YqIiBD7BpWVla5nn33W1blzZ7FPbDd06FDX3LlzxfezZ88Wdf/ss89c3bt3d8XGxrr69evnWrZsmbFfb+UyDMMw9ojAv8DZTAzDMAwTOiCPBUbyMBMho0kxDMMwwYF9LBiGYRiGYRiG8Rs2LBiGYRiGYRiG8RuWQjEMwzAMwzAM4zc8Y8EwDMMwDMMwjN+wYcEwDMMwDMMwjN+wYcEwDMMwDMMwjN+wYcEwDMMwDMMwjN+wYcEwDMMwDMMwjN+wYcEwDMMwDMMwjN+wYcEwDMMwDMMwjN+wYcEwDMMwDMMwjN+wYcEwDMMwDMMwDPnL/wNSyxtag9TC7AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_plotter.plot_results([log_dir], ts, results_plotter.X_TIMESTEPS, \"CantileverEnv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13338629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5027e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09e787dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0eeb49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = PPO.load(log_dir + \"best_model.zip\", env = env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1f8872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "ans=[]\n",
    "while i<1000:\n",
    "    action, _states = model_best.predict(obs)\n",
    "    obs, rewards, dones, _ , info = env.step(action)\n",
    "    ans.append(obs)\n",
    "    if dones:\n",
    "        break\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6dcae567",
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = reconstruct_3d_structure(ans[-1]['X_projection'].astype(np.uint8).reshape(x0,y0), \n",
    "                                    ans[-1]['Y_projection'].astype(np.uint8).reshape(y0,z0),\n",
    "                                    ans[-1]['Z_projection'].astype(np.uint8).reshape(x0,z0))\n",
    "grid = deconstruct(topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f797343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Cantilever beam design:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a6e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
