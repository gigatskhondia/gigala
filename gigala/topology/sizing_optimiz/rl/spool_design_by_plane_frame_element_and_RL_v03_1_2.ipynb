{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install stable_baselines3==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import A2C, SAC,PPO\n",
    "import torch\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common import results_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_coord(action, position, g_coord, dx=0.1, change_nodes=list(range(1,9))):\n",
    "        \n",
    "    if action==0:\n",
    "        g_coord[int(2*change_nodes[position])]+=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]+=dx\n",
    "    elif action==1:\n",
    "        g_coord[int(2*change_nodes[position])]+=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]-=dx\n",
    "    if action==2:\n",
    "        g_coord[int(2*change_nodes[position])]-=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]+=dx\n",
    "    elif action==3:\n",
    "        g_coord[int(2*change_nodes[position])]-=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]-=dx    \n",
    "    elif action==4:\n",
    "        g_coord[int(2*change_nodes[position])+1]-=0\n",
    "             \n",
    "    return g_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe(position, coord, displ, action):    \n",
    "    return position, coord[0], coord[1],coord[2], coord[3], coord[4], coord[5],coord[6], \\\n",
    "coord[7], coord[8], coord[9],coord[10], coord[11], coord[12], coord[13],coord[14], coord[15],\\\n",
    "coord[16], coord[17],coord[18], coord[19], np.max(abs(displ)),action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(coord,color,elcon):\n",
    "    coord=coord.reshape(np.max(elcon)+1,2)\n",
    "    plt.figure(figsize=(13,5))\n",
    "    for item in elcon:\n",
    "        plt.plot([coord[item[0]][0],coord[item[1]][0]],[coord[item[0]][1],coord[item[1]][1]],color=color)\n",
    "       \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_(obs_,obs): \n",
    "    if obs_[-1]>obs[-1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Element Model of the Plane Frame structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameElementLength(x1,y1,x2,y2):\n",
    "    return math.sqrt((x2-x1)*(x2-x1) + (y2-y1)*(y2-y1))+10e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameElementStiffness(E,A,I,L,theta):\n",
    "    pi=math.pi \n",
    "    x = theta*pi/180\n",
    "    C = math.cos(x)\n",
    "    S = math.sin(x)\n",
    "    w1 = A*C*C + 12*I*S*S/(L*L)\n",
    "    w2 = A*S*S + 12*I*C*C/(L*L)\n",
    "    w3 = (A-12*I/(L*L))*C*S\n",
    "    w4 = 6*I*S/L\n",
    "    w5 = 6*I*C/L\n",
    "    \n",
    "    return E/L*np.array([[w1, w3, -w4, -w1, -w3, -w4],[ w3, w2, w5, -w3, -w2, w5],\n",
    "                        [-w4, w5, 4*I, w4, -w5, 2*I],[ -w1, -w3, w4, w1, w3, w4],\n",
    "                        [-w3, -w2, -w5, w3, w2, -w5], [-w4, w5, 2*I, w4, -w5, 4*I]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameAssemble(K,k,i,j):\n",
    "    K[3*i,3*i] = K[3*i,3*i] + k[0,0]\n",
    "    K[3*i,3*i+1] = K[3*i,3*i+1] + k[0,1]    \n",
    "    K[3*i,3*i+2] = K[3*i,3*i+2] + k[0,2]\n",
    "    K[3*i,3*j] = K[3*i,3*j] + k[0,3]\n",
    "    K[3*i,3*j+1] = K[3*i,3*j+1] + k[0,4]\n",
    "    K[3*i,3*j+2] = K[3*i,3*j+2] + k[0,5]\n",
    "    K[3*i+1,3*i] = K[3*i+1,3*i] + k[1,0]\n",
    "    K[3*i+1,3*i+1] = K[3*i+1,3*i+1] + k[1,1]\n",
    "    K[3*i+1,3*i+2] = K[3*i+1,3*i+2] + k[1,2]\n",
    "    K[3*i+1,3*j] = K[3*i+1,3*j] + k[1,3]\n",
    "    K[3*i+1,3*j+1] = K[3*i+1,3*j+1] + k[1,4]\n",
    "    K[3*i+1,3*j+2] = K[3*i+1,3*j+2] + k[1,5]\n",
    "    K[3*i+2,3*i] = K[3*i+2,3*i] + k[2,0]\n",
    "    K[3*i+2,3*i+1] = K[3*i+2,3*i+1] + k[2,1]\n",
    "    K[3*i+2,3*i+2] = K[3*i+2,3*i+2] + k[2,2]\n",
    "    K[3*i+2,3*j] = K[3*i+2,3*j] + k[2,3]\n",
    "    K[3*i+2,3*j+1] = K[3*i,3*j+1] + k[2,4]\n",
    "    K[3*i+2,3*j+2] = K[3*i+2,3*j+2] + k[2,5]\n",
    "    K[3*j,3*i] = K[3*j,3*i] + k[3,0]\n",
    "    K[3*j,3*i+1] = K[3*j,3*i+1] + k[3,1]\n",
    "    K[3*j,3*i+2] = K[3*j,3*i+2] + k[3,2]\n",
    "    K[3*j,3*j] = K[3*j,3*j] + k[3,3]\n",
    "    K[3*j,3*j+1] = K[3*j,3*j+1] + k[3,4]\n",
    "    K[3*j,3*j+2] = K[3*j,3*j+2] + k[3,5]   \n",
    "    K[3*j+1,3*i] = K[3*j+1,3*i] + k[4,0]\n",
    "    K[3*j+1,3*i+1] = K[3*j+1,3*i+1] + k[4,1]\n",
    "    K[3*j+1,3*i+2] = K[3*j+1,3*i+2] + k[4,2]\n",
    "    K[3*j+1,3*j] = K[3*j+1,3*j] + k[4,3]\n",
    "    K[3*j+1,3*j+1] = K[3*j+1,3*j+1] + k[4,4]\n",
    "    K[3*j+1,3*j+2] = K[3*j+1,3*j+2] + k[4,5]\n",
    "    K[3*j+2,3*i] = K[3*j+2,3*i] + k[5,0]\n",
    "    K[3*j+2,3*i+1] = K[3*j+2,3*i+1] + k[5,1]\n",
    "    K[3*j+2,3*i+2] = K[3*j+2,3*i+2] + k[5,2]\n",
    "    K[3*j+2,3*j] = K[3*j+2,3*j] + k[5,3]\n",
    "    K[3*j+2,3*j+1] = K[3*j+2,3*j+1] + k[5,4]\n",
    "    K[3*j+2,3*j+2] = K[3*j+2,3*j+2] + k[5,5]\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FEA_u(coord, elcon, bc_node, bc_val, global_force, I=5e-5, A=2e-2, E=210e6):\n",
    "    K=np.zeros(shape=(3*np.max(elcon)+3,3*np.max(elcon)+3))\n",
    "    pi=math.pi\n",
    "    for el in elcon:\n",
    "        L=PlaneFrameElementLength(coord[el[0]][0],coord[el[0]][1],coord[el[1]][0],coord[el[1]][1])\n",
    "        theta=math.atan((coord[el[1]][1]-coord[el[0]][1])/(coord[el[1]][0]-coord[el[0]][0]+1e-13))*180/pi\n",
    "        k=PlaneFrameElementStiffness(E,A,I,L,theta)\n",
    "        K=PlaneFrameAssemble(K,k,el[0],el[1])\n",
    "    \n",
    "    \n",
    "    F = np.array(global_force)\n",
    "    \n",
    "    \n",
    "    # https://github.com/CALFEM/calfem-matlab/blob/master/fem/solveq.m\n",
    "    \n",
    "    bc=np.array([bc_node, \n",
    "                bc_val]).T\n",
    "    nd, nd=K.shape\n",
    "    fdof=np.array([i for i in range(nd)]).T\n",
    "    d=np.zeros(shape=(len(fdof),))\n",
    "    Q=np.zeros(shape=(len(fdof),))\n",
    "\n",
    "    pdof=bc[:,0].astype(int)\n",
    "    dp=bc[:,1]\n",
    "    fdof=np.delete(fdof, pdof, 0)\n",
    "    \n",
    "    K[np.isnan(K)] = 0\n",
    "    F[np.isnan(F)] = 0\n",
    "    \n",
    "    s=np.linalg.lstsq(K[fdof,:][:,fdof], (F[fdof].T-np.dot(K[fdof,:][:,pdof],dp.T)).T, rcond=None)[0] \n",
    "    d[pdof]=dp\n",
    "    d[fdof]=s.reshape(-1,)\n",
    "    \n",
    "#     Q=np.dot(K,d).T-F \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 The Plane Frame Element - verification\n",
    "d = FEA_u(np.array([0,0,\n",
    "                    0,3,\n",
    "                    4,3,\n",
    "                    4,0]).reshape(4,2),\n",
    "          elcon=np.array([[0, 1],\n",
    "                      [1, 2],\n",
    "                      [2, 3]]),\n",
    "          bc_node=[0,1,2,9,10,11], \n",
    "          bc_val=[0,0,0,0,0,0], \n",
    "          global_force=[0,0,0,-20,0,0,0,0,12,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -3.78670357e-03,\n",
       "       -6.13322735e-06,  7.83082263e-04, -3.77926520e-03,  6.13322735e-06,\n",
       "        1.40375402e-03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DISCRETE_ACTIONS=5\n",
    "DIM=23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrussEnv(gym.Env):\n",
    "    \n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS)\n",
    "        \n",
    "        self.pst=random.randint(0,7)\n",
    "        self.g_coord = alter_coord(4, self.pst, \n",
    "                                   np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "                                   dx=0.1, \n",
    "                                   change_nodes=list(range(1,9)))\n",
    "            \n",
    "            \n",
    "        self.displ = FEA_u(self.g_coord.reshape(10,2), \n",
    "                           elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                           bc_node=[0,1,2], \n",
    "                           bc_val=[0,0,0], \n",
    "                           global_force=np.array([0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  -10,0,0]))\n",
    "        self.obs=observe(self.pst, self.g_coord, self.displ,0)\n",
    "        self.observation_space = spaces.Box(low=np.array([-np.inf for x in range(DIM)]),\n",
    "                                            high=np.array([np.inf for y in range(DIM)]),\n",
    "                                            shape=(DIM,),\n",
    "                                           dtype=np.float64)\n",
    "        self.needs_reset = True\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        obs_=self.obs        \n",
    "        self.g_coord = alter_coord(action, self.pst, self.g_coord,\n",
    "                                  dx=0.1, change_nodes=list(range(1,9)))\n",
    "\n",
    "        self.pst=random.randint(0,7)\n",
    "        \n",
    "        done =False\n",
    "        if PlaneFrameElementLength(self.g_coord[0],\n",
    "                                   self.g_coord[1],\n",
    "                                   self.g_coord[2],\n",
    "                                   self.g_coord[3])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[2],\n",
    "                                   self.g_coord[3],\n",
    "                                   self.g_coord[4],\n",
    "                                   self.g_coord[5])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[4],\n",
    "                                   self.g_coord[5],\n",
    "                                   self.g_coord[6],\n",
    "                                   self.g_coord[7])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[6],\n",
    "                                   self.g_coord[7],\n",
    "                                   self.g_coord[8],\n",
    "                                   self.g_coord[9])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[8],\n",
    "                                   self.g_coord[9],\n",
    "                                   self.g_coord[10],\n",
    "                                   self.g_coord[11])<0.02:\n",
    "            done=True\n",
    "\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[10],\n",
    "                                   self.g_coord[11],\n",
    "                                   self.g_coord[12],\n",
    "                                   self.g_coord[13])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[12],\n",
    "                                   self.g_coord[13],\n",
    "                                   self.g_coord[14],\n",
    "                                   self.g_coord[15])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[14],\n",
    "                                   self.g_coord[15],\n",
    "                                   self.g_coord[16],\n",
    "                                   self.g_coord[17])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[16],\n",
    "                                   self.g_coord[17],\n",
    "                                   self.g_coord[18],\n",
    "                                   self.g_coord[19])<0.02:\n",
    "            done=True\n",
    "\n",
    "\n",
    "        self.displ = FEA_u(self.g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                           bc_node=[0,1,2], \n",
    "                                           bc_val=[0,0,0], \n",
    "                                           global_force=np.array([0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  -10,0,0]))\n",
    "\n",
    "        self.obs=observe(self.pst,self.g_coord,self.displ,action) \n",
    "\n",
    "        reward=reward_(obs_, self.obs)\n",
    "        \n",
    "        if self.needs_reset:\n",
    "            raise RuntimeError(\"Tried to step environment that needs reset\")\n",
    "            \n",
    "        if done:\n",
    "            self.needs_reset = True\n",
    "      \n",
    "        return np.array(self.obs), reward, done, dict()\n",
    "\n",
    "    def reset(self):\n",
    "        self.pst=random.randint(0,7)\n",
    "        self.g_coord = alter_coord(4, self.pst, np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "                                          dx=0.1, change_nodes=list(range(1,9)))\n",
    "            \n",
    "            \n",
    "        self.displ = FEA_u(self.g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_node=[0,1,2], \n",
    "                                                    bc_val=[0,0,0], \n",
    "                                                    global_force=np.array([0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  -10,0,0]))\n",
    "        self.obs=observe(self.pst, self.g_coord, self.displ,0)\n",
    "        self.needs_reset = False\n",
    "        return np.array(self.obs)  \n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        draw(self.g_coord,\n",
    "             color=\"blue\",\n",
    "             elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]))\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
    "                    )\n",
    "\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
    "                    self.model.save(self.save_path)\n",
    "\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log dir\n",
    "log_dir = \"/tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = TrussEnv()\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 11000\n",
      "Best mean reward: -inf - Last mean reward per episode: 4140.00\n",
      "Saving new best model to /tmp/gym/best_model.zip\n",
      "Num timesteps: 12000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 13000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 14000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 15000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 16000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 17000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 18000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 19000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 20000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 21000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4140.00\n",
      "Num timesteps: 22000\n",
      "Best mean reward: 4140.00 - Last mean reward per episode: 4552.50\n",
      "Saving new best model to /tmp/gym/best_model.zip\n",
      "Num timesteps: 23000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 24000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 25000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 26000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 27000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 28000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 29000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 30000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 31000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 32000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 33000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 34000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 35000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 36000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 37000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 38000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 39000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 40000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 41000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 42000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 43000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 44000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 45000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 46000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 47000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 48000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 49000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 50000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 51000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 52000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 53000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 54000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 55000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 56000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 57000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 58000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 59000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 60000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 61000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 62000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 63000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 64000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 65000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 66000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 67000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 68000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 69000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 70000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 71000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 72000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 73000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 74000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 75000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 76000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 77000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 78000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 79000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 80000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 81000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 82000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 83000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 84000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 85000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 86000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 87000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 88000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 89000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 90000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 91000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 92000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 93000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 94000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 95000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 96000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 97000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 98000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 99000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n",
      "Num timesteps: 100000\n",
      "Best mean reward: 4552.50 - Last mean reward per episode: 3158.33\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "# action_noise = NormalActionNoise(mean=np.zeros(N_DISCRETE_ACTIONS), sigma=0.1 * np.ones(N_DISCRETE_ACTIONS))\n",
    "model = PPO(\"MlpPolicy\", env,verbose=0).learn(total_timesteps=ts, callback=callback)\n",
    "end=time.time()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 4.486263648668925 min\n"
     ]
    }
   ],
   "source": [
    "print('Total time taken: {} min'.format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design by AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i<50:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    i+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.006254321329159678, 0.013833020196469958)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(env.displ),max(env.displ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(np.array([0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "     color=\"green\",\n",
    "     elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst=random.randint(0,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_coord = alter_coord(4, pst, np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "                                          dx=0.1, change_nodes=list(range(1,9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis=FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_node=[0,1,2], \n",
    "                                                    bc_val=[0,0,0], \n",
    "                                        global_force=np.array([0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  -10,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9257571525764527, 1.3885714431377043)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(dis), max(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper from the library\n",
    "results_plotter.plot_results([log_dir], ts, results_plotter.X_TIMESTEPS, \"PPO TrussEnv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
